{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BIOASQ_Bert_Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahithikodali1/Summarization-of-Biomedical-evidence/blob/Data_processing/BIOASQ_Bert_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yudBwt9FiLNu",
        "outputId": "ade0f3fb-edf7-4956-dc01-562c9cfd4668"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0NECXYHd7G5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a38f1f-8f73-4c5a-fd4b-4c9d630dbd51"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import csv\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# install\n",
        "!pip install pytorch-pretrained-bert pytorch-nlp\n",
        "\n",
        "# BERT imports\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.8.1+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.17.66)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.4.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.66 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.20.66)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.66->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.66->boto3->pytorch-pretrained-bert) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XshQoNObpnD7"
      },
      "source": [
        "##Code to load jsonfile\n",
        "\n",
        "# from pandas.io.json import json_normalize \n",
        "\n",
        "# with open('/content/drive/MyDrive/Thesis_B/training9b.json', 'r') as json_file:\n",
        "#     data = json.load(json_file)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUa1A23zzNw4"
      },
      "source": [
        "##Code to get questions list\n",
        "\n",
        "# data_access = data['questions']\n",
        "# body_list = []\n",
        "# for i in range(len(data_access)):\n",
        "#   text_list = []\n",
        "#   body_list.append(data_access[i]['body'])\n",
        "#   for j in data_access[i]['snippets']:\n",
        "#     text_list.append(j['text'])\n",
        "#   # list_concat = body_list+text_list\n",
        "#   # body_text_list.append(list_concat)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsBvr50uBrxg"
      },
      "source": [
        "## Code to add questions to csv data\n",
        "\n",
        "#DATA_DIR = \"/content/drive/MyDrive/Thesis_B\"\n",
        "# file = pd.read_csv(os.path.join(DATA_DIR,'rouge_9b_mod.csv'))\n",
        "# f_values = file.values\n",
        "\n",
        "# qids = f_values[:,0]\n",
        "# question_array = np.array(body_list)\n",
        "\n",
        "# questions = []\n",
        "# for i in range(len(qids)):\n",
        "#   qid = qids[i]\n",
        "#   questions.append(question_array[qid])\n",
        "\n",
        "# file['question'] = questions\n",
        "# file.to_csv('/content/drive/MyDrive/Thesis_B/9b_data.csv', index=False)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiAeyrco9CZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f9c05fa-1315-413a-8005-cc1a33b4ae5b"
      },
      "source": [
        "# #Code to split based on qid\n",
        "\n",
        "# DATA_DIR = \"/content/drive/MyDrive/Thesis_B\"\n",
        "# file = pd.read_csv(os.path.join(DATA_DIR,'9b_data.csv'))\n",
        "# f_values = file.values\n",
        "# q_id_split = np.split(f_values, np.where(np.diff(f_values[:,0]))[0]+1)\n",
        "# print(q_id_split[:2])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[0, '55031181e9bde69634000014', 20, 0.5814, 0.57143,\n",
            "        0.5121899999999999, 0.44998999999999995, 0.52892,\n",
            "        \"The non-Mendelian inheritance of sporadic non-syndromic Hirschsprung's disease proved to be complex; involvement of multiple loci was demonstrated in a multiplicative model\",\n",
            "        1,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 3, 0.5814, 0.57143,\n",
            "        0.5121899999999999, 0.44998999999999995, 0.52892,\n",
            "        \"The non-Mendelian inheritance of sporadic non-syndromic Hirschsprung's disease proved to be complex; involvement of multiple loci was demonstrated in a multiplicative model\",\n",
            "        1,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 16, 0.38961, 0.26666999999999996,\n",
            "        0.21916999999999998, 0.16902, 0.25117,\n",
            "        \"The majority of the identified genes are related to Mendelian syndromic forms of Hirschsprung's disease\",\n",
            "        1,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 2, 0.38961, 0.26666999999999996,\n",
            "        0.21916999999999998, 0.16902, 0.25117,\n",
            "        \"The majority of the identified genes are related to Mendelian syndromic forms of Hirschsprung's disease.\",\n",
            "        1,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 1, 0.41379, 0.18823, 0.09639,\n",
            "        0.04938, 0.2,\n",
            "        \"In this study, we review the identification of genes and loci involved in the non-syndromic common form and syndromic Mendelian forms of Hirschsprung's disease.\",\n",
            "        1,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 17, 0.41667, 0.14894000000000002,\n",
            "        0.04348, 0.0, 0.18015,\n",
            "        'In the etiology of Hirschsprung disease various genes play a role; these are: RET, EDNRB, GDNF, EDN3 and SOX10, NTN3, ECE1, Mutations in these genes may result in dominant, recessive or multifactorial patterns of inheritance',\n",
            "        0,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 14, 0.41667, 0.14894000000000002,\n",
            "        0.04348, 0.0, 0.18015,\n",
            "        'In the etiology of Hirschsprung disease various genes play a role; these are: RET, EDNRB, GDNF, EDN3 and SOX10, NTN3, ECE1, Mutations in these genes may result in dominant, recessive or multifactorial patterns of inheritance.',\n",
            "        0,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 6, 0.32143, 0.09091,\n",
            "        0.055560000000000005, 0.037739999999999996, 0.1375,\n",
            "        'Furthermore, mutations in the RET gene are responsible for approximately half of the familial and some sporadic cases, strongly suggesting, on the one hand, the importance of non-coding variations and, on the other hand, that additional genes involved in the development of the enteric nervous system still await their discovery',\n",
            "        0,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 5, 0.27659, 0.10869000000000001,\n",
            "        0.08889, 0.06817999999999999, 0.12405999999999999,\n",
            "        'RET, GDNF, EDNRB, EDN3, and SOX10 lead to long-segment (L-HSCR) as well as syndromic HSCR but fail to explain the transmission of the much more common short-segment form (S-HSCR).',\n",
            "        0,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 9, 0.31915, 0.13043, 0.04445,\n",
            "        0.02273, 0.09399,\n",
            "        ' Hirschsprung disease (HSCR) is a multifactorial, non-mendelian disorder in which rare high-penetrance coding sequence mutations in the receptor tyrosine kinase RET contribute to risk in combination with mutations at other genes.',\n",
            "        0,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 0, 0.31915, 0.13043, 0.04445,\n",
            "        0.02273, 0.09399,\n",
            "        'Hirschsprung disease (HSCR) is a multifactorial, non-mendelian disorder in which rare high-penetrance coding sequence mutations in the receptor tyrosine kinase RET contribute to risk in combination with mutations at other genes',\n",
            "        0,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 11, 0.31915, 0.13043, 0.04445,\n",
            "        0.02273, 0.09399,\n",
            "        'Hirschsprung disease (HSCR) is a multifactorial, non-mendelian disorder in which rare high-penetrance coding sequence mutations in the receptor tyrosine kinase RET contribute to risk in combination with mutations at other genes.',\n",
            "        0,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 19, 0.19512000000000002, 0.075,\n",
            "        0.025639999999999996, 0.0, 0.07826,\n",
            "        'The inheritance of Hirschsprung disease is generally consistent with sex-modified multifactorial inheritance with a lower threshold of expression in males',\n",
            "        0,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 10, 0.19512000000000002, 0.075,\n",
            "        0.025639999999999996, 0.0, 0.07826,\n",
            "        ' The inheritance of Hirschsprung disease is generally consistent with sex-modified multifactorial inheritance with a lower threshold of expression in males.',\n",
            "        0,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 13, 0.26374000000000003, 0.02247,\n",
            "        0.0, 0.0, 0.07782,\n",
            "        'BACKGROUND: RET is the major gene associated to Hirschsprung disease (HSCR) with differential contributions of its rare and common, coding and noncoding mutations to the multifactorial nature of this pathology.',\n",
            "        0,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 8, 0.24176, 0.06742000000000001,\n",
            "        0.02299, 0.0, 0.06615,\n",
            "        'Therefore, HSCR has become a model for a complex oligo-/polygenic disorder in which the relationship between different genes creating a non-mendelian inheritance pattern still remains to be elucidated',\n",
            "        0,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 15, 0.16901, 0.057970000000000015,\n",
            "        0.02985, 0.0, 0.05584,\n",
            "        \"Chromosomal and related Mendelian syndromes associated with Hirschsprung's disease.\",\n",
            "        0,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 12, 0.2078, 0.02667, 0.0, 0.0,\n",
            "        0.05582,\n",
            "        'Differential contributions of rare and common, coding and noncoding Ret mutations to multifactorial Hirschsprung disease liability.',\n",
            "        0,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 4, 0.1194, 0.09231, 0.0635,\n",
            "        0.032780000000000004, 0.05405,\n",
            "        'Coding sequence mutations in e.g.', 0,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 7, 0.16867000000000001, 0.0, 0.0,\n",
            "        0.0, 0.04292,\n",
            "        'For almost all of the identified HSCR genes incomplete penetrance of the HSCR phenotype has been reported, probably due to modifier loci.',\n",
            "        0,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?'],\n",
            "       [0, '55031181e9bde69634000014', 18, 0.16327, 0.02084, 0.0, 0.0,\n",
            "        0.03957,\n",
            "        'On the basis of a skewed sex-ratio (M/F = 4/1) and a risk to relatives much higher than the incidence in the general population, HSCR has long been regarded as a sex-modified multifactorial disorder',\n",
            "        0,\n",
            "        'Is Hirschsprung disease a mendelian or a multifactorial disorder?']],\n",
            "      dtype=object), array([[1, '55046d5ff8aee20f27000007', 8, 0.78261, 0.59091, 0.38095,\n",
            "        0.25, 0.54918,\n",
            "        'the 7 known EGFR ligands (EGF, betacellulin, epiregulin, heparin-binding EGF, transforming growth factor-α [TGF-α], amphiregulin, and epigen)',\n",
            "        1,\n",
            "        'List signaling molecules (ligands) that interact with the receptor EGFR?'],\n",
            "       [1, '55046d5ff8aee20f27000007', 1, 0.61905, 0.4,\n",
            "        0.21053000000000002, 0.055560000000000005, 0.4,\n",
            "        ' EGFR ligands epidermal growth factor (EGF), amphiregulin (AREG) and transforming growth factor alpha (TGFα)',\n",
            "        1,\n",
            "        'List signaling molecules (ligands) that interact with the receptor EGFR?'],\n",
            "       [1, '55046d5ff8aee20f27000007', 15, 0.69387, 0.38298000000000004,\n",
            "        0.08889, 0.0, 0.35114,\n",
            "        'mammalian EGFR ligands including EGF, TGF-α (TGFα), amphiregulin (AREG), heparin-binding EGF-like growth factor (HB-EGF), betacellulin, epiregulin, and epigen.',\n",
            "        1,\n",
            "        'List signaling molecules (ligands) that interact with the receptor EGFR?'],\n",
            "       [1, '55046d5ff8aee20f27000007', 0, 0.54545, 0.28570999999999996,\n",
            "        0.1, 0.052629999999999996, 0.28449,\n",
            "        'the epidermal growth factor receptor (EGFR) ligands, such as epidermal growth factor (EGF) and amphiregulin (AREG)',\n",
            "        1,\n",
            "        'List signaling molecules (ligands) that interact with the receptor EGFR?'],\n",
            "       [1, '55046d5ff8aee20f27000007', 6, 0.47368999999999994, 0.27778,\n",
            "        0.058820000000000004, 0.0, 0.2653,\n",
            "        'Among EGFR ligands, heparin-binding epidermal growth factor (HB-EGF)',\n",
            "        1,\n",
            "        'List signaling molecules (ligands) that interact with the receptor EGFR?'],\n",
            "       [1, '55046d5ff8aee20f27000007', 3, 0.49057, 0.23529, 0.08163, 0.0,\n",
            "        0.23776,\n",
            "        'Among EGFR ligands, heparin-binding EGF-like growth factor, TGF-α and Betacellulin (BTC) are produced in the tumor microenvironment of FDC-S at RNA level.',\n",
            "        0,\n",
            "        'List signaling molecules (ligands) that interact with the receptor EGFR?'],\n",
            "       [1, '55046d5ff8aee20f27000007', 13, 0.50794, 0.22951, 0.0678, 0.0,\n",
            "        0.237,\n",
            "        'oluble amphiregulin (AR), transforming growth factor alpha (TGFα), neuregulin 2 beta, and epigen stimulate greater EGFR coupling to cell proliferation and DNA synthesis than do EGF, betacellulin, heparin-binding EGF-like growth factor, and epiregulin',\n",
            "        0,\n",
            "        'List signaling molecules (ligands) that interact with the receptor EGFR?'],\n",
            "       [1, '55046d5ff8aee20f27000007', 5, 0.47058999999999995,\n",
            "        0.32653000000000004, 0.21277, 0.08889, 0.21898,\n",
            "        'Plasma amphiregulin (AR), epidermal growth factor (EGF), transforming growth factor-α, and heparin binding-EGF were assessed by ELISA in 45 chemorefractory mCRC patients',\n",
            "        0,\n",
            "        'List signaling molecules (ligands) that interact with the receptor EGFR?'],\n",
            "       [1, '55046d5ff8aee20f27000007', 14, 0.49057, 0.23529, 0.04082,\n",
            "        0.0, 0.17482,\n",
            "        'Here, we demonstrate that histamine releases 2 EGFR ligands, amphiregulin and heparin-binding epidermal growth factor-like growth factor (HB-EGF), from airway epithelial cells.',\n",
            "        0,\n",
            "        'List signaling molecules (ligands) that interact with the receptor EGFR?'],\n",
            "       [1, '55046d5ff8aee20f27000007', 7, 0.29629, 0.15385, 0.08, 0.0,\n",
            "        0.17123,\n",
            "        ' Of the six known EGFR ligands, transforming growth factor alpha (TGFα) was expressed more highly in triple-negative breast tumors than in tumors of other subtypes.',\n",
            "        0,\n",
            "        'List signaling molecules (ligands) that interact with the receptor EGFR?'],\n",
            "       [1, '55046d5ff8aee20f27000007', 9, 0.45453999999999994, 0.14286,\n",
            "        0.05, 0.0, 0.16379000000000002,\n",
            "        'EGFR ligands based on the two affinity classes: EGF>HB-EGF>TGF-α>BTC>EPR>EPG>AR',\n",
            "        0,\n",
            "        'List signaling molecules (ligands) that interact with the receptor EGFR?'],\n",
            "       [1, '55046d5ff8aee20f27000007', 12, 0.43903000000000003, 0.15385,\n",
            "        0.10811, 0.057139999999999996, 0.15888,\n",
            "        'Epidermal growth factor (EGF) family peptides are ligands for the EGF receptor (EGFR).',\n",
            "        0,\n",
            "        'List signaling molecules (ligands) that interact with the receptor EGFR?'],\n",
            "       [1, '55046d5ff8aee20f27000007', 11, 0.32433, 0.11427999999999999,\n",
            "        0.0, 0.0, 0.12632000000000002,\n",
            "        'four EGFR ligands (AR, HB-EGF, TGF-α, and EREG)', 0,\n",
            "        'List signaling molecules (ligands) that interact with the receptor EGFR?'],\n",
            "       [1, '55046d5ff8aee20f27000007', 10, 0.21739, 0.09091,\n",
            "        0.047619999999999996, 0.0, 0.057379999999999994,\n",
            "        'In this article, however, we demonstrate that PEPD directly binds to and activates epidermal growth factor receptor (EGFR),',\n",
            "        0,\n",
            "        'List signaling molecules (ligands) that interact with the receptor EGFR?'],\n",
            "       [1, '55046d5ff8aee20f27000007', 2, 0.18181, 0.0, 0.0, 0.0, 0.0241,\n",
            "        ' EGFR and its ligand EGF', 0,\n",
            "        'List signaling molecules (ligands) that interact with the receptor EGFR?'],\n",
            "       [1, '55046d5ff8aee20f27000007', 4, 0.0, 0.0, 0.0, 0.0, 0.0, '.',\n",
            "        0,\n",
            "        'List signaling molecules (ligands) that interact with the receptor EGFR?']],\n",
            "      dtype=object)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNWmw1_OqNns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a4318f-b08a-4a37-b46a-efba57445984"
      },
      "source": [
        "# #Predict train and test sizes\n",
        "\n",
        "# train_data_size = round(len(q_id_split)*0.8)\n",
        "# test_data_size = round(len(q_id_split) - train_data_size)\n",
        "# print(train_data_size)\n",
        "# print(test_data_size)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2994\n",
            "749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX6KqkjiqQQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae7883f8-bb72-483d-b3f2-c08c91f791d9"
      },
      "source": [
        "# #Shuffle qid randomly\n",
        "\n",
        "# import random\n",
        "# random.seed(3007)\n",
        "# random.shuffle(q_id_split)\n",
        "# print(type(q_id_split[:1]))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ0vrip7qSX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f7b652-a2ae-48b4-f4c5-47a7ab2f2130"
      },
      "source": [
        "# #Split train data into train and validation\n",
        "\n",
        "# train_data_beforeval = q_id_split[:2994]\n",
        "# f_values_train_beforeval = np.concatenate(train_data_beforeval, axis=0)\n",
        "# # print((f_values_train_beforeval))\n",
        "\n",
        "# q_id_split_train = np.split(f_values_train_beforeval, np.where(np.diff(f_values_train_beforeval[:,0]))[0]+1)\n",
        "# val_data_size = round(len(q_id_split_train)*0.2)\n",
        "# train_data_size = round(len(q_id_split_train) - val_data_size)\n",
        "# print(train_data_size)\n",
        "# print(val_data_size)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2395\n",
            "599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG9a2jANqjV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3650e754-ed0a-48c3-9836-6cf25514da8d"
      },
      "source": [
        "# #Split train, val, test data\n",
        "\n",
        "# train_data = q_id_split_train[:2395]\n",
        "# val_data = q_id_split_train[2395:]\n",
        "# test_data = q_id_split[2994:]\n",
        "# f_values_train = np.concatenate(train_data, axis=0)\n",
        "# f_values_val = np.concatenate(val_data, axis=0)\n",
        "# f_values_test = np.concatenate(test_data, axis=0)\n",
        "# col_names = file.columns\n",
        "# print(col_names)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['qid', 'pubmedid', 'sentid', 'N1', 'N2', 'L', 'S4', 'SU4',\n",
            "       'sentence text', 'SU4_labels', 'question'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEZu2kIHqweb"
      },
      "source": [
        "# #Convert train,val,test data into dataframes\n",
        "\n",
        "# train_df = pd.DataFrame(f_values_train, columns = col_names)\n",
        "# val_df = pd.DataFrame(f_values_val, columns = col_names)\n",
        "# test_df = pd.DataFrame(f_values_test, columns = col_names)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inoOuIV_q2wc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b61847-d45d-4359-a83a-e99c01fde39e"
      },
      "source": [
        "# print(len(train_data))\n",
        "# print(len(val_data))\n",
        "# print(len(test_data))\n",
        "\n",
        "# print(len(train_df))\n",
        "# print(len(val_df))\n",
        "# print(len(test_df))\n",
        "# print(train_df.columns.values)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2395\n",
            "599\n",
            "749\n",
            "37178\n",
            "8494\n",
            "11219\n",
            "['qid' 'pubmedid' 'sentid' 'N1' 'N2' 'L' 'S4' 'SU4' 'sentence text'\n",
            " 'SU4_labels' 'question']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAEVJ58c9dzP"
      },
      "source": [
        "# def obtain_specialtokenized_list(dataframe):\n",
        "#   sentences = dataframe['sentence text']\n",
        "#   questions = dataframe['question']\n",
        "#   sentences_list = list(sentences)\n",
        "#   questions_list = list(questions)\n",
        "#   question_sentence_list = []\n",
        "#   for i in range(len(sentences_list)):\n",
        "#     question_sentence_list = question_sentence_list + [\"[CLS] \" + questions_list[i] + \" [SEP] \" + sentences_list[i] + \" [SEP]\"]\n",
        "#   return question_sentence_list"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IKAlASHVGH6"
      },
      "source": [
        "# train_specialtok_list = obtain_specialtokenized_list(train_df)  \n",
        "# val_specialtok_list = obtain_specialtokenized_list(val_df)  "
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqummOa1yiXW"
      },
      "source": [
        "# def obtain_SU4labels_list(dataframe):\n",
        "#   SU4_labels = dataframe['SU4_labels']\n",
        "#   labels_list = list(SU4_labels)\n",
        "#   return labels_list\n",
        "\n",
        "\n",
        "# train_labels = obtain_SU4labels_list(train_df)\n",
        "# val_labels = obtain_SU4labels_list(val_df)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "914a_scryjlc"
      },
      "source": [
        "# #Write labels\n",
        "\n",
        "# with open(\"/content/drive/MyDrive/Thesis_B/labels_train.txt\", \"wb\") as fp:   #Pickling\n",
        "#   pickle.dump(train_labels, fp)\n",
        "\n",
        "# with open(\"/content/drive/MyDrive/Thesis_B/labels_val.txt\", \"wb\") as fp:   #Pickling\n",
        "#   pickle.dump(val_labels, fp)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgUgduIkWutv"
      },
      "source": [
        "##Write n Read Specialtok sentences\n",
        "\n",
        "# import pickle\n",
        "# with open(\"/content/drive/MyDrive/Thesis_B/Specialtok_sent_train.txt\", \"wb\") as fp:   #Pickling\n",
        "#   pickle.dump(train_specialtok_list, fp)\n",
        "\n",
        "# with open(\"/content/drive/MyDrive/Thesis_B/Specialtok_sent_val.txt\", \"wb\") as fp:   #Pickling\n",
        "#   pickle.dump(val_specialtok_list, fp)\n",
        "\n",
        "# with open(\"/content/drive/MyDrive/Thesis_B/Specialtok_sent_train.txt\", \"rb\") as fp:   # Unpickling\n",
        "#   train_specialtok_list = pickle.load(fp)\n",
        "\n",
        "# with open(\"/content/drive/MyDrive/Thesis_B/Specialtok_sent_val.txt\", \"rb\") as fp:   # Unpickling\n",
        "#   val_specialtok_list = pickle.load(fp)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oJXkfdl2ZtUa",
        "outputId": "9cacadc9-eeba-4b30-a10c-4079fc98daa8"
      },
      "source": [
        "# specify GPU device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iletNX7NWjTo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40cafd24-ebc7-489a-efb5-89eb20ded0d4"
      },
      "source": [
        "# Tokenize with BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 698807.68B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3h3Wo-LaBg5"
      },
      "source": [
        "# def tokenize_sent(givenlist):\n",
        "#   tokenized_texts = [tokenizer.tokenize(sent) for sent in givenlist]\n",
        "#   return tokenized_texts"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj45H6C8tp_9"
      },
      "source": [
        "# train_tokenized = tokenize_sent(train_specialtok_list)\n",
        "# val_tokenized = tokenize_sent(val_specialtok_list)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP-iTRPnvcLe"
      },
      "source": [
        "# print(type(train_tokenized))\n",
        "# print(len(train_tokenized))\n",
        "# print(train_tokenized[0])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-X_uM1bneh0"
      },
      "source": [
        "##Write tokenized sentences\n",
        "\n",
        "# with open(\"/content/drive/MyDrive/Thesis_B/Tokenized_sent_train.txt\", \"wb\") as fp:   #Pickling\n",
        "#   pickle.dump(train_tokenized, fp)\n",
        "\n",
        "# with open(\"/content/drive/MyDrive/Thesis_B/Tokenized_sent_val.txt\", \"wb\") as fp:   #Pickling\n",
        "#   pickle.dump(val_tokenized, fp)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4tXGaNznlXS"
      },
      "source": [
        "#Read tokenized sentences\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Thesis_B/Tokenized_sent_train.txt\", \"rb\") as fp:   # Unpickling\n",
        "  train_tokenized = pickle.load(fp)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Thesis_B/Tokenized_sent_val.txt\", \"rb\") as fp:   # Unpickling\n",
        "  val_tokenized = pickle.load(fp)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQv76Q37zmyx"
      },
      "source": [
        "#Read labels\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Thesis_B/labels_train.txt\", \"rb\") as fp:   # Unpickling\n",
        "  train_labels = pickle.load(fp)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Thesis_B/labels_val.txt\", \"rb\") as fp:   # Unpickling\n",
        "  val_labels = pickle.load(fp)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YECi9irnusj",
        "outputId": "8e597a16-4f91-451f-de29-a07c6d21da44"
      },
      "source": [
        "print(type(train_tokenized))\n",
        "print(len(train_tokenized))\n",
        "print(train_tokenized[0])\n",
        "print(len(val_tokenized))\n",
        "print(val_tokenized[0])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "37178\n",
            "['[CLS]', 'what', 'is', 'mas', '##iti', '##ni', '##b', 'an', 'inhibitor', 'of', '?', '[SEP]', 'this', 'study', 'evaluated', 'the', 'therapeutic', 'potential', 'of', 'mas', '##iti', '##ni', '##b', ',', 'an', 'oral', 'ty', '##ros', '##ine', 'kinase', 'inhibitor', 'with', 'activity', 'against', 'c', '-', 'kit', 'and', 'plate', '##let', '-', 'derived', 'growth', 'factor', 'receptors', '(', 'pd', '##gf', '##r', ')', ',', 'to', 'reduce', 'is', '##che', '##mic', 'brain', 'area', 'and', 'neurological', 'deficit', '.', '[SEP]']\n",
            "8494\n",
            "['[CLS]', 'which', 'proteins', 'are', 'regulated', 'by', 'nr', '##f', '##2', '?', '[SEP]', 'ke', '##ap', '##1', '-', 'nr', '##f', '##2', 'system', 'is', 'known', 'as', 'a', 'sensor', 'of', 'electro', '##phi', '##lic', 'compounds', ',', 'and', 'protects', 'cells', 'from', 'ox', '##ida', '##tive', 'stress', 'through', 'induction', 'of', 'various', 'anti', '##ox', '##ida', '##nt', 'enzymes', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBR6_H8poQi7"
      },
      "source": [
        "#Convert tokenized sentences to respective token ids\n",
        "\n",
        "def token2ids(tokenized_texts):\n",
        "  # Set the maximum sequence length. \n",
        "  MAX_LEN = 512\n",
        "\n",
        "  tokens_to_ids = [tokenizer.convert_tokens_to_ids(sent) for sent in tokenized_texts]\n",
        "  tokens_to_ids = pad_sequences(tokens_to_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "  return tokens_to_ids"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZiI2xi2xYP8"
      },
      "source": [
        "train_tokenids = token2ids(train_tokenized)\n",
        "val_tokenids = token2ids(val_tokenized)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJZiy4PJpLpz"
      },
      "source": [
        "#Create masks for the tokenids\n",
        "\n",
        "def create_masks(token_ids):\n",
        "  attention_masks = []\n",
        "\n",
        "  for tid in token_ids:\n",
        "    tid_mask = [float(i>0) for i in tid]\n",
        "    attention_masks.append(tid_mask)\n",
        "  return attention_masks"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BOKzFFXx2aV"
      },
      "source": [
        "train_masks = create_masks(train_tokenids)\n",
        "val_masks = create_masks(val_tokenids)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANygrvl2yP3M",
        "outputId": "59f6d0ae-c1a7-4805-ec57-c1fd2fa8b4a1"
      },
      "source": [
        "print(len(train_tokenids))\n",
        "print(len(train_masks))\n",
        "print(train_tokenids[0])\n",
        "print(train_masks[0])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37178\n",
            "37178\n",
            "[  101  2054  2003 16137 25090  3490  2497  2019 24054  1997  1029   102\n",
            "  2023  2817 16330  1996 17261  4022  1997 16137 25090  3490  2497  1010\n",
            "  2019  8700  5939  7352  3170 21903 24054  2007  4023  2114  1039  1011\n",
            "  8934  1998  5127  7485  1011  5173  3930  5387 13833  1006 22851 25708\n",
            "  2099  1007  1010  2000  5547  2003  5403  7712  4167  2181  1998 23130\n",
            " 15074  1012   102     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8Vu1OJ90Miu",
        "outputId": "49381cb6-a657-48de-f10e-77950e6f5e27"
      },
      "source": [
        "print(type(train_tokenids))\n",
        "print(type(train_masks))\n",
        "print(type(train_labels))\n",
        "\n",
        "print(train_tokenids.shape)\n",
        "print(len(train_masks))\n",
        "print(len(train_labels))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "(37178, 512)\n",
            "37178\n",
            "37178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncp3-8E200hN"
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "train_inputs = torch.tensor(train_tokenids, dtype=torch.int64)\n",
        "validation_inputs = torch.tensor(val_tokenids, dtype=torch.int64)\n",
        "\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.int64)\n",
        "validation_labels = torch.tensor(val_labels, dtype=torch.int64)\n",
        "\n",
        "train_masks = torch.tensor(train_masks, dtype=torch.float32)\n",
        "validation_masks = torch.tensor(val_masks, dtype=torch.float32)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP0IAWDg08tL",
        "outputId": "b7ae5daa-d1ae-47d9-e6dc-b29d9df3102e"
      },
      "source": [
        "print(type(train_inputs))\n",
        "print(type(train_labels))\n",
        "print(type(train_masks))\n",
        "\n",
        "print(train_inputs.dtype)\n",
        "print(train_labels.dtype)\n",
        "print(train_masks.dtype)\n",
        "\n",
        "print(validation_inputs.dtype)\n",
        "print(validation_labels.dtype)\n",
        "print(validation_masks.dtype)\n",
        "\n",
        "print(train_inputs.shape)\n",
        "print(train_labels.shape)\n",
        "print(train_masks.shape)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "torch.int64\n",
            "torch.int64\n",
            "torch.float32\n",
            "torch.int64\n",
            "torch.int64\n",
            "torch.float32\n",
            "torch.Size([37178, 512])\n",
            "torch.Size([37178])\n",
            "torch.Size([37178, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCihmfFS1I6E",
        "outputId": "d665a88b-3686-4c5b-e4eb-a1d37194d862"
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\r\u001b[K     |▏                               | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 19.9MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 16.4MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 14.8MB/s eta 0:00:01\r\u001b[K     |▉                               | 51kB 12.4MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 11.5MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71kB 10.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 81kB 11.4MB/s eta 0:00:01\r\u001b[K     |█▍                              | 92kB 11.6MB/s eta 0:00:01\r\u001b[K     |█▋                              | 102kB 10.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 112kB 10.1MB/s eta 0:00:01\r\u001b[K     |██                              | 122kB 10.1MB/s eta 0:00:01\r\u001b[K     |██                              | 133kB 10.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 143kB 10.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 153kB 10.1MB/s eta 0:00:01\r\u001b[K     |██▌                             | 163kB 10.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 174kB 10.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 184kB 10.1MB/s eta 0:00:01\r\u001b[K     |███                             | 194kB 10.1MB/s eta 0:00:01\r\u001b[K     |███▏                            | 204kB 10.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 215kB 10.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 225kB 10.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 235kB 10.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 245kB 10.1MB/s eta 0:00:01\r\u001b[K     |████                            | 256kB 10.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 266kB 10.1MB/s eta 0:00:01\r\u001b[K     |████▎                           | 276kB 10.1MB/s eta 0:00:01\r\u001b[K     |████▌                           | 286kB 10.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 296kB 10.1MB/s eta 0:00:01\r\u001b[K     |████▊                           | 307kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 317kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 327kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 337kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 348kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 358kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 368kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 378kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 389kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 399kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 409kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 419kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 430kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 440kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 450kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 460kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 471kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 481kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 491kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 501kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 512kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 522kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 532kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 542kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 552kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 563kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 573kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 583kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 593kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 604kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 614kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 624kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 634kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 645kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 655kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 665kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 675kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 686kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 696kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 706kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 716kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 727kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 737kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 747kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 757kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 768kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 778kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 788kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 798kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 808kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 819kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 829kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 839kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 849kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 860kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 870kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 880kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 890kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 901kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 911kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 921kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 931kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 942kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 952kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 962kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 972kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 983kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 993kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.3MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.3MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.3MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.3MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.3MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.3MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.3MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.3MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.3MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.4MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.4MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.4MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.4MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.4MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.4MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.4MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.4MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.4MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.4MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.5MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.5MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.5MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.5MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.5MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.5MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.5MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.5MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.5MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.5MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.6MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.6MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.6MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.6MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.6MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.6MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.6MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.6MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.6MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.6MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.7MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.7MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.7MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.7MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.7MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.7MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.7MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.7MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.7MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.8MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.8MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.8MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.8MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.8MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.8MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.8MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.8MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.8MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.8MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.9MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.9MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.9MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.9MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.9MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.9MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.9MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.9MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.9MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.9MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 2.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.1MB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 40.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 38.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqmqchho1NsN",
        "outputId": "c12b9085-97b5-43c8-fb6d-f52131e0fe3e"
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top.\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 2)\n",
        "\n",
        "for param in model.bert.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "model.cuda()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:13<00:00, 29776450.07B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IbM4BJo5TBZ"
      },
      "source": [
        "#BERT fine-tuning parameters\n",
        "lr=2e-5\n",
        "num_warmup_steps = 10\n",
        "num_training_steps = 1000\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = lr)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = num_warmup_steps, num_training_steps = num_training_steps)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFEw7RYU1Ah2"
      },
      "source": [
        "# Select a batch size for training. \n",
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader \n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data) #change to seq sampler next time and try\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cMTaqzI-ZsQ"
      },
      "source": [
        "# for step, batch in enumerate(train_dataloader):\n",
        "#   print(step)\n",
        "#   b_input_ids, b_input_mask, b_labels = batch\n",
        "#   print(b_input_ids.size(0))\n",
        "#   # print(len(b_input_mask))\n",
        "#   # print(len(b_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JWrNaxwBxIB"
      },
      "source": [
        "import random\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufY2Ca8CPa_z"
      },
      "source": [
        "# train_loss_set = []\n",
        "# # train_logits_set = []\n",
        "# epochs = 3\n",
        "\n",
        "# for _ in trange(epochs, desc=\"Epoch\"): \n",
        "#   model.train() \n",
        "#   tr_loss = 0\n",
        "#   nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "#   for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "#     print(\"Step:{}\".format(step))\n",
        "\n",
        "#     batch = tuple(t.to(device) for t in batch)\n",
        "#     b_input_ids, b_input_masks, b_labels = batch\n",
        "\n",
        "#     optimizer.zero_grad()\n",
        "\n",
        "#     loss = model(b_input_ids, token_type_ids = None, attention_mask = b_input_masks, labels = b_labels)\n",
        "#     print(\"Loss for batch :{}\".format(loss))\n",
        "#     # print(\"Logits for batch :{}\".format(logits))\n",
        "#     train_loss_set.append(loss.item()) \n",
        "#     # train_logits_set.append(logits.item()) \n",
        "\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "#     scheduler.step()\n",
        "\n",
        "#     tr_loss = tr_loss + loss.item()\n",
        "#     print(\"tr_loss:{}\".format(tr_loss))\n",
        "\n",
        "#     nb_tr_examples += b_input_ids.size(0)\n",
        "#     print(\"nb_tr_examples:{}\".format(nb_tr_examples))\n",
        "\n",
        "#     nb_tr_steps += 1\n",
        "#     print(\"nb_tr_steps:{}\".format(nb_tr_steps))\n",
        "\n",
        "#   print(\" Train loss: {}\".format(tr_loss/nb_tr_steps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXdM5Tw75eBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f6aaa19-c99a-4fbb-b4bd-815901337d07"
      },
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs \n",
        "epochs = 3\n",
        "\n",
        "for _ in trange(epochs, desc=\"Epoch\"):  \n",
        "  ## TRAINING\n",
        "  # Set our model to training mode\n",
        "  model.train()  \n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_masks, b_labels = batch\n",
        "\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids, token_type_ids = None, attention_mask = b_input_masks, labels = b_labels)\n",
        "    train_loss_set.append(loss.item())  \n",
        "    # train_logits_set.append(logits.item())   \n",
        "    \n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item() #(Transfers to a plain python number as that only can live on CPU)\n",
        "    \n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    \n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\" Train loss: {}\".format(tr_loss/nb_tr_steps))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  33%|███▎      | 1/3 [44:52<1:29:45, 2692.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Train loss: 0.615616526461099\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  67%|██████▋   | 2/3 [1:29:34<44:49, 2689.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Train loss: 0.608901037227061\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 3/3 [2:14:16<00:00, 2685.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Train loss: 0.6088739113943097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHcbCMxuz7b_"
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV4u50CfpsjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b3201b-6326-4648-adc6-10eccb9e0407"
      },
      "source": [
        "# VALIDATION\n",
        "\n",
        "logits_list = []\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "eval_loss, eval_accuracy, eval_f1score = 0, 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in validation_dataloader:\n",
        "\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_masks, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    # Forward pass, calculate logit predictions\n",
        "    logits = model(b_input_ids, token_type_ids = None, attention_mask = b_input_masks)   \n",
        "    print(\"Logits_each:{}\".format(logits))\n",
        "    logits_list.append(logits)\n",
        "  \n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  print(\"Logits:{}\".format(logits))\n",
        "  print(\"Labels:{}\".format(label_ids))\n",
        "  \n",
        "  tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "  # tmp_eval_f1score = flat_f1score(logits, label_ids)    \n",
        "  eval_accuracy += tmp_eval_accuracy\n",
        "  # eval_f1score += tmp_eval_f1score\n",
        "  nb_eval_steps += 1\n",
        "\n",
        "print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "# print(\"Validation f1score: {}\".format(eval_f1score/nb_eval_steps))\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " [ 0.3096775  -0.52360564]\n",
            " [ 0.34029275 -0.43659687]\n",
            " [ 0.37122482 -0.5126048 ]\n",
            " [ 0.40293613 -0.43832722]\n",
            " [ 0.35754216 -0.4249533 ]\n",
            " [ 0.49490553 -0.45117253]\n",
            " [ 0.40284264 -0.43330753]\n",
            " [ 0.4922052  -0.4499023 ]\n",
            " [ 0.4922052  -0.4499023 ]\n",
            " [ 0.4000904  -0.42449948]\n",
            " [ 0.43301797 -0.4456572 ]\n",
            " [ 0.38505372 -0.42947805]\n",
            " [ 0.49580994 -0.51767844]\n",
            " [ 0.49580994 -0.51767844]\n",
            " [ 0.49580994 -0.51767844]\n",
            " [ 0.5020286  -0.47296157]\n",
            " [ 0.5020286  -0.47296157]\n",
            " [ 0.40437597 -0.46629772]\n",
            " [ 0.43338394 -0.47650668]\n",
            " [ 0.3854981  -0.49821627]\n",
            " [ 0.3854981  -0.49821627]\n",
            " [ 0.38791537 -0.45711148]\n",
            " [ 0.45707613 -0.49449468]\n",
            " [ 0.45748755 -0.51141864]\n",
            " [ 0.33420643 -0.53976583]\n",
            " [ 0.33420643 -0.53976583]\n",
            " [ 0.33420643 -0.53976583]\n",
            " [ 0.4597324  -0.5145579 ]\n",
            " [ 0.37594172 -0.48977098]]\n",
            "Labels:[0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4549, -0.4877],\n",
            "        [ 0.3776, -0.5072],\n",
            "        [ 0.4946, -0.4291],\n",
            "        [ 0.4579, -0.4713],\n",
            "        [ 0.3567, -0.4584],\n",
            "        [ 0.2993, -0.3678],\n",
            "        [ 0.3808, -0.4817],\n",
            "        [ 0.4172, -0.4455],\n",
            "        [ 0.4474, -0.4700],\n",
            "        [ 0.3364, -0.5442],\n",
            "        [ 0.3803, -0.5024],\n",
            "        [ 0.4938, -0.4845],\n",
            "        [ 0.3944, -0.4677],\n",
            "        [ 0.4308, -0.4859],\n",
            "        [ 0.2800, -0.5952],\n",
            "        [ 0.3686, -0.5240],\n",
            "        [ 0.4203, -0.4728],\n",
            "        [ 0.3446, -0.5543],\n",
            "        [ 0.4164, -0.4891],\n",
            "        [ 0.3868, -0.5720],\n",
            "        [ 0.4768, -0.4466],\n",
            "        [ 0.2633, -0.5107],\n",
            "        [ 0.2072, -0.5092],\n",
            "        [ 0.3334, -0.4879],\n",
            "        [ 0.0134, -0.3671],\n",
            "        [ 0.0134, -0.3671],\n",
            "        [ 0.0134, -0.3671],\n",
            "        [ 0.2237, -0.5004],\n",
            "        [ 0.3374, -0.5459],\n",
            "        [ 0.2033, -0.5151],\n",
            "        [ 0.3055, -0.5272],\n",
            "        [ 0.2812, -0.5710]], device='cuda:0')\n",
            "Logits:[[ 0.454888   -0.48768508]\n",
            " [ 0.37759143 -0.5072221 ]\n",
            " [ 0.49461648 -0.4291045 ]\n",
            " [ 0.45793048 -0.47125804]\n",
            " [ 0.3567009  -0.458379  ]\n",
            " [ 0.29933897 -0.3678302 ]\n",
            " [ 0.38075387 -0.4816511 ]\n",
            " [ 0.41719428 -0.4454647 ]\n",
            " [ 0.44740587 -0.4700467 ]\n",
            " [ 0.33641687 -0.54423857]\n",
            " [ 0.38025227 -0.5023564 ]\n",
            " [ 0.49381098 -0.48452356]\n",
            " [ 0.39435765 -0.46771085]\n",
            " [ 0.43083242 -0.48590034]\n",
            " [ 0.28001374 -0.5951965 ]\n",
            " [ 0.36858782 -0.52399385]\n",
            " [ 0.4203184  -0.4728277 ]\n",
            " [ 0.34457943 -0.55427665]\n",
            " [ 0.41643173 -0.48914894]\n",
            " [ 0.3867531  -0.5720315 ]\n",
            " [ 0.4768297  -0.4466052 ]\n",
            " [ 0.26326355 -0.51074314]\n",
            " [ 0.2072323  -0.5091808 ]\n",
            " [ 0.3333844  -0.48794618]\n",
            " [ 0.0133573  -0.36705565]\n",
            " [ 0.0133573  -0.36705565]\n",
            " [ 0.0133573  -0.36705565]\n",
            " [ 0.22373758 -0.50039077]\n",
            " [ 0.33742678 -0.5459145 ]\n",
            " [ 0.20327736 -0.5151497 ]\n",
            " [ 0.30551457 -0.52723145]\n",
            " [ 0.28116974 -0.5710031 ]]\n",
            "Labels:[0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.2608, -0.4929],\n",
            "        [ 0.2712, -0.4945],\n",
            "        [ 0.3016, -0.4669],\n",
            "        [ 0.3462, -0.4764],\n",
            "        [ 0.4627, -0.4437],\n",
            "        [ 0.4128, -0.4688],\n",
            "        [ 0.4372, -0.4729],\n",
            "        [ 0.4668, -0.4858],\n",
            "        [ 0.4670, -0.4600],\n",
            "        [ 0.4851, -0.4005],\n",
            "        [ 0.4945, -0.5693],\n",
            "        [ 0.4291, -0.4590],\n",
            "        [ 0.3594, -0.4760],\n",
            "        [ 0.3610, -0.4441],\n",
            "        [ 0.3493, -0.4684],\n",
            "        [ 0.3563, -0.4839],\n",
            "        [ 0.3630, -0.4752],\n",
            "        [ 0.4176, -0.4690],\n",
            "        [ 0.3579, -0.5113],\n",
            "        [ 0.3296, -0.5226],\n",
            "        [ 0.2823, -0.4513],\n",
            "        [ 0.3676, -0.4776],\n",
            "        [ 0.2558, -0.5019],\n",
            "        [ 0.3442, -0.4570],\n",
            "        [ 0.3933, -0.4914],\n",
            "        [ 0.3718, -0.4791],\n",
            "        [ 0.3887, -0.4791],\n",
            "        [ 0.3362, -0.4804],\n",
            "        [ 0.4159, -0.4871],\n",
            "        [ 0.3729, -0.5111],\n",
            "        [ 0.3432, -0.4840],\n",
            "        [ 0.3209, -0.4745]], device='cuda:0')\n",
            "Logits:[[ 0.26078576 -0.49287802]\n",
            " [ 0.2711524  -0.494536  ]\n",
            " [ 0.3015928  -0.4669429 ]\n",
            " [ 0.34616083 -0.47635323]\n",
            " [ 0.46272248 -0.44365132]\n",
            " [ 0.4128345  -0.46883065]\n",
            " [ 0.43719846 -0.4728727 ]\n",
            " [ 0.46682027 -0.48583648]\n",
            " [ 0.46701726 -0.4600368 ]\n",
            " [ 0.48513913 -0.40052634]\n",
            " [ 0.4945063  -0.5693289 ]\n",
            " [ 0.42910084 -0.4590422 ]\n",
            " [ 0.35941178 -0.4760018 ]\n",
            " [ 0.36101833 -0.44412333]\n",
            " [ 0.34927666 -0.46844184]\n",
            " [ 0.3562825  -0.48392272]\n",
            " [ 0.36304578 -0.47522086]\n",
            " [ 0.417609   -0.46895555]\n",
            " [ 0.35794595 -0.5112812 ]\n",
            " [ 0.32957783 -0.52263135]\n",
            " [ 0.28234658 -0.45129603]\n",
            " [ 0.36758682 -0.4776245 ]\n",
            " [ 0.25581098 -0.50194246]\n",
            " [ 0.34418976 -0.45700604]\n",
            " [ 0.39327908 -0.4913971 ]\n",
            " [ 0.37177324 -0.47913036]\n",
            " [ 0.38872516 -0.4790944 ]\n",
            " [ 0.33619815 -0.48039958]\n",
            " [ 0.41585013 -0.4870643 ]\n",
            " [ 0.37288845 -0.511112  ]\n",
            " [ 0.3431785  -0.48396733]\n",
            " [ 0.32090488 -0.47451422]]\n",
            "Labels:[0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3266, -0.4857],\n",
            "        [ 0.3532, -0.4735],\n",
            "        [ 0.3874, -0.4750],\n",
            "        [ 0.2868, -0.5257],\n",
            "        [ 0.3570, -0.5178],\n",
            "        [ 0.3528, -0.4913],\n",
            "        [ 0.2468, -0.5212],\n",
            "        [ 0.2444, -0.4797],\n",
            "        [ 0.4133, -0.4722],\n",
            "        [ 0.4145, -0.4321],\n",
            "        [ 0.3531, -0.4941],\n",
            "        [ 0.3089, -0.5580],\n",
            "        [ 0.3624, -0.5169],\n",
            "        [ 0.4611, -0.5275],\n",
            "        [ 0.4623, -0.5407],\n",
            "        [ 0.3611, -0.5899],\n",
            "        [ 0.3955, -0.5254],\n",
            "        [ 0.4371, -0.4833],\n",
            "        [ 0.4371, -0.4833],\n",
            "        [ 0.3384, -0.5151],\n",
            "        [ 0.4776, -0.5150],\n",
            "        [ 0.3259, -0.5113],\n",
            "        [ 0.4348, -0.4622],\n",
            "        [ 0.3365, -0.5235],\n",
            "        [ 0.4165, -0.4459],\n",
            "        [ 0.4112, -0.4844],\n",
            "        [ 0.4449, -0.4703],\n",
            "        [ 0.4633, -0.5016],\n",
            "        [ 0.5061, -0.4660],\n",
            "        [ 0.4092, -0.5129],\n",
            "        [ 0.3932, -0.4856],\n",
            "        [ 0.3696, -0.4551]], device='cuda:0')\n",
            "Logits:[[ 0.32658318 -0.48570263]\n",
            " [ 0.35324702 -0.4735196 ]\n",
            " [ 0.38740218 -0.47501516]\n",
            " [ 0.2867752  -0.52571505]\n",
            " [ 0.3570323  -0.51783556]\n",
            " [ 0.3528459  -0.49132833]\n",
            " [ 0.24679126 -0.5211801 ]\n",
            " [ 0.24436519 -0.47967657]\n",
            " [ 0.41326448 -0.47223035]\n",
            " [ 0.4144666  -0.4320701 ]\n",
            " [ 0.35313344 -0.4941307 ]\n",
            " [ 0.30892864 -0.5580002 ]\n",
            " [ 0.36237186 -0.5169151 ]\n",
            " [ 0.4610969  -0.52751887]\n",
            " [ 0.46226484 -0.5406506 ]\n",
            " [ 0.36109337 -0.5898999 ]\n",
            " [ 0.39548275 -0.52543724]\n",
            " [ 0.43705446 -0.4832914 ]\n",
            " [ 0.43705446 -0.4832914 ]\n",
            " [ 0.33844718 -0.5151227 ]\n",
            " [ 0.47756693 -0.51496834]\n",
            " [ 0.32588232 -0.5113477 ]\n",
            " [ 0.43483815 -0.46220633]\n",
            " [ 0.33653817 -0.52353203]\n",
            " [ 0.4164703  -0.4458698 ]\n",
            " [ 0.41115704 -0.48442602]\n",
            " [ 0.44486162 -0.4703083 ]\n",
            " [ 0.46327466 -0.50156474]\n",
            " [ 0.5061374  -0.46603695]\n",
            " [ 0.40924665 -0.5129443 ]\n",
            " [ 0.3932112  -0.4856464 ]\n",
            " [ 0.3695845  -0.455101  ]]\n",
            "Labels:[0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1]\n",
            "Logits_each:tensor([[ 0.4031, -0.4357],\n",
            "        [ 0.3818, -0.4573],\n",
            "        [ 0.4453, -0.4023],\n",
            "        [ 0.4411, -0.4922],\n",
            "        [ 0.3958, -0.3937],\n",
            "        [ 0.3057, -0.4994],\n",
            "        [ 0.3396, -0.4410],\n",
            "        [ 0.4408, -0.4455],\n",
            "        [ 0.3388, -0.4286],\n",
            "        [ 0.4399, -0.4366],\n",
            "        [ 0.1382, -0.3277],\n",
            "        [ 0.4846, -0.4771],\n",
            "        [ 0.4788, -0.4355],\n",
            "        [ 0.3202, -0.4816],\n",
            "        [ 0.4420, -0.3906],\n",
            "        [ 0.2561, -0.2593],\n",
            "        [ 0.4222, -0.3878],\n",
            "        [ 0.3819, -0.5020],\n",
            "        [ 0.2021, -0.1917],\n",
            "        [ 0.4309, -0.4309],\n",
            "        [ 0.3516, -0.5307],\n",
            "        [ 0.4518, -0.4005],\n",
            "        [ 0.3645, -0.4492],\n",
            "        [ 0.3645, -0.4492],\n",
            "        [ 0.4259, -0.4349],\n",
            "        [ 0.3873, -0.4974],\n",
            "        [ 0.3972, -0.4613],\n",
            "        [ 0.4214, -0.4485],\n",
            "        [ 0.3360, -0.5202],\n",
            "        [ 0.4318, -0.4268],\n",
            "        [ 0.3676, -0.5133],\n",
            "        [ 0.4009, -0.4793]], device='cuda:0')\n",
            "Logits:[[ 0.40309545 -0.43567815]\n",
            " [ 0.38177183 -0.45725742]\n",
            " [ 0.44529897 -0.40231532]\n",
            " [ 0.4410738  -0.49215934]\n",
            " [ 0.39583474 -0.39365944]\n",
            " [ 0.30569133 -0.49941042]\n",
            " [ 0.3395965  -0.44098336]\n",
            " [ 0.44077834 -0.44549707]\n",
            " [ 0.33884206 -0.42855847]\n",
            " [ 0.43994305 -0.43662947]\n",
            " [ 0.13820583 -0.32770032]\n",
            " [ 0.4845794  -0.47710064]\n",
            " [ 0.4788073  -0.43546474]\n",
            " [ 0.3201524  -0.48157004]\n",
            " [ 0.44204295 -0.39060798]\n",
            " [ 0.2560597  -0.25928572]\n",
            " [ 0.42221197 -0.3877749 ]\n",
            " [ 0.3818581  -0.5020295 ]\n",
            " [ 0.2021426  -0.19171786]\n",
            " [ 0.43086615 -0.43093982]\n",
            " [ 0.3515924  -0.5307401 ]\n",
            " [ 0.45178813 -0.40045607]\n",
            " [ 0.36445752 -0.44923496]\n",
            " [ 0.36445752 -0.44923496]\n",
            " [ 0.4258875  -0.43486515]\n",
            " [ 0.387252   -0.4973576 ]\n",
            " [ 0.3972219  -0.46128872]\n",
            " [ 0.42144305 -0.44850895]\n",
            " [ 0.33596122 -0.52018946]\n",
            " [ 0.43182945 -0.42680132]\n",
            " [ 0.36757562 -0.51329696]\n",
            " [ 0.40087995 -0.47928134]]\n",
            "Labels:[1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0]\n",
            "Logits_each:tensor([[ 0.4737, -0.4470],\n",
            "        [ 0.4908, -0.4525],\n",
            "        [ 0.3997, -0.4402],\n",
            "        [ 0.3221, -0.4444],\n",
            "        [ 0.4061, -0.5188],\n",
            "        [ 0.4535, -0.4756],\n",
            "        [ 0.4179, -0.4667],\n",
            "        [ 0.4356, -0.4614],\n",
            "        [ 0.4474, -0.4220],\n",
            "        [ 0.4050, -0.4814],\n",
            "        [ 0.4111, -0.4748],\n",
            "        [ 0.4503, -0.4461],\n",
            "        [ 0.4924, -0.4848],\n",
            "        [ 0.4427, -0.4036],\n",
            "        [ 0.3750, -0.4594],\n",
            "        [ 0.3930, -0.4654],\n",
            "        [ 0.4686, -0.4263],\n",
            "        [ 0.4024, -0.4866],\n",
            "        [ 0.4541, -0.4430],\n",
            "        [ 0.4726, -0.4328],\n",
            "        [ 0.5008, -0.4418],\n",
            "        [ 0.3689, -0.4173],\n",
            "        [ 0.3427, -0.4627],\n",
            "        [ 0.4474, -0.4527],\n",
            "        [ 0.4412, -0.4119],\n",
            "        [ 0.3421, -0.4107],\n",
            "        [ 0.3548, -0.4069],\n",
            "        [ 0.4692, -0.4464],\n",
            "        [ 0.3490, -0.3988],\n",
            "        [ 0.4268, -0.4861],\n",
            "        [ 0.4023, -0.4261],\n",
            "        [ 0.4023, -0.4261]], device='cuda:0')\n",
            "Logits:[[ 0.47365138 -0.44702017]\n",
            " [ 0.49083683 -0.45253888]\n",
            " [ 0.39969125 -0.4402224 ]\n",
            " [ 0.32205442 -0.44443664]\n",
            " [ 0.40606394 -0.51882577]\n",
            " [ 0.45353776 -0.47559667]\n",
            " [ 0.4179131  -0.4666817 ]\n",
            " [ 0.43560463 -0.46144208]\n",
            " [ 0.44738713 -0.42203736]\n",
            " [ 0.4049966  -0.48140097]\n",
            " [ 0.41112885 -0.47484842]\n",
            " [ 0.4503229  -0.44609836]\n",
            " [ 0.49241984 -0.48484737]\n",
            " [ 0.4427171  -0.4036241 ]\n",
            " [ 0.37495676 -0.45936742]\n",
            " [ 0.39302635 -0.4654128 ]\n",
            " [ 0.46855065 -0.42634565]\n",
            " [ 0.4023911  -0.4865627 ]\n",
            " [ 0.45409206 -0.44304857]\n",
            " [ 0.47261813 -0.43276927]\n",
            " [ 0.5007998  -0.44178864]\n",
            " [ 0.36887282 -0.41725448]\n",
            " [ 0.34273535 -0.46271843]\n",
            " [ 0.44744173 -0.45270798]\n",
            " [ 0.44121125 -0.41190037]\n",
            " [ 0.34208784 -0.41067597]\n",
            " [ 0.3547792  -0.40693754]\n",
            " [ 0.4692332  -0.44639084]\n",
            " [ 0.34901196 -0.39883336]\n",
            " [ 0.42680854 -0.48605773]\n",
            " [ 0.40232137 -0.4261395 ]\n",
            " [ 0.40232137 -0.4261395 ]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3717, -0.5046],\n",
            "        [ 0.4642, -0.5051],\n",
            "        [ 0.5046, -0.4352],\n",
            "        [ 0.3586, -0.3824],\n",
            "        [ 0.3764, -0.4758],\n",
            "        [ 0.3822, -0.4558],\n",
            "        [ 0.3822, -0.4558],\n",
            "        [ 0.4051, -0.4390],\n",
            "        [ 0.3904, -0.4625],\n",
            "        [ 0.4604, -0.4986],\n",
            "        [ 0.2180, -0.5202],\n",
            "        [ 0.2908, -0.5209],\n",
            "        [ 0.3802, -0.4081],\n",
            "        [ 0.3889, -0.3954],\n",
            "        [ 0.3710, -0.4851],\n",
            "        [ 0.3587, -0.4950],\n",
            "        [ 0.3990, -0.4918],\n",
            "        [ 0.4244, -0.4457],\n",
            "        [ 0.3810, -0.5612],\n",
            "        [ 0.3520, -0.5159],\n",
            "        [ 0.2501, -0.5756],\n",
            "        [ 0.3913, -0.4804],\n",
            "        [ 0.3945, -0.4279],\n",
            "        [ 0.3949, -0.5795],\n",
            "        [ 0.3757, -0.5989],\n",
            "        [ 0.4463, -0.4942],\n",
            "        [ 0.4363, -0.5574],\n",
            "        [ 0.3670, -0.5537],\n",
            "        [ 0.3491, -0.5794],\n",
            "        [ 0.4070, -0.5176],\n",
            "        [ 0.2256, -0.5712],\n",
            "        [ 0.3866, -0.5343]], device='cuda:0')\n",
            "Logits:[[ 0.37173656 -0.50458354]\n",
            " [ 0.46419436 -0.5050505 ]\n",
            " [ 0.50462264 -0.4351948 ]\n",
            " [ 0.3585951  -0.38239884]\n",
            " [ 0.37637132 -0.47580346]\n",
            " [ 0.3821675  -0.45577437]\n",
            " [ 0.3821675  -0.45577437]\n",
            " [ 0.405111   -0.438986  ]\n",
            " [ 0.39039233 -0.46247607]\n",
            " [ 0.46039617 -0.49857542]\n",
            " [ 0.21798661 -0.5202311 ]\n",
            " [ 0.29078445 -0.52091604]\n",
            " [ 0.38022268 -0.40805537]\n",
            " [ 0.38886184 -0.3953918 ]\n",
            " [ 0.37097254 -0.48509693]\n",
            " [ 0.35869327 -0.49502623]\n",
            " [ 0.39903244 -0.4917964 ]\n",
            " [ 0.42439592 -0.4456946 ]\n",
            " [ 0.38103956 -0.56115896]\n",
            " [ 0.35198137 -0.5158505 ]\n",
            " [ 0.2500682  -0.5756311 ]\n",
            " [ 0.39129466 -0.48043823]\n",
            " [ 0.39446306 -0.42785737]\n",
            " [ 0.39485568 -0.57950526]\n",
            " [ 0.3757325  -0.5989182 ]\n",
            " [ 0.44630736 -0.49424633]\n",
            " [ 0.43626857 -0.5574333 ]\n",
            " [ 0.36704525 -0.5537098 ]\n",
            " [ 0.3490743  -0.5794021 ]\n",
            " [ 0.40696898 -0.5175746 ]\n",
            " [ 0.22561441 -0.5712026 ]\n",
            " [ 0.38663462 -0.53429675]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4409, -0.5334],\n",
            "        [ 0.3543, -0.5949],\n",
            "        [ 0.4261, -0.5745],\n",
            "        [ 0.4060, -0.5197],\n",
            "        [ 0.3594, -0.5479],\n",
            "        [ 0.4430, -0.3649],\n",
            "        [ 0.4578, -0.4665],\n",
            "        [ 0.3775, -0.5743],\n",
            "        [ 0.4774, -0.4817],\n",
            "        [ 0.4953, -0.4941],\n",
            "        [ 0.4009, -0.5159],\n",
            "        [ 0.5039, -0.4967],\n",
            "        [ 0.4652, -0.4946],\n",
            "        [ 0.4230, -0.4733],\n",
            "        [ 0.3959, -0.4798],\n",
            "        [ 0.3974, -0.4402],\n",
            "        [ 0.3740, -0.4362],\n",
            "        [ 0.3832, -0.5865],\n",
            "        [ 0.4513, -0.5857],\n",
            "        [ 0.4053, -0.6272],\n",
            "        [ 0.4298, -0.5766],\n",
            "        [ 0.4298, -0.5766],\n",
            "        [ 0.3432, -0.6143],\n",
            "        [ 0.3759, -0.5912],\n",
            "        [ 0.3232, -0.5745],\n",
            "        [ 0.4392, -0.5802],\n",
            "        [ 0.4367, -0.5036],\n",
            "        [ 0.4392, -0.5802],\n",
            "        [ 0.4699, -0.4066],\n",
            "        [ 0.4490, -0.4167],\n",
            "        [ 0.3799, -0.3739],\n",
            "        [ 0.4892, -0.4196]], device='cuda:0')\n",
            "Logits:[[ 0.44091883 -0.5333885 ]\n",
            " [ 0.35433498 -0.5948869 ]\n",
            " [ 0.4260788  -0.5745077 ]\n",
            " [ 0.40599146 -0.5197283 ]\n",
            " [ 0.35944223 -0.5478898 ]\n",
            " [ 0.4430495  -0.36493352]\n",
            " [ 0.45781085 -0.4665196 ]\n",
            " [ 0.37750357 -0.5742878 ]\n",
            " [ 0.4773979  -0.48165628]\n",
            " [ 0.4953325  -0.49413294]\n",
            " [ 0.40090397 -0.51589596]\n",
            " [ 0.5038814  -0.4967377 ]\n",
            " [ 0.46519947 -0.4946278 ]\n",
            " [ 0.42296118 -0.47333613]\n",
            " [ 0.3958804  -0.47983688]\n",
            " [ 0.39736512 -0.44019687]\n",
            " [ 0.37399977 -0.43616349]\n",
            " [ 0.3831861  -0.58645046]\n",
            " [ 0.4512817  -0.5857211 ]\n",
            " [ 0.4053036  -0.6272282 ]\n",
            " [ 0.4297945  -0.57661366]\n",
            " [ 0.4297945  -0.57661366]\n",
            " [ 0.3431796  -0.61432445]\n",
            " [ 0.37593448 -0.59118557]\n",
            " [ 0.32321507 -0.5744762 ]\n",
            " [ 0.4392095  -0.5801873 ]\n",
            " [ 0.43667138 -0.5035834 ]\n",
            " [ 0.4392095  -0.5801873 ]\n",
            " [ 0.4698872  -0.40657344]\n",
            " [ 0.44897944 -0.41671628]\n",
            " [ 0.37986267 -0.37389374]\n",
            " [ 0.48915243 -0.41961497]]\n",
            "Labels:[0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Logits_each:tensor([[ 0.4180, -0.3844],\n",
            "        [ 0.4466, -0.4043],\n",
            "        [ 0.4607, -0.3927],\n",
            "        [ 0.4976, -0.4168],\n",
            "        [ 0.4847, -0.4143],\n",
            "        [ 0.4766, -0.4593],\n",
            "        [ 0.4591, -0.3921],\n",
            "        [ 0.4545, -0.4062],\n",
            "        [ 0.4886, -0.4093],\n",
            "        [ 0.4586, -0.4251],\n",
            "        [ 0.4121, -0.4351],\n",
            "        [ 0.4795, -0.4270],\n",
            "        [ 0.4066, -0.4031],\n",
            "        [ 0.3791, -0.4213],\n",
            "        [ 0.3141, -0.2248],\n",
            "        [ 0.4429, -0.4214],\n",
            "        [ 0.4879, -0.4607],\n",
            "        [ 0.3483, -0.4282],\n",
            "        [ 0.2958, -0.2047],\n",
            "        [ 0.4081, -0.4356],\n",
            "        [ 0.4243, -0.3905],\n",
            "        [ 0.4460, -0.4065],\n",
            "        [ 0.3874, -0.4207],\n",
            "        [ 0.3359, -0.3714],\n",
            "        [ 0.3359, -0.3714],\n",
            "        [ 0.4780, -0.4656],\n",
            "        [ 0.4006, -0.4086],\n",
            "        [ 0.4299, -0.3858],\n",
            "        [ 0.4084, -0.4242],\n",
            "        [ 0.4158, -0.4820],\n",
            "        [ 0.0674,  0.1532],\n",
            "        [ 0.3791, -0.4463]], device='cuda:0')\n",
            "Logits:[[ 0.41799816 -0.38439238]\n",
            " [ 0.4465617  -0.40425175]\n",
            " [ 0.46074718 -0.39269435]\n",
            " [ 0.49755907 -0.41684473]\n",
            " [ 0.48472583 -0.41428515]\n",
            " [ 0.47663307 -0.45927685]\n",
            " [ 0.45911232 -0.3921203 ]\n",
            " [ 0.4544821  -0.4061887 ]\n",
            " [ 0.48860437 -0.4092579 ]\n",
            " [ 0.45859575 -0.4251214 ]\n",
            " [ 0.41210073 -0.43506142]\n",
            " [ 0.479462   -0.4270067 ]\n",
            " [ 0.4066296  -0.4031315 ]\n",
            " [ 0.37906185 -0.4212868 ]\n",
            " [ 0.31412536 -0.2248357 ]\n",
            " [ 0.4429435  -0.42141548]\n",
            " [ 0.4878522  -0.4607399 ]\n",
            " [ 0.34827256 -0.42821088]\n",
            " [ 0.2957759  -0.20471942]\n",
            " [ 0.40811154 -0.43557388]\n",
            " [ 0.42425078 -0.39048684]\n",
            " [ 0.44595695 -0.40648264]\n",
            " [ 0.38744947 -0.42069423]\n",
            " [ 0.33587718 -0.37143773]\n",
            " [ 0.33587718 -0.37143773]\n",
            " [ 0.47804794 -0.4655935 ]\n",
            " [ 0.4005787  -0.4085625 ]\n",
            " [ 0.42987412 -0.38582805]\n",
            " [ 0.40836245 -0.42418933]\n",
            " [ 0.4157797  -0.48202553]\n",
            " [ 0.06741337  0.1532328 ]\n",
            " [ 0.37910128 -0.44630897]]\n",
            "Labels:[1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4297, -0.5190],\n",
            "        [ 0.4487, -0.3395],\n",
            "        [ 0.3487, -0.4749],\n",
            "        [ 0.3852, -0.3909],\n",
            "        [ 0.4019, -0.4741],\n",
            "        [ 0.3944, -0.4019],\n",
            "        [ 0.4431, -0.4783],\n",
            "        [ 0.3504, -0.4586],\n",
            "        [ 0.4533, -0.4759],\n",
            "        [ 0.3168, -0.4055],\n",
            "        [ 0.3168, -0.4055],\n",
            "        [ 0.3081, -0.3867],\n",
            "        [ 0.3168, -0.4055],\n",
            "        [ 0.3679, -0.3837],\n",
            "        [ 0.5210, -0.5006],\n",
            "        [ 0.3644, -0.4649],\n",
            "        [ 0.3658, -0.4568],\n",
            "        [ 0.4258, -0.4845],\n",
            "        [ 0.3957, -0.4325],\n",
            "        [ 0.3860, -0.4444],\n",
            "        [ 0.4600, -0.5259],\n",
            "        [ 0.3921, -0.4360],\n",
            "        [ 0.3396, -0.4424],\n",
            "        [ 0.3104, -0.4032],\n",
            "        [ 0.4011, -0.5100],\n",
            "        [ 0.3920, -0.4867],\n",
            "        [ 0.3724, -0.4173],\n",
            "        [ 0.3699, -0.5151],\n",
            "        [ 0.3293, -0.4409],\n",
            "        [ 0.3183, -0.5036],\n",
            "        [ 0.3320, -0.5915],\n",
            "        [ 0.3066, -0.5027]], device='cuda:0')\n",
            "Logits:[[ 0.42970484 -0.51897556]\n",
            " [ 0.4486738  -0.33951366]\n",
            " [ 0.34867093 -0.47487307]\n",
            " [ 0.38516775 -0.3909041 ]\n",
            " [ 0.4019291  -0.47411966]\n",
            " [ 0.39443353 -0.40189078]\n",
            " [ 0.44307682 -0.47826096]\n",
            " [ 0.35038674 -0.45860606]\n",
            " [ 0.45325285 -0.4758799 ]\n",
            " [ 0.3167961  -0.40553242]\n",
            " [ 0.3167961  -0.40553242]\n",
            " [ 0.30814564 -0.3866526 ]\n",
            " [ 0.3167961  -0.40553242]\n",
            " [ 0.36789435 -0.38365465]\n",
            " [ 0.5210444  -0.50063795]\n",
            " [ 0.36435682 -0.4648945 ]\n",
            " [ 0.36575374 -0.4567844 ]\n",
            " [ 0.42577147 -0.48453546]\n",
            " [ 0.39567488 -0.432544  ]\n",
            " [ 0.3859888  -0.4443864 ]\n",
            " [ 0.4600406  -0.5258954 ]\n",
            " [ 0.39209628 -0.43600884]\n",
            " [ 0.3396354  -0.4423776 ]\n",
            " [ 0.31041357 -0.40315178]\n",
            " [ 0.4011169  -0.50995266]\n",
            " [ 0.39198625 -0.48674622]\n",
            " [ 0.3723653  -0.41727784]\n",
            " [ 0.3698562  -0.51507556]\n",
            " [ 0.3292605  -0.44089305]\n",
            " [ 0.31834653 -0.5036071 ]\n",
            " [ 0.33200875 -0.59150153]\n",
            " [ 0.30661085 -0.50268865]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3320, -0.5400],\n",
            "        [ 0.4811, -0.4480],\n",
            "        [ 0.3700, -0.4961],\n",
            "        [ 0.3697, -0.4607],\n",
            "        [ 0.3542, -0.5067],\n",
            "        [ 0.3602, -0.4743],\n",
            "        [ 0.3109, -0.3068],\n",
            "        [ 0.3675, -0.4169],\n",
            "        [ 0.3500, -0.5024],\n",
            "        [ 0.3365, -0.5363],\n",
            "        [ 0.4100, -0.4703],\n",
            "        [ 0.3648, -0.5076],\n",
            "        [ 0.3738, -0.4658],\n",
            "        [ 0.4110, -0.4400],\n",
            "        [ 0.3272, -0.5599],\n",
            "        [ 0.3777, -0.4235],\n",
            "        [ 0.4051, -0.4786],\n",
            "        [ 0.3772, -0.4754],\n",
            "        [ 0.3114, -0.4012],\n",
            "        [ 0.3182, -0.4565],\n",
            "        [ 0.3141, -0.4535],\n",
            "        [ 0.3286, -0.3476],\n",
            "        [ 0.2877, -0.4553],\n",
            "        [ 0.2877, -0.4553],\n",
            "        [ 0.2877, -0.4553],\n",
            "        [ 0.2877, -0.4553],\n",
            "        [ 0.3604, -0.4336],\n",
            "        [ 0.3541, -0.4615],\n",
            "        [ 0.3322, -0.4233],\n",
            "        [ 0.2879, -0.4412],\n",
            "        [ 0.0870,  0.0548],\n",
            "        [ 0.1223,  0.0187]], device='cuda:0')\n",
            "Logits:[[ 0.33201563 -0.5399592 ]\n",
            " [ 0.48109132 -0.44797325]\n",
            " [ 0.36998227 -0.49608988]\n",
            " [ 0.36970946 -0.46073002]\n",
            " [ 0.35421482 -0.50666666]\n",
            " [ 0.36020488 -0.4742502 ]\n",
            " [ 0.31086275 -0.30678487]\n",
            " [ 0.36750814 -0.41691336]\n",
            " [ 0.34995386 -0.5023983 ]\n",
            " [ 0.33653432 -0.53631586]\n",
            " [ 0.40996823 -0.4703167 ]\n",
            " [ 0.3648425  -0.50759983]\n",
            " [ 0.37383032 -0.46584755]\n",
            " [ 0.41099522 -0.43998975]\n",
            " [ 0.32724017 -0.5598903 ]\n",
            " [ 0.3776997  -0.42350018]\n",
            " [ 0.40507394 -0.47857314]\n",
            " [ 0.37717372 -0.47537196]\n",
            " [ 0.3113541  -0.40115792]\n",
            " [ 0.3181794  -0.4564668 ]\n",
            " [ 0.31408677 -0.45348474]\n",
            " [ 0.32859573 -0.3475982 ]\n",
            " [ 0.28765383 -0.4552718 ]\n",
            " [ 0.28765383 -0.4552718 ]\n",
            " [ 0.28765383 -0.4552718 ]\n",
            " [ 0.28765383 -0.4552718 ]\n",
            " [ 0.3604116  -0.43359527]\n",
            " [ 0.3540668  -0.46146822]\n",
            " [ 0.33222222 -0.42327338]\n",
            " [ 0.28786603 -0.44117945]\n",
            " [ 0.08698175  0.05483728]\n",
            " [ 0.1222505   0.01870257]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4173, -0.4370],\n",
            "        [ 0.2750, -0.4698],\n",
            "        [ 0.4251, -0.4192],\n",
            "        [ 0.3106, -0.4283],\n",
            "        [ 0.3651, -0.4607],\n",
            "        [ 0.3645, -0.4105],\n",
            "        [ 0.3936, -0.4294],\n",
            "        [ 0.3125, -0.3898],\n",
            "        [ 0.3028, -0.4217],\n",
            "        [ 0.3028, -0.4217],\n",
            "        [ 0.3028, -0.4217],\n",
            "        [ 0.4434, -0.4680],\n",
            "        [ 0.4675, -0.4327],\n",
            "        [ 0.4438, -0.4168],\n",
            "        [ 0.3274, -0.3883],\n",
            "        [ 0.3501, -0.5007],\n",
            "        [ 0.2861, -0.4056],\n",
            "        [ 0.4030, -0.4940],\n",
            "        [ 0.3663, -0.3681],\n",
            "        [ 0.3960, -0.3742],\n",
            "        [ 0.4925, -0.4354],\n",
            "        [ 0.3278, -0.4706],\n",
            "        [ 0.3890, -0.5435],\n",
            "        [ 0.4181, -0.5201],\n",
            "        [ 0.4401, -0.5243],\n",
            "        [ 0.3828, -0.4931],\n",
            "        [ 0.4047, -0.5178],\n",
            "        [ 0.4627, -0.5290],\n",
            "        [ 0.4421, -0.5757],\n",
            "        [ 0.4486, -0.5027],\n",
            "        [ 0.4301, -0.4541],\n",
            "        [ 0.5319, -0.4811]], device='cuda:0')\n",
            "Logits:[[ 0.41728106 -0.43695235]\n",
            " [ 0.2749536  -0.46977127]\n",
            " [ 0.4251403  -0.41923568]\n",
            " [ 0.3105825  -0.4283023 ]\n",
            " [ 0.36514893 -0.46069452]\n",
            " [ 0.36451483 -0.4104517 ]\n",
            " [ 0.393578   -0.42937893]\n",
            " [ 0.31249815 -0.3897718 ]\n",
            " [ 0.30277792 -0.42168248]\n",
            " [ 0.30277792 -0.42168248]\n",
            " [ 0.30277792 -0.42168248]\n",
            " [ 0.4434445  -0.4679618 ]\n",
            " [ 0.46754214 -0.4327448 ]\n",
            " [ 0.44384137 -0.41681325]\n",
            " [ 0.32742321 -0.38830286]\n",
            " [ 0.35005888 -0.500663  ]\n",
            " [ 0.2861038  -0.4056331 ]\n",
            " [ 0.4030008  -0.4940426 ]\n",
            " [ 0.36630094 -0.36809   ]\n",
            " [ 0.3960132  -0.37424105]\n",
            " [ 0.49250427 -0.43540186]\n",
            " [ 0.32776645 -0.47062892]\n",
            " [ 0.3890239  -0.5434857 ]\n",
            " [ 0.4181223  -0.5201481 ]\n",
            " [ 0.44011426 -0.5243078 ]\n",
            " [ 0.38278586 -0.49311733]\n",
            " [ 0.40465894 -0.5177703 ]\n",
            " [ 0.46272656 -0.5289722 ]\n",
            " [ 0.4420648  -0.5756743 ]\n",
            " [ 0.4485992  -0.5026772 ]\n",
            " [ 0.43009564 -0.45412531]\n",
            " [ 0.53188276 -0.48107865]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1]\n",
            "Logits_each:tensor([[ 0.1668, -0.6184],\n",
            "        [ 0.1756, -0.5901],\n",
            "        [ 0.1756, -0.5901],\n",
            "        [ 0.0234, -0.1222],\n",
            "        [ 0.2774, -0.5479],\n",
            "        [ 0.0121, -0.3777],\n",
            "        [ 0.0487, -0.1838],\n",
            "        [ 0.2806, -0.5133],\n",
            "        [ 0.4803, -0.4999],\n",
            "        [ 0.4855, -0.5239],\n",
            "        [ 0.3109, -0.5034],\n",
            "        [ 0.3030, -0.5137],\n",
            "        [ 0.3482, -0.4507],\n",
            "        [ 0.2073, -0.5658],\n",
            "        [ 0.3508, -0.4875],\n",
            "        [ 0.2745, -0.5078],\n",
            "        [ 0.2605, -0.5146],\n",
            "        [ 0.4389, -0.5035],\n",
            "        [ 0.4427, -0.5309],\n",
            "        [ 0.3751, -0.4897],\n",
            "        [ 0.3368, -0.5212],\n",
            "        [ 0.2641, -0.5501],\n",
            "        [ 0.2641, -0.5501],\n",
            "        [ 0.2641, -0.5501],\n",
            "        [ 0.2184, -0.5986],\n",
            "        [ 0.2184, -0.5986],\n",
            "        [ 0.2426, -0.5769],\n",
            "        [ 0.3924, -0.5585],\n",
            "        [ 0.2265, -0.6407],\n",
            "        [ 0.1652, -0.4608],\n",
            "        [ 0.3464, -0.5468],\n",
            "        [ 0.4011, -0.5114]], device='cuda:0')\n",
            "Logits:[[ 0.16677724 -0.6183602 ]\n",
            " [ 0.17558032 -0.5901066 ]\n",
            " [ 0.17558032 -0.5901066 ]\n",
            " [ 0.02340464 -0.12215655]\n",
            " [ 0.27740845 -0.5478738 ]\n",
            " [ 0.01214095 -0.37765756]\n",
            " [ 0.04872096 -0.18378742]\n",
            " [ 0.2805753  -0.5133176 ]\n",
            " [ 0.48026487 -0.49991375]\n",
            " [ 0.48554808 -0.523929  ]\n",
            " [ 0.31093222 -0.50337934]\n",
            " [ 0.30300453 -0.5136593 ]\n",
            " [ 0.34816542 -0.4507399 ]\n",
            " [ 0.2073028  -0.5657977 ]\n",
            " [ 0.3507562  -0.48754776]\n",
            " [ 0.27454138 -0.5077748 ]\n",
            " [ 0.26054874 -0.51460624]\n",
            " [ 0.4389011  -0.5034752 ]\n",
            " [ 0.44268522 -0.53090197]\n",
            " [ 0.37513506 -0.4897383 ]\n",
            " [ 0.3367784  -0.5212404 ]\n",
            " [ 0.26408818 -0.5500824 ]\n",
            " [ 0.26408818 -0.5500824 ]\n",
            " [ 0.26408818 -0.5500824 ]\n",
            " [ 0.21840847 -0.5986302 ]\n",
            " [ 0.21840847 -0.5986302 ]\n",
            " [ 0.24263918 -0.5769235 ]\n",
            " [ 0.3924089  -0.5585428 ]\n",
            " [ 0.226549   -0.64068   ]\n",
            " [ 0.16516984 -0.46075225]\n",
            " [ 0.34639487 -0.5467548 ]\n",
            " [ 0.40110278 -0.5113641 ]]\n",
            "Labels:[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4102, -0.5104],\n",
            "        [ 0.3821, -0.5351],\n",
            "        [ 0.4113, -0.5077],\n",
            "        [ 0.4342, -0.4223],\n",
            "        [ 0.4321, -0.5267],\n",
            "        [ 0.4139, -0.5414],\n",
            "        [ 0.3983, -0.5093],\n",
            "        [ 0.3200, -0.5075],\n",
            "        [ 0.4613, -0.5673],\n",
            "        [ 0.3735, -0.5389],\n",
            "        [ 0.4464, -0.5013],\n",
            "        [ 0.3747, -0.3756],\n",
            "        [ 0.4171, -0.3242],\n",
            "        [ 0.3785, -0.3867],\n",
            "        [ 0.3859, -0.3410],\n",
            "        [ 0.3984, -0.3420],\n",
            "        [ 0.3840, -0.4092],\n",
            "        [ 0.4138, -0.3942],\n",
            "        [ 0.3281, -0.4311],\n",
            "        [ 0.3941, -0.3948],\n",
            "        [ 0.4391, -0.3953],\n",
            "        [ 0.4391, -0.3953],\n",
            "        [ 0.3994, -0.3761],\n",
            "        [ 0.4921, -0.4769],\n",
            "        [ 0.3558, -0.4617],\n",
            "        [ 0.4126, -0.4366],\n",
            "        [ 0.4543, -0.4262],\n",
            "        [ 0.4442, -0.4682],\n",
            "        [ 0.4858, -0.3970],\n",
            "        [ 0.3335, -0.4458],\n",
            "        [ 0.4281, -0.4370],\n",
            "        [ 0.4346, -0.4458]], device='cuda:0')\n",
            "Logits:[[ 0.41016448 -0.5103881 ]\n",
            " [ 0.38212913 -0.53510934]\n",
            " [ 0.41128626 -0.5076853 ]\n",
            " [ 0.4341538  -0.42226192]\n",
            " [ 0.43210474 -0.526678  ]\n",
            " [ 0.41390815 -0.5414067 ]\n",
            " [ 0.39832956 -0.509305  ]\n",
            " [ 0.31996968 -0.5074727 ]\n",
            " [ 0.46127263 -0.56726897]\n",
            " [ 0.3734952  -0.53890336]\n",
            " [ 0.4464004  -0.5012503 ]\n",
            " [ 0.3746623  -0.37563467]\n",
            " [ 0.41712305 -0.32415798]\n",
            " [ 0.3785443  -0.38666356]\n",
            " [ 0.38590103 -0.34099835]\n",
            " [ 0.39844698 -0.3419796 ]\n",
            " [ 0.38400915 -0.40917215]\n",
            " [ 0.41377705 -0.39424893]\n",
            " [ 0.32809874 -0.43111354]\n",
            " [ 0.39407963 -0.3947623 ]\n",
            " [ 0.43911803 -0.3952705 ]\n",
            " [ 0.43911803 -0.3952705 ]\n",
            " [ 0.39937797 -0.37612954]\n",
            " [ 0.4920685  -0.47688258]\n",
            " [ 0.35582894 -0.46165454]\n",
            " [ 0.4125988  -0.43664503]\n",
            " [ 0.4542594  -0.42616186]\n",
            " [ 0.444153   -0.46816292]\n",
            " [ 0.48577523 -0.3970193 ]\n",
            " [ 0.3334793  -0.4458034 ]\n",
            " [ 0.42807412 -0.43703458]\n",
            " [ 0.43458533 -0.44582313]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4033, -0.4165],\n",
            "        [ 0.4244, -0.4889],\n",
            "        [ 0.3835, -0.4936],\n",
            "        [ 0.4062, -0.4228],\n",
            "        [ 0.2660, -0.4625],\n",
            "        [ 0.5584, -0.4472],\n",
            "        [ 0.4439, -0.4591],\n",
            "        [ 0.2727, -0.4605],\n",
            "        [ 0.4972, -0.4506],\n",
            "        [ 0.3304, -0.4049],\n",
            "        [ 0.4288, -0.4500],\n",
            "        [ 0.3818, -0.4293],\n",
            "        [ 0.3983, -0.4707],\n",
            "        [ 0.3849, -0.4266],\n",
            "        [ 0.3518, -0.4145],\n",
            "        [ 0.3693, -0.4285],\n",
            "        [ 0.3646, -0.4543],\n",
            "        [ 0.4334, -0.4287],\n",
            "        [ 0.3806, -0.5081],\n",
            "        [ 0.3833, -0.4316],\n",
            "        [ 0.3547, -0.4635],\n",
            "        [ 0.3817, -0.4544],\n",
            "        [ 0.4432, -0.5282],\n",
            "        [ 0.3696, -0.4715],\n",
            "        [ 0.4244, -0.3874],\n",
            "        [ 0.5717, -0.4416],\n",
            "        [ 0.4352, -0.4636],\n",
            "        [ 0.4352, -0.4636],\n",
            "        [ 0.3651, -0.5111],\n",
            "        [ 0.5212, -0.4711],\n",
            "        [ 0.1950, -0.5543],\n",
            "        [ 0.4839, -0.4436]], device='cuda:0')\n",
            "Logits:[[ 0.40326685 -0.41651878]\n",
            " [ 0.4244024  -0.48892835]\n",
            " [ 0.38354525 -0.4936231 ]\n",
            " [ 0.40621206 -0.42284113]\n",
            " [ 0.26601213 -0.46250814]\n",
            " [ 0.55837315 -0.4472255 ]\n",
            " [ 0.44386172 -0.45909494]\n",
            " [ 0.27269813 -0.46053725]\n",
            " [ 0.49720263 -0.45062828]\n",
            " [ 0.3304488  -0.40493414]\n",
            " [ 0.4288088  -0.44997984]\n",
            " [ 0.38175833 -0.42929432]\n",
            " [ 0.39830184 -0.47070006]\n",
            " [ 0.3848872  -0.42657652]\n",
            " [ 0.3518165  -0.4145326 ]\n",
            " [ 0.36932445 -0.42850244]\n",
            " [ 0.3646447  -0.45429662]\n",
            " [ 0.43342116 -0.4287177 ]\n",
            " [ 0.38056976 -0.50814915]\n",
            " [ 0.3832939  -0.4316335 ]\n",
            " [ 0.3546667  -0.46351075]\n",
            " [ 0.38173285 -0.45438787]\n",
            " [ 0.44316256 -0.5282443 ]\n",
            " [ 0.3696032  -0.47152355]\n",
            " [ 0.42443362 -0.38738883]\n",
            " [ 0.57171685 -0.44161013]\n",
            " [ 0.43520337 -0.46363956]\n",
            " [ 0.43520337 -0.46363956]\n",
            " [ 0.3651168  -0.51112944]\n",
            " [ 0.5211929  -0.47114924]\n",
            " [ 0.19499053 -0.55427516]\n",
            " [ 0.48394057 -0.4435856 ]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
            "Logits_each:tensor([[ 0.3873, -0.4482],\n",
            "        [ 0.4451, -0.4321],\n",
            "        [ 0.3775, -0.5236],\n",
            "        [ 0.3847, -0.4503],\n",
            "        [ 0.3069, -0.5051],\n",
            "        [ 0.3777, -0.5093],\n",
            "        [ 0.4139, -0.5238],\n",
            "        [ 0.4716, -0.4176],\n",
            "        [ 0.3883, -0.5473],\n",
            "        [ 0.3818, -0.4454],\n",
            "        [ 0.4915, -0.4967],\n",
            "        [ 0.4781, -0.4973],\n",
            "        [ 0.3700, -0.5239],\n",
            "        [ 0.5187, -0.4979],\n",
            "        [ 0.5032, -0.4618],\n",
            "        [ 0.2349, -0.5805],\n",
            "        [ 0.4936, -0.4921],\n",
            "        [ 0.2651, -0.5398],\n",
            "        [ 0.4230, -0.4492],\n",
            "        [ 0.4373, -0.4407],\n",
            "        [ 0.3939, -0.4250],\n",
            "        [ 0.3716, -0.5181],\n",
            "        [ 0.4328, -0.4752],\n",
            "        [ 0.2929, -0.5266],\n",
            "        [ 0.3778, -0.5047],\n",
            "        [ 0.4477, -0.5361],\n",
            "        [ 0.4877, -0.4972],\n",
            "        [ 0.3166, -0.4685],\n",
            "        [ 0.3718, -0.5499],\n",
            "        [ 0.3416, -0.5093],\n",
            "        [ 0.3088, -0.5510],\n",
            "        [ 0.3912, -0.5017]], device='cuda:0')\n",
            "Logits:[[ 0.3872564  -0.4481736 ]\n",
            " [ 0.44505972 -0.4320968 ]\n",
            " [ 0.37747884 -0.5236323 ]\n",
            " [ 0.3846809  -0.4503091 ]\n",
            " [ 0.30691308 -0.5051316 ]\n",
            " [ 0.3777187  -0.5092906 ]\n",
            " [ 0.4138897  -0.5238207 ]\n",
            " [ 0.47155392 -0.41764215]\n",
            " [ 0.3883196  -0.54731876]\n",
            " [ 0.38179964 -0.445427  ]\n",
            " [ 0.49153525 -0.49670312]\n",
            " [ 0.47807837 -0.49733126]\n",
            " [ 0.3700463  -0.5239401 ]\n",
            " [ 0.5187093  -0.497907  ]\n",
            " [ 0.5032333  -0.4618226 ]\n",
            " [ 0.23493814 -0.58048195]\n",
            " [ 0.49359915 -0.49210465]\n",
            " [ 0.26505426 -0.5397969 ]\n",
            " [ 0.42296734 -0.44915655]\n",
            " [ 0.43728694 -0.44069356]\n",
            " [ 0.3939415  -0.4250339 ]\n",
            " [ 0.37156412 -0.51809883]\n",
            " [ 0.43282858 -0.47517246]\n",
            " [ 0.29294452 -0.5266221 ]\n",
            " [ 0.37783208 -0.5046576 ]\n",
            " [ 0.44773307 -0.5361155 ]\n",
            " [ 0.4877461  -0.49720764]\n",
            " [ 0.31655717 -0.46853286]\n",
            " [ 0.371838   -0.54989594]\n",
            " [ 0.34159526 -0.50930053]\n",
            " [ 0.30883703 -0.551046  ]\n",
            " [ 0.39120814 -0.50171006]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1]\n",
            "Logits_each:tensor([[ 0.3449, -0.5086],\n",
            "        [ 0.2316, -0.3623],\n",
            "        [ 0.2382, -0.4291],\n",
            "        [ 0.2382, -0.4291],\n",
            "        [ 0.3609, -0.4721],\n",
            "        [ 0.3085, -0.4546],\n",
            "        [ 0.2259, -0.4556],\n",
            "        [ 0.2259, -0.4556],\n",
            "        [ 0.4124, -0.5274],\n",
            "        [ 0.2583, -0.4267],\n",
            "        [ 0.3686, -0.4843],\n",
            "        [ 0.3486, -0.3641],\n",
            "        [ 0.3021, -0.4418],\n",
            "        [ 0.3021, -0.4418],\n",
            "        [ 0.3114, -0.4844],\n",
            "        [ 0.2388, -0.4533],\n",
            "        [ 0.2595, -0.4726],\n",
            "        [ 0.2754, -0.4767],\n",
            "        [ 0.3014, -0.4297],\n",
            "        [ 0.2695, -0.5035],\n",
            "        [ 0.3508, -0.4752],\n",
            "        [ 0.3170, -0.4425],\n",
            "        [ 0.3445, -0.4292],\n",
            "        [ 0.2998, -0.4281],\n",
            "        [ 0.4335, -0.4839],\n",
            "        [ 0.4235, -0.4119],\n",
            "        [ 0.3574, -0.4670],\n",
            "        [ 0.4235, -0.4119],\n",
            "        [ 0.4235, -0.4119],\n",
            "        [ 0.4235, -0.4119],\n",
            "        [ 0.4235, -0.4119],\n",
            "        [ 0.4235, -0.4119]], device='cuda:0')\n",
            "Logits:[[ 0.3448627  -0.50862324]\n",
            " [ 0.2315533  -0.36229566]\n",
            " [ 0.23815516 -0.42912957]\n",
            " [ 0.23815516 -0.42912957]\n",
            " [ 0.36089236 -0.47206956]\n",
            " [ 0.308452   -0.45456693]\n",
            " [ 0.22587433 -0.45564324]\n",
            " [ 0.22587433 -0.45564324]\n",
            " [ 0.4123532  -0.52741814]\n",
            " [ 0.25827906 -0.4267379 ]\n",
            " [ 0.36859822 -0.48432675]\n",
            " [ 0.34861413 -0.36407024]\n",
            " [ 0.30214766 -0.44176036]\n",
            " [ 0.30214766 -0.44176036]\n",
            " [ 0.31143293 -0.48439142]\n",
            " [ 0.23884585 -0.45327115]\n",
            " [ 0.25947267 -0.4726157 ]\n",
            " [ 0.2753864  -0.4766819 ]\n",
            " [ 0.3014044  -0.42974952]\n",
            " [ 0.2694952  -0.50348026]\n",
            " [ 0.3508466  -0.47521487]\n",
            " [ 0.31703955 -0.44248238]\n",
            " [ 0.3444535  -0.42915124]\n",
            " [ 0.2998087  -0.4281028 ]\n",
            " [ 0.43353894 -0.48394403]\n",
            " [ 0.42349812 -0.41189554]\n",
            " [ 0.35744482 -0.4670181 ]\n",
            " [ 0.42349812 -0.41189554]\n",
            " [ 0.42349812 -0.41189554]\n",
            " [ 0.42349812 -0.41189554]\n",
            " [ 0.42349812 -0.41189554]\n",
            " [ 0.42349812 -0.41189554]]\n",
            "Labels:[0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0]\n",
            "Logits_each:tensor([[ 0.4235, -0.4119],\n",
            "        [ 0.4235, -0.4119],\n",
            "        [ 0.3574, -0.4670],\n",
            "        [ 0.4169, -0.4819],\n",
            "        [ 0.3782, -0.5173],\n",
            "        [ 0.3897, -0.4604],\n",
            "        [ 0.3306, -0.5175],\n",
            "        [ 0.4031, -0.4219],\n",
            "        [ 0.4031, -0.4219],\n",
            "        [ 0.4218, -0.5356],\n",
            "        [ 0.4218, -0.5356],\n",
            "        [ 0.4398, -0.5588],\n",
            "        [ 0.4566, -0.5838],\n",
            "        [ 0.4599, -0.4800],\n",
            "        [ 0.4599, -0.4800],\n",
            "        [ 0.4599, -0.4800],\n",
            "        [ 0.4198, -0.5831],\n",
            "        [ 0.3805, -0.5200],\n",
            "        [ 0.3805, -0.5200],\n",
            "        [ 0.3805, -0.5200],\n",
            "        [ 0.3553, -0.4887],\n",
            "        [ 0.4388, -0.5052],\n",
            "        [ 0.4373, -0.5370],\n",
            "        [ 0.3854, -0.5417],\n",
            "        [ 0.4248, -0.4842],\n",
            "        [ 0.3556, -0.5167],\n",
            "        [ 0.4519, -0.5077],\n",
            "        [ 0.4027, -0.5650],\n",
            "        [ 0.4027, -0.5650],\n",
            "        [ 0.3643, -0.5618],\n",
            "        [ 0.4055, -0.4942],\n",
            "        [ 0.3720, -0.5728]], device='cuda:0')\n",
            "Logits:[[ 0.42349812 -0.41189554]\n",
            " [ 0.42349812 -0.41189554]\n",
            " [ 0.35744482 -0.4670181 ]\n",
            " [ 0.41686657 -0.48194945]\n",
            " [ 0.3781609  -0.51732   ]\n",
            " [ 0.38965386 -0.46041003]\n",
            " [ 0.33063757 -0.51746315]\n",
            " [ 0.4031098  -0.4218883 ]\n",
            " [ 0.4031098  -0.4218883 ]\n",
            " [ 0.42177    -0.53557813]\n",
            " [ 0.42177    -0.53557813]\n",
            " [ 0.43983755 -0.55881006]\n",
            " [ 0.4565727  -0.58375627]\n",
            " [ 0.45991635 -0.47999972]\n",
            " [ 0.45991635 -0.47999972]\n",
            " [ 0.45991635 -0.47999972]\n",
            " [ 0.4198328  -0.5830721 ]\n",
            " [ 0.3805424  -0.519995  ]\n",
            " [ 0.3805424  -0.519995  ]\n",
            " [ 0.3805424  -0.519995  ]\n",
            " [ 0.35526147 -0.48870683]\n",
            " [ 0.43875775 -0.50519484]\n",
            " [ 0.43725428 -0.5370196 ]\n",
            " [ 0.38542497 -0.54166716]\n",
            " [ 0.4248401  -0.4842048 ]\n",
            " [ 0.35558254 -0.51670355]\n",
            " [ 0.45186123 -0.50765526]\n",
            " [ 0.4026743  -0.564969  ]\n",
            " [ 0.4026743  -0.564969  ]\n",
            " [ 0.36429593 -0.5618056 ]\n",
            " [ 0.40545872 -0.4942418 ]\n",
            " [ 0.37197506 -0.5728406 ]]\n",
            "Labels:[0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.2942, -0.5302],\n",
            "        [ 0.4488, -0.5763],\n",
            "        [ 0.4278, -0.5988],\n",
            "        [ 0.2148, -0.5335],\n",
            "        [ 0.2185, -0.5289],\n",
            "        [ 0.3110, -0.5182],\n",
            "        [ 0.3950, -0.5033],\n",
            "        [ 0.3909, -0.4164],\n",
            "        [ 0.2733, -0.4493],\n",
            "        [ 0.5082, -0.4844],\n",
            "        [ 0.3414, -0.4590],\n",
            "        [ 0.3523, -0.4201],\n",
            "        [ 0.3304, -0.5437],\n",
            "        [ 0.3848, -0.4714],\n",
            "        [ 0.3080, -0.5070],\n",
            "        [ 0.4342, -0.5017],\n",
            "        [ 0.3754, -0.4669],\n",
            "        [ 0.3165, -0.4650],\n",
            "        [ 0.3453, -0.4740],\n",
            "        [ 0.3342, -0.4851],\n",
            "        [ 0.3659, -0.4528],\n",
            "        [ 0.3919, -0.4050],\n",
            "        [ 0.3343, -0.4377],\n",
            "        [ 0.4462, -0.4715],\n",
            "        [ 0.3577, -0.4089],\n",
            "        [ 0.4180, -0.4318],\n",
            "        [ 0.3897, -0.4653],\n",
            "        [ 0.4388, -0.3422],\n",
            "        [ 0.1399,  0.0827],\n",
            "        [ 0.3898, -0.4609],\n",
            "        [ 0.4170, -0.3722],\n",
            "        [ 0.4095, -0.4839]], device='cuda:0')\n",
            "Logits:[[ 0.29423493 -0.530166  ]\n",
            " [ 0.44875357 -0.5762523 ]\n",
            " [ 0.42781964 -0.5988251 ]\n",
            " [ 0.21483625 -0.53348833]\n",
            " [ 0.21848172 -0.52894694]\n",
            " [ 0.3109513  -0.5181603 ]\n",
            " [ 0.39497218 -0.5033098 ]\n",
            " [ 0.39093158 -0.41643694]\n",
            " [ 0.27325675 -0.44933838]\n",
            " [ 0.5082233  -0.48440608]\n",
            " [ 0.34142277 -0.4590461 ]\n",
            " [ 0.35230228 -0.42011037]\n",
            " [ 0.33045    -0.54368484]\n",
            " [ 0.38484764 -0.471368  ]\n",
            " [ 0.30803335 -0.5069848 ]\n",
            " [ 0.43420288 -0.5016619 ]\n",
            " [ 0.37539765 -0.4668548 ]\n",
            " [ 0.31645757 -0.46497017]\n",
            " [ 0.34525618 -0.47398227]\n",
            " [ 0.33424193 -0.4850717 ]\n",
            " [ 0.36587587 -0.45276383]\n",
            " [ 0.39193445 -0.40502167]\n",
            " [ 0.3342707  -0.43768772]\n",
            " [ 0.44617367 -0.47149283]\n",
            " [ 0.35767442 -0.40891394]\n",
            " [ 0.4179857  -0.43183115]\n",
            " [ 0.38965818 -0.46525887]\n",
            " [ 0.43884525 -0.34216505]\n",
            " [ 0.13992925  0.08273222]\n",
            " [ 0.3898334  -0.4608822 ]\n",
            " [ 0.4170431  -0.3722114 ]\n",
            " [ 0.40946984 -0.48388457]]\n",
            "Labels:[0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3915, -0.4603],\n",
            "        [ 0.4120, -0.5456],\n",
            "        [ 0.4428, -0.4607],\n",
            "        [ 0.4455, -0.4586],\n",
            "        [ 0.3863, -0.4775],\n",
            "        [ 0.3859, -0.4677],\n",
            "        [ 0.3740, -0.4725],\n",
            "        [ 0.3740, -0.4725],\n",
            "        [ 0.4490, -0.4600],\n",
            "        [ 0.4143, -0.4393],\n",
            "        [ 0.3197, -0.4515],\n",
            "        [ 0.3717, -0.4794],\n",
            "        [ 0.3507, -0.3854],\n",
            "        [ 0.3547, -0.3787],\n",
            "        [ 0.4391, -0.4985],\n",
            "        [ 0.3522, -0.4861],\n",
            "        [ 0.4019, -0.4867],\n",
            "        [ 0.1682, -0.4774],\n",
            "        [ 0.4660, -0.5113],\n",
            "        [ 0.3779, -0.4954],\n",
            "        [ 0.3675, -0.4842],\n",
            "        [ 0.4401, -0.5055],\n",
            "        [ 0.4205, -0.4783],\n",
            "        [ 0.4434, -0.4967],\n",
            "        [ 0.3963, -0.5053],\n",
            "        [ 0.4363, -0.5013],\n",
            "        [ 0.4139, -0.4842],\n",
            "        [ 0.4139, -0.4842],\n",
            "        [ 0.4966, -0.5880],\n",
            "        [ 0.4335, -0.5241],\n",
            "        [ 0.4460, -0.5394],\n",
            "        [ 0.3944, -0.5246]], device='cuda:0')\n",
            "Logits:[[ 0.39146674 -0.46033582]\n",
            " [ 0.41204292 -0.54563123]\n",
            " [ 0.44277033 -0.4606598 ]\n",
            " [ 0.44546348 -0.45864397]\n",
            " [ 0.3862805  -0.47748652]\n",
            " [ 0.3858846  -0.46772024]\n",
            " [ 0.3740111  -0.47249526]\n",
            " [ 0.3740111  -0.47249526]\n",
            " [ 0.44898555 -0.45997378]\n",
            " [ 0.41428342 -0.43926272]\n",
            " [ 0.31971884 -0.45149866]\n",
            " [ 0.3717457  -0.4793591 ]\n",
            " [ 0.35073036 -0.38538468]\n",
            " [ 0.35469812 -0.37870553]\n",
            " [ 0.4390583  -0.49850643]\n",
            " [ 0.35215977 -0.48609844]\n",
            " [ 0.40192866 -0.48667175]\n",
            " [ 0.16817017 -0.47738418]\n",
            " [ 0.46596158 -0.5112944 ]\n",
            " [ 0.37787208 -0.4954198 ]\n",
            " [ 0.36747327 -0.48421255]\n",
            " [ 0.44008267 -0.5055357 ]\n",
            " [ 0.42054015 -0.47827536]\n",
            " [ 0.44341704 -0.49667877]\n",
            " [ 0.3962658  -0.5053426 ]\n",
            " [ 0.4363368  -0.5012738 ]\n",
            " [ 0.41394427 -0.48417747]\n",
            " [ 0.41394427 -0.48417747]\n",
            " [ 0.4965685  -0.587963  ]\n",
            " [ 0.4335096  -0.52406406]\n",
            " [ 0.44601014 -0.53936243]\n",
            " [ 0.3943516  -0.52461034]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4213, -0.5369],\n",
            "        [ 0.4213, -0.5369],\n",
            "        [ 0.4214, -0.4827],\n",
            "        [ 0.4332, -0.4647],\n",
            "        [ 0.4556, -0.5118],\n",
            "        [ 0.4592, -0.5029],\n",
            "        [ 0.4592, -0.5029],\n",
            "        [ 0.4328, -0.3741],\n",
            "        [ 0.4404, -0.4301],\n",
            "        [ 0.4499, -0.4793],\n",
            "        [ 0.4351, -0.5003],\n",
            "        [ 0.4351, -0.5003],\n",
            "        [ 0.4152, -0.4993],\n",
            "        [ 0.4654, -0.4599],\n",
            "        [ 0.4344, -0.4347],\n",
            "        [ 0.4073, -0.4491],\n",
            "        [ 0.4408, -0.4442],\n",
            "        [ 0.5066, -0.4581],\n",
            "        [ 0.3411, -0.4676],\n",
            "        [ 0.3983, -0.4057],\n",
            "        [ 0.4628, -0.3998],\n",
            "        [ 0.5068, -0.4924],\n",
            "        [ 0.4040, -0.5128],\n",
            "        [ 0.3535, -0.5383],\n",
            "        [ 0.4120, -0.5331],\n",
            "        [ 0.3901, -0.5830],\n",
            "        [ 0.4856, -0.5216],\n",
            "        [ 0.4168, -0.5458],\n",
            "        [ 0.4130, -0.4661],\n",
            "        [ 0.3810, -0.5314],\n",
            "        [ 0.3290, -0.4762],\n",
            "        [ 0.3881, -0.5124]], device='cuda:0')\n",
            "Logits:[[ 0.421323   -0.5368609 ]\n",
            " [ 0.421323   -0.5368609 ]\n",
            " [ 0.42143437 -0.4827177 ]\n",
            " [ 0.43322986 -0.4646757 ]\n",
            " [ 0.4555801  -0.511823  ]\n",
            " [ 0.45921448 -0.5028784 ]\n",
            " [ 0.45921448 -0.5028784 ]\n",
            " [ 0.43276757 -0.3741336 ]\n",
            " [ 0.44039294 -0.43007421]\n",
            " [ 0.44990784 -0.47930914]\n",
            " [ 0.43509826 -0.5003141 ]\n",
            " [ 0.43509826 -0.5003141 ]\n",
            " [ 0.41517603 -0.49926752]\n",
            " [ 0.46539274 -0.45992604]\n",
            " [ 0.43438363 -0.43467802]\n",
            " [ 0.40731856 -0.44913533]\n",
            " [ 0.4408314  -0.44417578]\n",
            " [ 0.5066342  -0.4580763 ]\n",
            " [ 0.34113848 -0.46764335]\n",
            " [ 0.39829126 -0.4056848 ]\n",
            " [ 0.4627832  -0.3997726 ]\n",
            " [ 0.5068361  -0.49236026]\n",
            " [ 0.40395877 -0.5127631 ]\n",
            " [ 0.35346368 -0.538328  ]\n",
            " [ 0.4119536  -0.5331398 ]\n",
            " [ 0.39013487 -0.58300394]\n",
            " [ 0.48562342 -0.52159977]\n",
            " [ 0.41677088 -0.54576385]\n",
            " [ 0.41304493 -0.46608096]\n",
            " [ 0.38096792 -0.53140056]\n",
            " [ 0.32903874 -0.4761982 ]\n",
            " [ 0.38808244 -0.51243645]]\n",
            "Labels:[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1]\n",
            "Logits_each:tensor([[ 0.3635, -0.3827],\n",
            "        [ 0.3635, -0.3827],\n",
            "        [ 0.3187, -0.4826],\n",
            "        [ 0.3680, -0.4905],\n",
            "        [ 0.2661, -0.4093],\n",
            "        [ 0.3570, -0.4962],\n",
            "        [ 0.3664, -0.4017],\n",
            "        [ 0.3970, -0.3818],\n",
            "        [ 0.3403, -0.4241],\n",
            "        [ 0.3986, -0.4270],\n",
            "        [ 0.2773, -0.5342],\n",
            "        [ 0.3642, -0.4834],\n",
            "        [ 0.4389, -0.4910],\n",
            "        [ 0.3625, -0.4285],\n",
            "        [ 0.2984, -0.4250],\n",
            "        [ 0.3171, -0.4349],\n",
            "        [ 0.2984, -0.4250],\n",
            "        [ 0.4839, -0.4526],\n",
            "        [ 0.2613, -0.4268],\n",
            "        [ 0.2613, -0.4268],\n",
            "        [ 0.3435, -0.4779],\n",
            "        [ 0.3339, -0.4185],\n",
            "        [ 0.3074, -0.4774],\n",
            "        [ 0.3700, -0.4563],\n",
            "        [ 0.3700, -0.4563],\n",
            "        [ 0.3624, -0.4993],\n",
            "        [ 0.3624, -0.4993],\n",
            "        [ 0.3624, -0.4993],\n",
            "        [ 0.3330, -0.4754],\n",
            "        [ 0.4667, -0.4435],\n",
            "        [ 0.1494,  0.0263],\n",
            "        [ 0.3295, -0.4697]], device='cuda:0')\n",
            "Logits:[[ 0.36350155 -0.3826911 ]\n",
            " [ 0.36350155 -0.3826911 ]\n",
            " [ 0.31870735 -0.4825547 ]\n",
            " [ 0.36804575 -0.4905479 ]\n",
            " [ 0.26607043 -0.40930617]\n",
            " [ 0.35703623 -0.49615273]\n",
            " [ 0.36644992 -0.40169802]\n",
            " [ 0.3969563  -0.38182947]\n",
            " [ 0.3403386  -0.42405933]\n",
            " [ 0.39860627 -0.4269624 ]\n",
            " [ 0.27734625 -0.5341819 ]\n",
            " [ 0.36415252 -0.48340145]\n",
            " [ 0.4388937  -0.49101183]\n",
            " [ 0.36245924 -0.42848128]\n",
            " [ 0.29837754 -0.42496794]\n",
            " [ 0.3170582  -0.43487334]\n",
            " [ 0.29837754 -0.42496794]\n",
            " [ 0.4838967  -0.4526029 ]\n",
            " [ 0.26126945 -0.42677718]\n",
            " [ 0.26126945 -0.42677718]\n",
            " [ 0.3435032  -0.47794202]\n",
            " [ 0.3339038  -0.41847906]\n",
            " [ 0.30736303 -0.4773809 ]\n",
            " [ 0.36996353 -0.45629984]\n",
            " [ 0.36996353 -0.45629984]\n",
            " [ 0.3623501  -0.49934372]\n",
            " [ 0.3623501  -0.49934372]\n",
            " [ 0.3623501  -0.49934372]\n",
            " [ 0.3330151  -0.47540966]\n",
            " [ 0.4666972  -0.44345543]\n",
            " [ 0.14943467  0.02627574]\n",
            " [ 0.32952374 -0.46972382]]\n",
            "Labels:[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.5140, -0.5027],\n",
            "        [ 0.3355, -0.5526],\n",
            "        [ 0.4242, -0.5203],\n",
            "        [ 0.4337, -0.5067],\n",
            "        [ 0.3186, -0.5781],\n",
            "        [ 0.4095, -0.4702],\n",
            "        [ 0.3309, -0.5586],\n",
            "        [ 0.4764, -0.5644],\n",
            "        [ 0.3732, -0.5318],\n",
            "        [ 0.3734, -0.5577],\n",
            "        [ 0.4105, -0.5313],\n",
            "        [ 0.3939, -0.5255],\n",
            "        [ 0.4470, -0.4353],\n",
            "        [ 0.3891, -0.4548],\n",
            "        [ 0.4439, -0.4674],\n",
            "        [ 0.3834, -0.5003],\n",
            "        [ 0.3250, -0.5065],\n",
            "        [ 0.4215, -0.4121],\n",
            "        [ 0.4183, -0.4523],\n",
            "        [ 0.4076, -0.4435],\n",
            "        [ 0.4248, -0.5259],\n",
            "        [ 0.4043, -0.5054],\n",
            "        [ 0.4214, -0.5031],\n",
            "        [ 0.4463, -0.4400],\n",
            "        [ 0.2928, -0.4337],\n",
            "        [ 0.4407, -0.4892],\n",
            "        [ 0.4176, -0.4595],\n",
            "        [ 0.4363, -0.4724],\n",
            "        [ 0.3492, -0.3443],\n",
            "        [ 0.4389, -0.4730],\n",
            "        [ 0.4219, -0.4040],\n",
            "        [ 0.4396, -0.4907]], device='cuda:0')\n",
            "Logits:[[ 0.5139651  -0.50266635]\n",
            " [ 0.33545235 -0.5526178 ]\n",
            " [ 0.42417872 -0.5203289 ]\n",
            " [ 0.4336618  -0.50674534]\n",
            " [ 0.31855568 -0.5781295 ]\n",
            " [ 0.40951985 -0.47022435]\n",
            " [ 0.33088338 -0.5585604 ]\n",
            " [ 0.47644645 -0.5643671 ]\n",
            " [ 0.37321395 -0.5317767 ]\n",
            " [ 0.3734261  -0.55768204]\n",
            " [ 0.41051945 -0.5313349 ]\n",
            " [ 0.39393416 -0.52547246]\n",
            " [ 0.44700393 -0.43529883]\n",
            " [ 0.3891128  -0.45477483]\n",
            " [ 0.44393763 -0.46740457]\n",
            " [ 0.3833811  -0.5003119 ]\n",
            " [ 0.3249874  -0.50645494]\n",
            " [ 0.42145723 -0.41210642]\n",
            " [ 0.4183262  -0.4523286 ]\n",
            " [ 0.4075653  -0.443519  ]\n",
            " [ 0.42481777 -0.5259482 ]\n",
            " [ 0.40430847 -0.50544524]\n",
            " [ 0.4214239  -0.50311595]\n",
            " [ 0.44632468 -0.44002846]\n",
            " [ 0.29275522 -0.4336699 ]\n",
            " [ 0.44069707 -0.48923516]\n",
            " [ 0.41761154 -0.45949823]\n",
            " [ 0.43632272 -0.47244057]\n",
            " [ 0.34918654 -0.3443036 ]\n",
            " [ 0.4389347  -0.4729517 ]\n",
            " [ 0.4218538  -0.40402985]\n",
            " [ 0.43957412 -0.4906575 ]]\n",
            "Labels:[0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0]\n",
            "Logits_each:tensor([[ 0.4231, -0.4542],\n",
            "        [ 0.4030, -0.5196],\n",
            "        [ 0.3380, -0.4215],\n",
            "        [ 0.3275, -0.4919],\n",
            "        [ 0.4414, -0.4025],\n",
            "        [ 0.2083, -0.5292],\n",
            "        [ 0.2083, -0.5292],\n",
            "        [ 0.3224, -0.4612],\n",
            "        [ 0.3224, -0.4612],\n",
            "        [ 0.4613, -0.4305],\n",
            "        [ 0.4613, -0.4305],\n",
            "        [ 0.4004, -0.4487],\n",
            "        [ 0.4705, -0.3930],\n",
            "        [ 0.3705, -0.5266],\n",
            "        [ 0.4011, -0.5323],\n",
            "        [ 0.2314, -0.5173],\n",
            "        [ 0.4336, -0.4262],\n",
            "        [ 0.4291, -0.5141],\n",
            "        [ 0.3963, -0.4666],\n",
            "        [ 0.3644, -0.5026],\n",
            "        [ 0.4332, -0.4307],\n",
            "        [ 0.3928, -0.5111],\n",
            "        [ 0.5280, -0.5169],\n",
            "        [ 0.3681, -0.5406],\n",
            "        [ 0.4221, -0.4815],\n",
            "        [ 0.3866, -0.4510],\n",
            "        [ 0.3866, -0.4510],\n",
            "        [ 0.3553, -0.4277],\n",
            "        [ 0.5266, -0.4509],\n",
            "        [ 0.3672, -0.5118],\n",
            "        [ 0.4477, -0.4704],\n",
            "        [ 0.3754, -0.4879]], device='cuda:0')\n",
            "Logits:[[ 0.4230619  -0.45418411]\n",
            " [ 0.4030286  -0.51964056]\n",
            " [ 0.3379574  -0.42145696]\n",
            " [ 0.32749146 -0.4918751 ]\n",
            " [ 0.4413684  -0.40249777]\n",
            " [ 0.20830278 -0.52920675]\n",
            " [ 0.20830278 -0.52920675]\n",
            " [ 0.32239994 -0.46123937]\n",
            " [ 0.32239994 -0.46123937]\n",
            " [ 0.46129423 -0.43053037]\n",
            " [ 0.46129423 -0.43053037]\n",
            " [ 0.40037206 -0.44865933]\n",
            " [ 0.47047648 -0.39296138]\n",
            " [ 0.37053728 -0.5266189 ]\n",
            " [ 0.401057   -0.53234166]\n",
            " [ 0.23144509 -0.51734036]\n",
            " [ 0.43356195 -0.4262388 ]\n",
            " [ 0.42913955 -0.51408   ]\n",
            " [ 0.39627197 -0.46663457]\n",
            " [ 0.36444646 -0.5025914 ]\n",
            " [ 0.43324396 -0.43068346]\n",
            " [ 0.39276403 -0.51107365]\n",
            " [ 0.52804106 -0.5168643 ]\n",
            " [ 0.36806622 -0.54055256]\n",
            " [ 0.4220771  -0.4815115 ]\n",
            " [ 0.38659772 -0.450996  ]\n",
            " [ 0.38659772 -0.450996  ]\n",
            " [ 0.3552855  -0.4277466 ]\n",
            " [ 0.5266208  -0.45086724]\n",
            " [ 0.36723384 -0.51181674]\n",
            " [ 0.44767326 -0.47039133]\n",
            " [ 0.37541583 -0.4878799 ]]\n",
            "Labels:[0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3841, -0.4549],\n",
            "        [ 0.3981, -0.4729],\n",
            "        [ 0.3086, -0.4855],\n",
            "        [ 0.4359, -0.5081],\n",
            "        [ 0.4594, -0.4989],\n",
            "        [ 0.4042, -0.4753],\n",
            "        [ 0.3297, -0.4890],\n",
            "        [ 0.4731, -0.4624],\n",
            "        [ 0.4076, -0.5166],\n",
            "        [ 0.4159, -0.5526],\n",
            "        [ 0.3971, -0.5199],\n",
            "        [ 0.4167, -0.4742],\n",
            "        [ 0.2437, -0.4491],\n",
            "        [ 0.4618, -0.4708],\n",
            "        [ 0.4427, -0.4706],\n",
            "        [ 0.4554, -0.4385],\n",
            "        [ 0.4306, -0.4637],\n",
            "        [ 0.2143, -0.4594],\n",
            "        [ 0.4306, -0.4637],\n",
            "        [ 0.2992, -0.3923],\n",
            "        [ 0.3455, -0.4030],\n",
            "        [ 0.3810, -0.3571],\n",
            "        [ 0.3404, -0.3044],\n",
            "        [ 0.4196, -0.4391],\n",
            "        [ 0.4106, -0.4172],\n",
            "        [ 0.3944, -0.3792],\n",
            "        [ 0.3562, -0.4569],\n",
            "        [ 0.2726, -0.3949],\n",
            "        [ 0.2726, -0.3949],\n",
            "        [ 0.2847, -0.3751],\n",
            "        [ 0.3424, -0.3760],\n",
            "        [ 0.4771, -0.4287]], device='cuda:0')\n",
            "Logits:[[ 0.38408357 -0.4548825 ]\n",
            " [ 0.3981213  -0.47290456]\n",
            " [ 0.30856583 -0.4855057 ]\n",
            " [ 0.43585044 -0.50814617]\n",
            " [ 0.45935446 -0.4988893 ]\n",
            " [ 0.4041833  -0.47529057]\n",
            " [ 0.32971764 -0.48898885]\n",
            " [ 0.47305655 -0.46238926]\n",
            " [ 0.4076061  -0.51659906]\n",
            " [ 0.4159204  -0.5525607 ]\n",
            " [ 0.39713573 -0.51988006]\n",
            " [ 0.4166744  -0.47422716]\n",
            " [ 0.24365757 -0.4490743 ]\n",
            " [ 0.46176493 -0.4707869 ]\n",
            " [ 0.4426881  -0.47059023]\n",
            " [ 0.45535606 -0.43854028]\n",
            " [ 0.43062598 -0.46374565]\n",
            " [ 0.21426226 -0.45936054]\n",
            " [ 0.43062598 -0.46374565]\n",
            " [ 0.29920688 -0.39227647]\n",
            " [ 0.34553194 -0.4030058 ]\n",
            " [ 0.38099515 -0.35711223]\n",
            " [ 0.3403659  -0.30443338]\n",
            " [ 0.41964164 -0.43914315]\n",
            " [ 0.41058013 -0.4171892 ]\n",
            " [ 0.39436638 -0.37916967]\n",
            " [ 0.35616073 -0.45694646]\n",
            " [ 0.27259776 -0.3948915 ]\n",
            " [ 0.27259776 -0.3948915 ]\n",
            " [ 0.28473842 -0.37510288]\n",
            " [ 0.34235147 -0.37598366]\n",
            " [ 0.47707412 -0.4287062 ]]\n",
            "Labels:[0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4647, -0.4124],\n",
            "        [ 0.4840, -0.4280],\n",
            "        [ 0.3911, -0.4852],\n",
            "        [ 0.4009, -0.4691],\n",
            "        [ 0.4013, -0.4960],\n",
            "        [ 0.3758, -0.4000],\n",
            "        [ 0.3484, -0.3483],\n",
            "        [ 0.3688, -0.4761],\n",
            "        [ 0.3509, -0.4272],\n",
            "        [ 0.3883, -0.5761],\n",
            "        [ 0.2519, -0.4588],\n",
            "        [ 0.2726, -0.5488],\n",
            "        [ 0.2944, -0.5260],\n",
            "        [ 0.5141, -0.4295],\n",
            "        [ 0.4479, -0.4319],\n",
            "        [ 0.4479, -0.4319],\n",
            "        [ 0.4479, -0.4319],\n",
            "        [ 0.4477, -0.4428],\n",
            "        [ 0.5341, -0.4152],\n",
            "        [ 0.4190, -0.3806],\n",
            "        [ 0.4631, -0.4266],\n",
            "        [ 0.4922, -0.3847],\n",
            "        [ 0.5242, -0.3956],\n",
            "        [ 0.4930, -0.4366],\n",
            "        [ 0.4933, -0.3968],\n",
            "        [ 0.1944, -0.4798],\n",
            "        [ 0.2878, -0.4546],\n",
            "        [ 0.2340, -0.4805],\n",
            "        [ 0.2691, -0.4927],\n",
            "        [ 0.2691, -0.4927],\n",
            "        [ 0.2733, -0.4757],\n",
            "        [ 0.4882, -0.4963]], device='cuda:0')\n",
            "Logits:[[ 0.4647257  -0.41242483]\n",
            " [ 0.48400816 -0.42795587]\n",
            " [ 0.39114952 -0.4852393 ]\n",
            " [ 0.40089378 -0.4690563 ]\n",
            " [ 0.4013268  -0.49600315]\n",
            " [ 0.3758003  -0.39997384]\n",
            " [ 0.3484419  -0.34827945]\n",
            " [ 0.36879703 -0.4761382 ]\n",
            " [ 0.35091552 -0.42723712]\n",
            " [ 0.3883302  -0.5761034 ]\n",
            " [ 0.251916   -0.45877296]\n",
            " [ 0.27262083 -0.54884756]\n",
            " [ 0.29440284 -0.52604705]\n",
            " [ 0.51407784 -0.4294827 ]\n",
            " [ 0.44788197 -0.43191585]\n",
            " [ 0.44788197 -0.43191585]\n",
            " [ 0.44788197 -0.43191585]\n",
            " [ 0.44766763 -0.44283468]\n",
            " [ 0.53408897 -0.41520992]\n",
            " [ 0.41904137 -0.3805547 ]\n",
            " [ 0.46309122 -0.42655775]\n",
            " [ 0.4921961  -0.38473234]\n",
            " [ 0.5241861  -0.39559665]\n",
            " [ 0.49300435 -0.43658832]\n",
            " [ 0.4932755  -0.3968308 ]\n",
            " [ 0.19437745 -0.47979936]\n",
            " [ 0.28781876 -0.45457664]\n",
            " [ 0.23398232 -0.48048937]\n",
            " [ 0.2691146  -0.4927197 ]\n",
            " [ 0.2691146  -0.4927197 ]\n",
            " [ 0.27330613 -0.4757354 ]\n",
            " [ 0.488225   -0.4963196 ]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
            "Logits_each:tensor([[ 0.2733, -0.4757],\n",
            "        [ 0.1051, -0.5352],\n",
            "        [ 0.1592, -0.4615],\n",
            "        [ 0.4782, -0.5366],\n",
            "        [ 0.3664, -0.5587],\n",
            "        [ 0.4782, -0.5366],\n",
            "        [ 0.3333, -0.5705],\n",
            "        [ 0.3977, -0.4542],\n",
            "        [ 0.4049, -0.4605],\n",
            "        [ 0.4010, -0.5461],\n",
            "        [ 0.3054, -0.5745],\n",
            "        [ 0.4456, -0.5045],\n",
            "        [ 0.3955, -0.5060],\n",
            "        [ 0.4027, -0.4656],\n",
            "        [ 0.4352, -0.5601],\n",
            "        [ 0.4911, -0.5258],\n",
            "        [ 0.4029, -0.4968],\n",
            "        [ 0.4508, -0.4729],\n",
            "        [ 0.3229, -0.4731],\n",
            "        [ 0.2846, -0.4446],\n",
            "        [ 0.3511, -0.4693],\n",
            "        [ 0.3658, -0.4196],\n",
            "        [ 0.3513, -0.4936],\n",
            "        [ 0.3514, -0.4093],\n",
            "        [ 0.3959, -0.4945],\n",
            "        [ 0.3208, -0.4771],\n",
            "        [ 0.3810, -0.4850],\n",
            "        [ 0.4115, -0.5161],\n",
            "        [ 0.3796, -0.4915],\n",
            "        [ 0.3710, -0.4706],\n",
            "        [ 0.3710, -0.4706],\n",
            "        [ 0.3905, -0.4746]], device='cuda:0')\n",
            "Logits:[[ 0.27330613 -0.4757354 ]\n",
            " [ 0.10511663 -0.5352229 ]\n",
            " [ 0.15916398 -0.46150458]\n",
            " [ 0.47818652 -0.5365955 ]\n",
            " [ 0.36639234 -0.5586695 ]\n",
            " [ 0.47818652 -0.5365955 ]\n",
            " [ 0.33331224 -0.5704929 ]\n",
            " [ 0.39771318 -0.4542367 ]\n",
            " [ 0.40492335 -0.46051967]\n",
            " [ 0.40100324 -0.5461013 ]\n",
            " [ 0.30536586 -0.5745301 ]\n",
            " [ 0.44557923 -0.5045293 ]\n",
            " [ 0.39550814 -0.5060271 ]\n",
            " [ 0.4027386  -0.46564198]\n",
            " [ 0.4352064  -0.560113  ]\n",
            " [ 0.4910989  -0.5258116 ]\n",
            " [ 0.4028906  -0.49683005]\n",
            " [ 0.45075375 -0.4729184 ]\n",
            " [ 0.32289422 -0.47308868]\n",
            " [ 0.28457457 -0.44459158]\n",
            " [ 0.3511238  -0.4693018 ]\n",
            " [ 0.36577526 -0.41962922]\n",
            " [ 0.35129416 -0.49355644]\n",
            " [ 0.35143712 -0.4092586 ]\n",
            " [ 0.3959476  -0.49446487]\n",
            " [ 0.3208081  -0.477145  ]\n",
            " [ 0.38100883 -0.48503587]\n",
            " [ 0.41151917 -0.516134  ]\n",
            " [ 0.37960845 -0.491464  ]\n",
            " [ 0.37099013 -0.47064567]\n",
            " [ 0.37099013 -0.47064567]\n",
            " [ 0.39048952 -0.47460487]]\n",
            "Labels:[0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3735, -0.5467],\n",
            "        [ 0.3568, -0.5407],\n",
            "        [ 0.2872, -0.4568],\n",
            "        [ 0.4021, -0.5203],\n",
            "        [ 0.3654, -0.4862],\n",
            "        [ 0.3420, -0.3895],\n",
            "        [ 0.3334, -0.4508],\n",
            "        [ 0.3714, -0.4977],\n",
            "        [ 0.3346, -0.4766],\n",
            "        [ 0.2770, -0.4129],\n",
            "        [ 0.4096, -0.4715],\n",
            "        [ 0.3674, -0.4969],\n",
            "        [ 0.4123, -0.4626],\n",
            "        [ 0.3745, -0.5689],\n",
            "        [ 0.3745, -0.5689],\n",
            "        [ 0.3162, -0.4629],\n",
            "        [ 0.3676, -0.5299],\n",
            "        [ 0.3379, -0.4516],\n",
            "        [ 0.3988, -0.5203],\n",
            "        [ 0.3573, -0.4758],\n",
            "        [ 0.3198, -0.5417],\n",
            "        [ 0.3508, -0.5356],\n",
            "        [ 0.3971, -0.5003],\n",
            "        [ 0.2818, -0.4745],\n",
            "        [ 0.3795, -0.4753],\n",
            "        [ 0.3544, -0.4471],\n",
            "        [ 0.3833, -0.4009],\n",
            "        [ 0.2925, -0.5043],\n",
            "        [ 0.4337, -0.4994],\n",
            "        [ 0.3292, -0.5380],\n",
            "        [ 0.3758, -0.5015],\n",
            "        [ 0.3005, -0.5538]], device='cuda:0')\n",
            "Logits:[[ 0.37346664 -0.546747  ]\n",
            " [ 0.3568393  -0.54071885]\n",
            " [ 0.2871547  -0.456849  ]\n",
            " [ 0.40207407 -0.520307  ]\n",
            " [ 0.36536223 -0.4862354 ]\n",
            " [ 0.34200263 -0.3894757 ]\n",
            " [ 0.33335856 -0.45079544]\n",
            " [ 0.3713938  -0.4976501 ]\n",
            " [ 0.33462515 -0.47661066]\n",
            " [ 0.27699897 -0.41291994]\n",
            " [ 0.40957236 -0.47148994]\n",
            " [ 0.36743608 -0.49688488]\n",
            " [ 0.41225514 -0.46261358]\n",
            " [ 0.3744587  -0.56886184]\n",
            " [ 0.3744587  -0.56886184]\n",
            " [ 0.31623036 -0.46286994]\n",
            " [ 0.367641   -0.5298985 ]\n",
            " [ 0.3379146  -0.45160544]\n",
            " [ 0.39878574 -0.52025044]\n",
            " [ 0.35725498 -0.4757513 ]\n",
            " [ 0.31976256 -0.5416685 ]\n",
            " [ 0.35080957 -0.535638  ]\n",
            " [ 0.39707324 -0.5003044 ]\n",
            " [ 0.28184947 -0.47447827]\n",
            " [ 0.37948272 -0.4752754 ]\n",
            " [ 0.3543538  -0.44713196]\n",
            " [ 0.3833363  -0.40093604]\n",
            " [ 0.2925081  -0.50434655]\n",
            " [ 0.43373978 -0.49942482]\n",
            " [ 0.32922837 -0.53799963]\n",
            " [ 0.37578285 -0.50153816]\n",
            " [ 0.3005252  -0.5538254 ]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3428, -0.4566],\n",
            "        [ 0.3658, -0.4968],\n",
            "        [ 0.4381, -0.4730],\n",
            "        [ 0.3740, -0.4508],\n",
            "        [ 0.3740, -0.4508],\n",
            "        [ 0.3641, -0.5136],\n",
            "        [ 0.3820, -0.5106],\n",
            "        [ 0.5182, -0.4886],\n",
            "        [ 0.5182, -0.4886],\n",
            "        [ 0.3184, -0.5422],\n",
            "        [ 0.3743, -0.4924],\n",
            "        [ 0.3691, -0.5131],\n",
            "        [ 0.4030, -0.5015],\n",
            "        [ 0.4362, -0.4652],\n",
            "        [ 0.3783, -0.4823],\n",
            "        [ 0.4302, -0.5151],\n",
            "        [ 0.3636, -0.4842],\n",
            "        [ 0.4120, -0.4831],\n",
            "        [ 0.3990, -0.4579],\n",
            "        [ 0.4367, -0.5126],\n",
            "        [ 0.3203, -0.5818],\n",
            "        [ 0.3326, -0.5778],\n",
            "        [ 0.3801, -0.4738],\n",
            "        [ 0.3848, -0.4552],\n",
            "        [ 0.4080, -0.4809],\n",
            "        [ 0.3099, -0.5026],\n",
            "        [ 0.3740, -0.5034],\n",
            "        [ 0.3647, -0.5185],\n",
            "        [ 0.3531, -0.4957],\n",
            "        [ 0.4460, -0.5207],\n",
            "        [ 0.3741, -0.5149],\n",
            "        [ 0.1467, -0.5294]], device='cuda:0')\n",
            "Logits:[[ 0.34282675 -0.4565774 ]\n",
            " [ 0.36584282 -0.49676916]\n",
            " [ 0.4380552  -0.47302097]\n",
            " [ 0.37397775 -0.45079863]\n",
            " [ 0.37397775 -0.45079863]\n",
            " [ 0.36414495 -0.51361924]\n",
            " [ 0.38196066 -0.51061946]\n",
            " [ 0.5182425  -0.48862472]\n",
            " [ 0.5182425  -0.48862472]\n",
            " [ 0.31835467 -0.5421694 ]\n",
            " [ 0.37429863 -0.49238384]\n",
            " [ 0.3691128  -0.51307434]\n",
            " [ 0.40302995 -0.5015489 ]\n",
            " [ 0.43616128 -0.46523225]\n",
            " [ 0.37825492 -0.4822575 ]\n",
            " [ 0.43015897 -0.51511574]\n",
            " [ 0.3636488  -0.48419127]\n",
            " [ 0.41195574 -0.48310655]\n",
            " [ 0.3989649  -0.45789135]\n",
            " [ 0.4367259  -0.5126334 ]\n",
            " [ 0.32029954 -0.58175486]\n",
            " [ 0.33259055 -0.5778395 ]\n",
            " [ 0.3800581  -0.47375008]\n",
            " [ 0.38481778 -0.4552269 ]\n",
            " [ 0.40796503 -0.4808732 ]\n",
            " [ 0.3098536  -0.50262254]\n",
            " [ 0.37403777 -0.5034327 ]\n",
            " [ 0.36468083 -0.5184796 ]\n",
            " [ 0.3531115  -0.4957241 ]\n",
            " [ 0.4460039  -0.5207186 ]\n",
            " [ 0.3740942  -0.5149248 ]\n",
            " [ 0.14670691 -0.5294462 ]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1]\n",
            "Logits_each:tensor([[ 0.3493, -0.5101],\n",
            "        [ 0.3842, -0.4669],\n",
            "        [ 0.2853, -0.4916],\n",
            "        [ 0.3965, -0.4460],\n",
            "        [ 0.2838, -0.4817],\n",
            "        [ 0.4897, -0.4804],\n",
            "        [ 0.4803, -0.3900],\n",
            "        [ 0.4859, -0.4209],\n",
            "        [ 0.5653, -0.3829],\n",
            "        [ 0.5026, -0.4582],\n",
            "        [ 0.4903, -0.4092],\n",
            "        [ 0.5025, -0.4171],\n",
            "        [ 0.5262, -0.3962],\n",
            "        [ 0.5130, -0.3814],\n",
            "        [ 0.4575, -0.3819],\n",
            "        [ 0.4697, -0.3772],\n",
            "        [ 0.5068, -0.3926],\n",
            "        [ 0.4469, -0.4130],\n",
            "        [ 0.4915, -0.3745],\n",
            "        [ 0.5119, -0.3983],\n",
            "        [ 0.4721, -0.4086],\n",
            "        [ 0.4911, -0.4327],\n",
            "        [ 0.4917, -0.4175],\n",
            "        [ 0.4798, -0.4083],\n",
            "        [ 0.4518, -0.4013],\n",
            "        [ 0.4818, -0.4308],\n",
            "        [ 0.5173, -0.4294],\n",
            "        [ 0.4421, -0.4263],\n",
            "        [ 0.4870, -0.4369],\n",
            "        [ 0.5141, -0.3713],\n",
            "        [ 0.4875, -0.3765],\n",
            "        [ 0.4679, -0.3977]], device='cuda:0')\n",
            "Logits:[[ 0.34927383 -0.510068  ]\n",
            " [ 0.3841548  -0.46693784]\n",
            " [ 0.28534657 -0.49155042]\n",
            " [ 0.396517   -0.4459702 ]\n",
            " [ 0.2838254  -0.4817402 ]\n",
            " [ 0.48971555 -0.48036322]\n",
            " [ 0.48025873 -0.38995805]\n",
            " [ 0.48590475 -0.42088643]\n",
            " [ 0.56533813 -0.3829157 ]\n",
            " [ 0.5025632  -0.45815232]\n",
            " [ 0.49033484 -0.4092171 ]\n",
            " [ 0.5024842  -0.41710743]\n",
            " [ 0.5262277  -0.39624414]\n",
            " [ 0.5129997  -0.3813884 ]\n",
            " [ 0.45746022 -0.38188538]\n",
            " [ 0.46968326 -0.37717307]\n",
            " [ 0.5067936  -0.3925768 ]\n",
            " [ 0.44686535 -0.41296023]\n",
            " [ 0.49151596 -0.3744952 ]\n",
            " [ 0.5118649  -0.39833954]\n",
            " [ 0.47212502 -0.4085775 ]\n",
            " [ 0.49105865 -0.43273014]\n",
            " [ 0.49171177 -0.4175368 ]\n",
            " [ 0.47981066 -0.40825823]\n",
            " [ 0.45181772 -0.40127677]\n",
            " [ 0.4818309  -0.43081418]\n",
            " [ 0.517333   -0.42938545]\n",
            " [ 0.4421338  -0.4263273 ]\n",
            " [ 0.4870256  -0.4368812 ]\n",
            " [ 0.5141391  -0.3713133 ]\n",
            " [ 0.48753166 -0.3764745 ]\n",
            " [ 0.46785575 -0.39766815]]\n",
            "Labels:[1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.5066, -0.4747],\n",
            "        [ 0.5271, -0.3805],\n",
            "        [ 0.4919, -0.3732],\n",
            "        [ 0.4724, -0.3829],\n",
            "        [ 0.4729, -0.3961],\n",
            "        [ 0.4723, -0.3815],\n",
            "        [ 0.4991, -0.4109],\n",
            "        [ 0.4987, -0.4203],\n",
            "        [ 0.5183, -0.3703],\n",
            "        [ 0.4856, -0.4200],\n",
            "        [ 0.4985, -0.4175],\n",
            "        [ 0.5211, -0.3754],\n",
            "        [ 0.5145, -0.3918],\n",
            "        [ 0.4914, -0.3975],\n",
            "        [ 0.4797, -0.3700],\n",
            "        [ 0.5045, -0.3733],\n",
            "        [ 0.5089, -0.4172],\n",
            "        [ 0.5170, -0.4337],\n",
            "        [ 0.4825, -0.4177],\n",
            "        [ 0.4349, -0.3886],\n",
            "        [ 0.2381, -0.2089],\n",
            "        [ 0.4787, -0.3826],\n",
            "        [ 0.4403, -0.4146],\n",
            "        [ 0.3531, -0.3803],\n",
            "        [ 0.3531, -0.3803],\n",
            "        [ 0.4468, -0.4102],\n",
            "        [ 0.4605, -0.3964],\n",
            "        [ 0.3053, -0.4173],\n",
            "        [ 0.4722, -0.3978],\n",
            "        [ 0.4763, -0.3906],\n",
            "        [ 0.4622, -0.3810],\n",
            "        [ 0.3393, -0.3706]], device='cuda:0')\n",
            "Logits:[[ 0.5065725  -0.47472927]\n",
            " [ 0.5271102  -0.38050082]\n",
            " [ 0.49190053 -0.37323785]\n",
            " [ 0.47237736 -0.38287413]\n",
            " [ 0.472867   -0.3961399 ]\n",
            " [ 0.47227144 -0.38152963]\n",
            " [ 0.4990774  -0.41094726]\n",
            " [ 0.49867693 -0.42028436]\n",
            " [ 0.51825917 -0.370291  ]\n",
            " [ 0.48563927 -0.42003226]\n",
            " [ 0.49847406 -0.41753513]\n",
            " [ 0.52109665 -0.37536314]\n",
            " [ 0.5144795  -0.39176965]\n",
            " [ 0.4914437  -0.39754885]\n",
            " [ 0.47965696 -0.3699706 ]\n",
            " [ 0.5044839  -0.37334403]\n",
            " [ 0.50889945 -0.4171947 ]\n",
            " [ 0.5169923  -0.43367073]\n",
            " [ 0.48247766 -0.41770083]\n",
            " [ 0.43493846 -0.38859993]\n",
            " [ 0.23808579 -0.20891893]\n",
            " [ 0.4787419  -0.38264963]\n",
            " [ 0.4402779  -0.4146133 ]\n",
            " [ 0.35314265 -0.38025615]\n",
            " [ 0.35314265 -0.38025615]\n",
            " [ 0.44680023 -0.4102313 ]\n",
            " [ 0.4605354  -0.39637277]\n",
            " [ 0.3052726  -0.4173326 ]\n",
            " [ 0.47215423 -0.39780322]\n",
            " [ 0.47626743 -0.39058498]\n",
            " [ 0.46222812 -0.38096136]\n",
            " [ 0.33928004 -0.37055746]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4638, -0.4029],\n",
            "        [ 0.4287, -0.3725],\n",
            "        [ 0.4287, -0.3725],\n",
            "        [ 0.5099, -0.4203],\n",
            "        [ 0.4023, -0.3818],\n",
            "        [ 0.4494, -0.4301],\n",
            "        [ 0.5080, -0.4120],\n",
            "        [ 0.4745, -0.4242],\n",
            "        [ 0.5080, -0.4120],\n",
            "        [ 0.3705, -0.4087],\n",
            "        [ 0.4698, -0.3937],\n",
            "        [ 0.2782, -0.5004],\n",
            "        [ 0.4329, -0.4251],\n",
            "        [ 0.4036, -0.3659],\n",
            "        [ 0.4745, -0.4242],\n",
            "        [ 0.4745, -0.4242],\n",
            "        [ 0.4036, -0.3659],\n",
            "        [ 0.3130, -0.3885],\n",
            "        [ 0.3290, -0.4866],\n",
            "        [ 0.3976, -0.4728],\n",
            "        [ 0.3391, -0.4725],\n",
            "        [ 0.3620, -0.3772],\n",
            "        [ 0.3486, -0.4736],\n",
            "        [ 0.3628, -0.5169],\n",
            "        [ 0.4272, -0.4446],\n",
            "        [ 0.3994, -0.4882],\n",
            "        [ 0.3436, -0.5025],\n",
            "        [ 0.3367, -0.5290],\n",
            "        [ 0.3681, -0.4612],\n",
            "        [ 0.4386, -0.4575],\n",
            "        [ 0.3809, -0.4713],\n",
            "        [ 0.4083, -0.4744]], device='cuda:0')\n",
            "Logits:[[ 0.46383125 -0.40286246]\n",
            " [ 0.4286793  -0.37252793]\n",
            " [ 0.4286793  -0.37252793]\n",
            " [ 0.50988597 -0.42032057]\n",
            " [ 0.40227267 -0.38180342]\n",
            " [ 0.44943845 -0.4301398 ]\n",
            " [ 0.50803983 -0.41203946]\n",
            " [ 0.47453785 -0.42421597]\n",
            " [ 0.50803983 -0.41203946]\n",
            " [ 0.37048697 -0.4086744 ]\n",
            " [ 0.4697728  -0.39368594]\n",
            " [ 0.27818018 -0.5004467 ]\n",
            " [ 0.43293735 -0.42512044]\n",
            " [ 0.40356702 -0.36586472]\n",
            " [ 0.47453785 -0.42421597]\n",
            " [ 0.47453785 -0.42421597]\n",
            " [ 0.40356702 -0.36586472]\n",
            " [ 0.3130419  -0.38854158]\n",
            " [ 0.32904956 -0.48658678]\n",
            " [ 0.39759526 -0.47280583]\n",
            " [ 0.33908167 -0.47252855]\n",
            " [ 0.36204413 -0.37717742]\n",
            " [ 0.348648   -0.47361505]\n",
            " [ 0.36275685 -0.5168579 ]\n",
            " [ 0.42723754 -0.4445561 ]\n",
            " [ 0.39943716 -0.48816335]\n",
            " [ 0.34361652 -0.5024966 ]\n",
            " [ 0.33670968 -0.5290273 ]\n",
            " [ 0.3680668  -0.46120065]\n",
            " [ 0.438602   -0.45746362]\n",
            " [ 0.38089722 -0.47129   ]\n",
            " [ 0.4083048  -0.47440147]]\n",
            "Labels:[0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3503, -0.4626],\n",
            "        [ 0.3436, -0.4402],\n",
            "        [ 0.3391, -0.4023],\n",
            "        [ 0.3423, -0.4077],\n",
            "        [ 0.3113, -0.4799],\n",
            "        [ 0.3914, -0.4400],\n",
            "        [ 0.3469, -0.4023],\n",
            "        [ 0.3946, -0.4478],\n",
            "        [ 0.3632, -0.4539],\n",
            "        [ 0.3985, -0.4445],\n",
            "        [ 0.3457, -0.5455],\n",
            "        [ 0.1269, -0.6532],\n",
            "        [ 0.3621, -0.5989],\n",
            "        [ 0.3946, -0.5596],\n",
            "        [ 0.4609, -0.4424],\n",
            "        [ 0.4612, -0.4739],\n",
            "        [ 0.4612, -0.4739],\n",
            "        [ 0.3300, -0.4820],\n",
            "        [ 0.4530, -0.4327],\n",
            "        [ 0.4530, -0.4327],\n",
            "        [ 0.4530, -0.4327],\n",
            "        [ 0.4036, -0.4486],\n",
            "        [ 0.0373, -0.2164],\n",
            "        [ 0.4905, -0.4158],\n",
            "        [ 0.4696, -0.5023],\n",
            "        [ 0.5015, -0.4961],\n",
            "        [ 0.5015, -0.4961],\n",
            "        [ 0.3979, -0.4250],\n",
            "        [ 0.3860, -0.4842],\n",
            "        [ 0.4112, -0.5111],\n",
            "        [ 0.4047, -0.4707],\n",
            "        [ 0.3978, -0.4740]], device='cuda:0')\n",
            "Logits:[[ 0.35032082 -0.46257743]\n",
            " [ 0.34362254 -0.4401984 ]\n",
            " [ 0.33911732 -0.40230525]\n",
            " [ 0.34234306 -0.40767217]\n",
            " [ 0.3112925  -0.47986397]\n",
            " [ 0.39141712 -0.43995067]\n",
            " [ 0.3469166  -0.4023204 ]\n",
            " [ 0.3945658  -0.44776556]\n",
            " [ 0.3631915  -0.45392275]\n",
            " [ 0.39853135 -0.44454056]\n",
            " [ 0.34572998 -0.5455189 ]\n",
            " [ 0.12691306 -0.6531555 ]\n",
            " [ 0.36213872 -0.59893644]\n",
            " [ 0.39455754 -0.5595649 ]\n",
            " [ 0.46085486 -0.4423905 ]\n",
            " [ 0.46121484 -0.47385517]\n",
            " [ 0.46121484 -0.47385517]\n",
            " [ 0.33004707 -0.4819611 ]\n",
            " [ 0.45300186 -0.43265682]\n",
            " [ 0.45300186 -0.43265682]\n",
            " [ 0.45300186 -0.43265682]\n",
            " [ 0.403641   -0.44857985]\n",
            " [ 0.03726462 -0.21635745]\n",
            " [ 0.4904733  -0.41578847]\n",
            " [ 0.469589   -0.5022636 ]\n",
            " [ 0.50152135 -0.4961066 ]\n",
            " [ 0.50152135 -0.4961066 ]\n",
            " [ 0.3979044  -0.42496768]\n",
            " [ 0.38602206 -0.48417735]\n",
            " [ 0.41119334 -0.5110547 ]\n",
            " [ 0.40469313 -0.47069463]\n",
            " [ 0.39777562 -0.47402167]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1]\n",
            "Logits_each:tensor([[ 0.4218, -0.4414],\n",
            "        [ 0.2576, -0.4628],\n",
            "        [ 0.4455, -0.4921],\n",
            "        [ 0.3996, -0.4699],\n",
            "        [ 0.3919, -0.4845],\n",
            "        [ 0.4157, -0.4093],\n",
            "        [ 0.3675, -0.4916],\n",
            "        [ 0.4694, -0.4879],\n",
            "        [ 0.3433, -0.4803],\n",
            "        [ 0.2996, -0.5013],\n",
            "        [ 0.4687, -0.4874],\n",
            "        [ 0.3593, -0.5229],\n",
            "        [ 0.1945, -0.4923],\n",
            "        [ 0.4343, -0.4931],\n",
            "        [ 0.1524, -0.4344],\n",
            "        [ 0.3532, -0.4811],\n",
            "        [ 0.4180, -0.4812],\n",
            "        [ 0.4357, -0.4740],\n",
            "        [ 0.3574, -0.4696],\n",
            "        [ 0.4281, -0.5099],\n",
            "        [ 0.3312, -0.5257],\n",
            "        [ 0.3300, -0.4955],\n",
            "        [ 0.4827, -0.4529],\n",
            "        [ 0.4042, -0.5223],\n",
            "        [ 0.4548, -0.4809],\n",
            "        [ 0.3099, -0.5391],\n",
            "        [ 0.4825, -0.5435],\n",
            "        [ 0.4450, -0.4512],\n",
            "        [ 0.5036, -0.4497],\n",
            "        [ 0.4332, -0.4954],\n",
            "        [ 0.4101, -0.4824],\n",
            "        [ 0.4827, -0.5009]], device='cuda:0')\n",
            "Logits:[[ 0.42178756 -0.44143832]\n",
            " [ 0.2575845  -0.46275812]\n",
            " [ 0.44545695 -0.49206856]\n",
            " [ 0.39963955 -0.46994874]\n",
            " [ 0.39190134 -0.4844527 ]\n",
            " [ 0.41566825 -0.40929633]\n",
            " [ 0.36752012 -0.49155128]\n",
            " [ 0.46943802 -0.48794484]\n",
            " [ 0.34331706 -0.48032168]\n",
            " [ 0.29957655 -0.5012935 ]\n",
            " [ 0.4686778  -0.48742515]\n",
            " [ 0.35925344 -0.522916  ]\n",
            " [ 0.19449104 -0.49229485]\n",
            " [ 0.434312   -0.49307418]\n",
            " [ 0.15238318 -0.43441483]\n",
            " [ 0.35322064 -0.4810567 ]\n",
            " [ 0.4180404  -0.48122478]\n",
            " [ 0.43573532 -0.47400627]\n",
            " [ 0.35736406 -0.46964857]\n",
            " [ 0.42811176 -0.5098988 ]\n",
            " [ 0.33115414 -0.5257154 ]\n",
            " [ 0.33003497 -0.49545845]\n",
            " [ 0.48267332 -0.45290175]\n",
            " [ 0.40424824 -0.5222881 ]\n",
            " [ 0.45479617 -0.48091024]\n",
            " [ 0.30993894 -0.539147  ]\n",
            " [ 0.48253733 -0.5434764 ]\n",
            " [ 0.44499353 -0.45117998]\n",
            " [ 0.5036077  -0.4496792 ]\n",
            " [ 0.43321577 -0.49537107]\n",
            " [ 0.41007113 -0.48239228]\n",
            " [ 0.48267892 -0.5009487 ]]\n",
            "Labels:[0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4623, -0.5230],\n",
            "        [ 0.4549, -0.5449],\n",
            "        [ 0.5116, -0.4751],\n",
            "        [ 0.1840, -0.4962],\n",
            "        [ 0.1612, -0.6467],\n",
            "        [ 0.3201, -0.5803],\n",
            "        [ 0.3960, -0.5296],\n",
            "        [ 0.4015, -0.5082],\n",
            "        [ 0.2678, -0.6230],\n",
            "        [ 0.1790, -0.5929],\n",
            "        [ 0.2847, -0.5931],\n",
            "        [ 0.1790, -0.5929],\n",
            "        [ 0.2129, -0.6512],\n",
            "        [ 0.4270, -0.5366],\n",
            "        [ 0.4162, -0.5355],\n",
            "        [ 0.4162, -0.5355],\n",
            "        [ 0.2407, -0.6332],\n",
            "        [ 0.3679, -0.6024],\n",
            "        [ 0.2987, -0.6039],\n",
            "        [ 0.4235, -0.5183],\n",
            "        [ 0.2761, -0.5952],\n",
            "        [ 0.2761, -0.5952],\n",
            "        [ 0.3617, -0.5008],\n",
            "        [ 0.3773, -0.5652],\n",
            "        [ 0.4029, -0.4915],\n",
            "        [ 0.4485, -0.4774],\n",
            "        [ 0.5083, -0.4330],\n",
            "        [ 0.1431, -0.5705],\n",
            "        [ 0.1257, -0.4914],\n",
            "        [ 0.3473, -0.4795],\n",
            "        [ 0.3521, -0.3708],\n",
            "        [ 0.4044, -0.4442]], device='cuda:0')\n",
            "Logits:[[ 0.46233845 -0.52300227]\n",
            " [ 0.4548586  -0.54490876]\n",
            " [ 0.51163113 -0.4750662 ]\n",
            " [ 0.18397544 -0.4962144 ]\n",
            " [ 0.16116145 -0.6466816 ]\n",
            " [ 0.32005736 -0.5803178 ]\n",
            " [ 0.39599517 -0.5296389 ]\n",
            " [ 0.40148365 -0.5082331 ]\n",
            " [ 0.26784182 -0.623042  ]\n",
            " [ 0.17904353 -0.592918  ]\n",
            " [ 0.28473035 -0.59305406]\n",
            " [ 0.17904353 -0.592918  ]\n",
            " [ 0.21289302 -0.6512081 ]\n",
            " [ 0.42704585 -0.5365722 ]\n",
            " [ 0.4162434  -0.5354752 ]\n",
            " [ 0.4162434  -0.5354752 ]\n",
            " [ 0.24073227 -0.63324034]\n",
            " [ 0.36792392 -0.6023861 ]\n",
            " [ 0.29869455 -0.6038798 ]\n",
            " [ 0.42349118 -0.5183146 ]\n",
            " [ 0.27614132 -0.5952263 ]\n",
            " [ 0.27614132 -0.5952263 ]\n",
            " [ 0.3617009  -0.50083524]\n",
            " [ 0.37726524 -0.565177  ]\n",
            " [ 0.4028811  -0.4914836 ]\n",
            " [ 0.44849423 -0.47743517]\n",
            " [ 0.50832623 -0.43304607]\n",
            " [ 0.1430607  -0.57048047]\n",
            " [ 0.12571377 -0.49137446]\n",
            " [ 0.3473125  -0.4795488 ]\n",
            " [ 0.35207874 -0.37075606]\n",
            " [ 0.40443188 -0.44417435]]\n",
            "Labels:[0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1]\n",
            "Logits_each:tensor([[ 0.3119, -0.4823],\n",
            "        [ 0.4033, -0.5440],\n",
            "        [ 0.4196, -0.4585],\n",
            "        [ 0.3357, -0.4577],\n",
            "        [ 0.3784, -0.4511],\n",
            "        [ 0.3949, -0.5084],\n",
            "        [ 0.3726, -0.5142],\n",
            "        [ 0.2911, -0.5302],\n",
            "        [ 0.3219, -0.4172],\n",
            "        [ 0.0724, -0.2629],\n",
            "        [ 0.4042, -0.3654],\n",
            "        [ 0.3789, -0.4384],\n",
            "        [ 0.3873, -0.4083],\n",
            "        [ 0.3554, -0.4509],\n",
            "        [ 0.3823, -0.4392],\n",
            "        [ 0.3627, -0.3954],\n",
            "        [ 0.3981, -0.4787],\n",
            "        [ 0.4206, -0.4978],\n",
            "        [ 0.3736, -0.3946],\n",
            "        [ 0.3532, -0.5088],\n",
            "        [ 0.3147, -0.4807],\n",
            "        [ 0.3657, -0.4437],\n",
            "        [ 0.5344, -0.4753],\n",
            "        [ 0.4450, -0.4785],\n",
            "        [ 0.4746, -0.4598],\n",
            "        [ 0.4880, -0.4529],\n",
            "        [ 0.4962, -0.3503],\n",
            "        [ 0.4956, -0.3172],\n",
            "        [ 0.4583, -0.4772],\n",
            "        [ 0.4785, -0.3945],\n",
            "        [ 0.4786, -0.4195],\n",
            "        [ 0.4922, -0.4081]], device='cuda:0')\n",
            "Logits:[[ 0.31190345 -0.48232788]\n",
            " [ 0.4032595  -0.544039  ]\n",
            " [ 0.419612   -0.45853508]\n",
            " [ 0.33566678 -0.45772576]\n",
            " [ 0.3783748  -0.45112568]\n",
            " [ 0.39491078 -0.50836056]\n",
            " [ 0.37261277 -0.5141784 ]\n",
            " [ 0.29105952 -0.5302023 ]\n",
            " [ 0.32193136 -0.41716135]\n",
            " [ 0.07244137 -0.26286075]\n",
            " [ 0.4042198  -0.36536634]\n",
            " [ 0.37887684 -0.43843138]\n",
            " [ 0.38730612 -0.4082805 ]\n",
            " [ 0.35542956 -0.45091856]\n",
            " [ 0.38230547 -0.43915   ]\n",
            " [ 0.3627379  -0.39542454]\n",
            " [ 0.39810565 -0.47869727]\n",
            " [ 0.42062077 -0.49780902]\n",
            " [ 0.3735972  -0.39458057]\n",
            " [ 0.35320324 -0.50875294]\n",
            " [ 0.3146785  -0.4806695 ]\n",
            " [ 0.36570245 -0.44371083]\n",
            " [ 0.5344453  -0.47533485]\n",
            " [ 0.4449543  -0.47849616]\n",
            " [ 0.4745874  -0.4597812 ]\n",
            " [ 0.48798543 -0.45289534]\n",
            " [ 0.49623755 -0.35033253]\n",
            " [ 0.49561745 -0.31720573]\n",
            " [ 0.45834705 -0.47721034]\n",
            " [ 0.4785465  -0.39452183]\n",
            " [ 0.47863144 -0.41947073]\n",
            " [ 0.49221557 -0.40809107]]\n",
            "Labels:[1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0]\n",
            "Logits_each:tensor([[ 0.4922, -0.4435],\n",
            "        [ 0.5474, -0.4660],\n",
            "        [ 0.4092, -0.4904],\n",
            "        [ 0.3415, -0.5296],\n",
            "        [ 0.3584, -0.4930],\n",
            "        [ 0.3295, -0.5270],\n",
            "        [ 0.4389, -0.5146],\n",
            "        [ 0.3797, -0.4879],\n",
            "        [ 0.3098, -0.4751],\n",
            "        [ 0.4310, -0.5084],\n",
            "        [ 0.3793, -0.4572],\n",
            "        [ 0.2880, -0.5450],\n",
            "        [ 0.3098, -0.5195],\n",
            "        [ 0.4450, -0.4315],\n",
            "        [ 0.4339, -0.4969],\n",
            "        [ 0.4101, -0.4901],\n",
            "        [ 0.3739, -0.5263],\n",
            "        [ 0.3798, -0.4880],\n",
            "        [ 0.4514, -0.4639],\n",
            "        [ 0.3503, -0.5305],\n",
            "        [ 0.4416, -0.4886],\n",
            "        [ 0.4221, -0.5678],\n",
            "        [ 0.4188, -0.4944],\n",
            "        [ 0.4462, -0.5164],\n",
            "        [ 0.4229, -0.4821],\n",
            "        [ 0.4081, -0.4662],\n",
            "        [ 0.4811, -0.4830],\n",
            "        [ 0.3956, -0.4826],\n",
            "        [ 0.3616, -0.4758],\n",
            "        [ 0.4154, -0.5041],\n",
            "        [ 0.3563, -0.5391],\n",
            "        [ 0.3082, -0.5171]], device='cuda:0')\n",
            "Logits:[[ 0.49219733 -0.44351035]\n",
            " [ 0.547362   -0.46595854]\n",
            " [ 0.40916932 -0.49037227]\n",
            " [ 0.34147212 -0.5296028 ]\n",
            " [ 0.35837394 -0.4930497 ]\n",
            " [ 0.32950965 -0.5270455 ]\n",
            " [ 0.43891856 -0.5146277 ]\n",
            " [ 0.3797402  -0.48787344]\n",
            " [ 0.30978808 -0.4750688 ]\n",
            " [ 0.43097383 -0.5083528 ]\n",
            " [ 0.37931266 -0.4571783 ]\n",
            " [ 0.28796366 -0.5450164 ]\n",
            " [ 0.30983543 -0.51948535]\n",
            " [ 0.44496444 -0.43149024]\n",
            " [ 0.43388516 -0.49690688]\n",
            " [ 0.41010845 -0.49011347]\n",
            " [ 0.3739207  -0.5262881 ]\n",
            " [ 0.37981284 -0.48799887]\n",
            " [ 0.451416   -0.46388853]\n",
            " [ 0.35030508 -0.5304911 ]\n",
            " [ 0.44156235 -0.4886044 ]\n",
            " [ 0.42213458 -0.5678244 ]\n",
            " [ 0.4188244  -0.49441046]\n",
            " [ 0.4461838  -0.51644915]\n",
            " [ 0.42293215 -0.48211366]\n",
            " [ 0.40809837 -0.46618137]\n",
            " [ 0.48113874 -0.4829738 ]\n",
            " [ 0.3955793  -0.48262084]\n",
            " [ 0.36157706 -0.47584796]\n",
            " [ 0.41544595 -0.50412506]\n",
            " [ 0.35629433 -0.53905135]\n",
            " [ 0.30820236 -0.5170727 ]]\n",
            "Labels:[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4754, -0.4511],\n",
            "        [ 0.3411, -0.5399],\n",
            "        [ 0.4277, -0.5109],\n",
            "        [ 0.4064, -0.4741],\n",
            "        [ 0.3792, -0.4457],\n",
            "        [ 0.4430, -0.5718],\n",
            "        [ 0.3333, -0.5199],\n",
            "        [ 0.3082, -0.5325],\n",
            "        [ 0.3718, -0.4301],\n",
            "        [ 0.1971, -0.4964],\n",
            "        [ 0.2738, -0.4550],\n",
            "        [ 0.2784, -0.4597],\n",
            "        [ 0.2394, -0.5063],\n",
            "        [ 0.3664, -0.4605],\n",
            "        [ 0.3360, -0.4634],\n",
            "        [ 0.1756, -0.5068],\n",
            "        [ 0.2551, -0.4809],\n",
            "        [ 0.2898, -0.5076],\n",
            "        [ 0.2507, -0.5557],\n",
            "        [ 0.2507, -0.5557],\n",
            "        [ 0.3536, -0.4405],\n",
            "        [ 0.3229, -0.4614],\n",
            "        [ 0.3128, -0.4332],\n",
            "        [ 0.3660, -0.4949],\n",
            "        [ 0.4447, -0.4681],\n",
            "        [ 0.3055, -0.4816],\n",
            "        [ 0.3055, -0.4816],\n",
            "        [ 0.3615, -0.4569],\n",
            "        [ 0.2870, -0.4859],\n",
            "        [ 0.3069, -0.4977],\n",
            "        [ 0.3855, -0.5295],\n",
            "        [ 0.2770, -0.5187]], device='cuda:0')\n",
            "Logits:[[ 0.47537717 -0.45111668]\n",
            " [ 0.3411273  -0.5399106 ]\n",
            " [ 0.42769575 -0.51090866]\n",
            " [ 0.406411   -0.47414687]\n",
            " [ 0.37922582 -0.44571835]\n",
            " [ 0.4430033  -0.5717543 ]\n",
            " [ 0.3332754  -0.5198693 ]\n",
            " [ 0.30816022 -0.53252405]\n",
            " [ 0.3718169  -0.43012866]\n",
            " [ 0.19713832 -0.4963965 ]\n",
            " [ 0.27376497 -0.4549556 ]\n",
            " [ 0.27835295 -0.45967817]\n",
            " [ 0.23939249 -0.50625896]\n",
            " [ 0.3664285  -0.4604881 ]\n",
            " [ 0.33600745 -0.4634346 ]\n",
            " [ 0.17559336 -0.5068239 ]\n",
            " [ 0.255122   -0.48094916]\n",
            " [ 0.28980994 -0.5075507 ]\n",
            " [ 0.2506554  -0.5556678 ]\n",
            " [ 0.2506554  -0.5556678 ]\n",
            " [ 0.3536465  -0.44054502]\n",
            " [ 0.32287955 -0.4613808 ]\n",
            " [ 0.31275976 -0.433188  ]\n",
            " [ 0.36599848 -0.49486348]\n",
            " [ 0.4446785  -0.4680542 ]\n",
            " [ 0.3055244  -0.48156863]\n",
            " [ 0.3055244  -0.48156863]\n",
            " [ 0.36146635 -0.45690355]\n",
            " [ 0.28702664 -0.48593014]\n",
            " [ 0.30686158 -0.49772248]\n",
            " [ 0.38550824 -0.52954453]\n",
            " [ 0.27704167 -0.5187234 ]]\n",
            "Labels:[0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.1872, -0.5329],\n",
            "        [ 0.1542, -0.5445],\n",
            "        [ 0.3004, -0.5232],\n",
            "        [ 0.3718, -0.4301],\n",
            "        [ 0.3360, -0.4634],\n",
            "        [ 0.3624, -0.3873],\n",
            "        [ 0.5212, -0.4561],\n",
            "        [ 0.4168, -0.5027],\n",
            "        [ 0.4604, -0.4625],\n",
            "        [ 0.4298, -0.4720],\n",
            "        [ 0.5418, -0.4406],\n",
            "        [ 0.4604, -0.4625],\n",
            "        [ 0.4181, -0.4583],\n",
            "        [ 0.4454, -0.5107],\n",
            "        [ 0.4888, -0.4146],\n",
            "        [ 0.2134, -0.2290],\n",
            "        [ 0.4575, -0.4638],\n",
            "        [ 0.4348, -0.4543],\n",
            "        [ 0.4917, -0.4411],\n",
            "        [ 0.4956, -0.3941],\n",
            "        [ 0.4447, -0.4594],\n",
            "        [ 0.4389, -0.5153],\n",
            "        [ 0.4938, -0.4745],\n",
            "        [ 0.5054, -0.4229],\n",
            "        [ 0.5133, -0.4814],\n",
            "        [ 0.4722, -0.4893],\n",
            "        [ 0.4582, -0.4471],\n",
            "        [ 0.2134, -0.2290],\n",
            "        [ 0.4897, -0.3705],\n",
            "        [ 0.4842, -0.4731],\n",
            "        [ 0.4545, -0.5273],\n",
            "        [ 0.4595, -0.4626]], device='cuda:0')\n",
            "Logits:[[ 0.18718132 -0.53287065]\n",
            " [ 0.15417664 -0.54450434]\n",
            " [ 0.30038318 -0.5232432 ]\n",
            " [ 0.3718169  -0.43012866]\n",
            " [ 0.33600745 -0.4634346 ]\n",
            " [ 0.3624335  -0.38728684]\n",
            " [ 0.52115834 -0.45611438]\n",
            " [ 0.41675654 -0.5027408 ]\n",
            " [ 0.46037668 -0.4625094 ]\n",
            " [ 0.42984068 -0.4720351 ]\n",
            " [ 0.54180425 -0.44055402]\n",
            " [ 0.46037668 -0.4625094 ]\n",
            " [ 0.4180679  -0.45831934]\n",
            " [ 0.44543454 -0.5107161 ]\n",
            " [ 0.48882023 -0.4146403 ]\n",
            " [ 0.21338151 -0.22904544]\n",
            " [ 0.4575184  -0.46378607]\n",
            " [ 0.4348224  -0.4542567 ]\n",
            " [ 0.49170834 -0.44113296]\n",
            " [ 0.49558347 -0.39410424]\n",
            " [ 0.4446942  -0.4593799 ]\n",
            " [ 0.43886882 -0.515336  ]\n",
            " [ 0.4938173  -0.47449005]\n",
            " [ 0.5054209  -0.422935  ]\n",
            " [ 0.5132563  -0.48143682]\n",
            " [ 0.47216514 -0.48926353]\n",
            " [ 0.45818022 -0.44708326]\n",
            " [ 0.21338151 -0.22904544]\n",
            " [ 0.4896909  -0.37048748]\n",
            " [ 0.48419183 -0.47307828]\n",
            " [ 0.45445037 -0.52731895]\n",
            " [ 0.45946053 -0.46255633]]\n",
            "Labels:[0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
            "Logits_each:tensor([[ 0.5234, -0.4558],\n",
            "        [ 0.3889, -0.4053],\n",
            "        [ 0.3290, -0.3573],\n",
            "        [ 0.3290, -0.3573],\n",
            "        [ 0.2917, -0.3691],\n",
            "        [ 0.2917, -0.3691],\n",
            "        [ 0.3540, -0.3642],\n",
            "        [ 0.3540, -0.3642],\n",
            "        [ 0.2645, -0.4793],\n",
            "        [ 0.2645, -0.4793],\n",
            "        [ 0.2645, -0.4793],\n",
            "        [ 0.3959, -0.4069],\n",
            "        [ 0.4715, -0.3536],\n",
            "        [ 0.4451, -0.4490],\n",
            "        [ 0.4572, -0.3765],\n",
            "        [ 0.3454, -0.3611],\n",
            "        [ 0.4028, -0.5618],\n",
            "        [ 0.4722, -0.5201],\n",
            "        [ 0.3969, -0.5739],\n",
            "        [ 0.3486, -0.5346],\n",
            "        [ 0.3757, -0.5567],\n",
            "        [ 0.3307, -0.5612],\n",
            "        [ 0.3232, -0.5624],\n",
            "        [ 0.3973, -0.4761],\n",
            "        [ 0.3020, -0.6187],\n",
            "        [ 0.4173, -0.5746],\n",
            "        [ 0.3809, -0.5668],\n",
            "        [ 0.3566, -0.6183],\n",
            "        [ 0.3718, -0.5686],\n",
            "        [ 0.3718, -0.5995],\n",
            "        [ 0.3458, -0.5587],\n",
            "        [ 0.3586, -0.4847]], device='cuda:0')\n",
            "Logits:[[ 0.52335805 -0.45580807]\n",
            " [ 0.38892174 -0.40527382]\n",
            " [ 0.32895264 -0.35734433]\n",
            " [ 0.32895264 -0.35734433]\n",
            " [ 0.2916681  -0.36906257]\n",
            " [ 0.2916681  -0.36906257]\n",
            " [ 0.35403058 -0.3642094 ]\n",
            " [ 0.35403058 -0.3642094 ]\n",
            " [ 0.26449776 -0.47929   ]\n",
            " [ 0.26449776 -0.47929   ]\n",
            " [ 0.26449776 -0.47929   ]\n",
            " [ 0.39594787 -0.40692195]\n",
            " [ 0.47154638 -0.3535548 ]\n",
            " [ 0.44508374 -0.4490047 ]\n",
            " [ 0.45720005 -0.37653363]\n",
            " [ 0.345354   -0.3610793 ]\n",
            " [ 0.402803   -0.5617572 ]\n",
            " [ 0.4722186  -0.5200972 ]\n",
            " [ 0.39691374 -0.57392544]\n",
            " [ 0.34859467 -0.5345961 ]\n",
            " [ 0.3756924  -0.55668664]\n",
            " [ 0.3307488  -0.5611746 ]\n",
            " [ 0.32323843 -0.56243974]\n",
            " [ 0.39726377 -0.4760862 ]\n",
            " [ 0.30203286 -0.618724  ]\n",
            " [ 0.41730586 -0.5746211 ]\n",
            " [ 0.38087702 -0.56676334]\n",
            " [ 0.35656714 -0.61831737]\n",
            " [ 0.37175366 -0.5685951 ]\n",
            " [ 0.37176538 -0.59950566]\n",
            " [ 0.34578618 -0.55866474]\n",
            " [ 0.35857874 -0.4847237 ]]\n",
            "Labels:[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3710, -0.5530],\n",
            "        [ 0.4356, -0.5426],\n",
            "        [ 0.3147, -0.5581],\n",
            "        [ 0.3319, -0.5467],\n",
            "        [ 0.4534, -0.5016],\n",
            "        [ 0.3340, -0.5137],\n",
            "        [ 0.3945, -0.5535],\n",
            "        [ 0.4531, -0.5315],\n",
            "        [ 0.3338, -0.5400],\n",
            "        [ 0.3176, -0.6008],\n",
            "        [ 0.3442, -0.4997],\n",
            "        [ 0.3365, -0.6248],\n",
            "        [ 0.4237, -0.4515],\n",
            "        [ 0.4512, -0.4739],\n",
            "        [ 0.4255, -0.4856],\n",
            "        [ 0.3802, -0.4207],\n",
            "        [ 0.3536, -0.5060],\n",
            "        [ 0.3399, -0.3592],\n",
            "        [ 0.3938, -0.3723],\n",
            "        [ 0.3466, -0.4433],\n",
            "        [ 0.2817, -0.4531],\n",
            "        [ 0.4419, -0.4683],\n",
            "        [ 0.3369, -0.4614],\n",
            "        [ 0.3620, -0.5320],\n",
            "        [ 0.3746, -0.4389],\n",
            "        [ 0.3713, -0.5081],\n",
            "        [ 0.3621, -0.4575],\n",
            "        [ 0.4006, -0.4624],\n",
            "        [ 0.2520, -0.5324],\n",
            "        [ 0.1817, -0.4839],\n",
            "        [ 0.4697, -0.3291],\n",
            "        [ 0.3102, -0.4412]], device='cuda:0')\n",
            "Logits:[[ 0.3709632  -0.5529644 ]\n",
            " [ 0.4355982  -0.5426333 ]\n",
            " [ 0.31470183 -0.5580803 ]\n",
            " [ 0.3319397  -0.54667854]\n",
            " [ 0.45336667 -0.5016381 ]\n",
            " [ 0.33397314 -0.51369566]\n",
            " [ 0.3945192  -0.5535108 ]\n",
            " [ 0.45309225 -0.5314916 ]\n",
            " [ 0.3337703  -0.54002565]\n",
            " [ 0.31759074 -0.6008367 ]\n",
            " [ 0.34418344 -0.49970534]\n",
            " [ 0.33647302 -0.6247513 ]\n",
            " [ 0.4236675  -0.45152223]\n",
            " [ 0.45124993 -0.47388595]\n",
            " [ 0.42554286 -0.48555744]\n",
            " [ 0.3801763  -0.4207412 ]\n",
            " [ 0.35357496 -0.5060091 ]\n",
            " [ 0.33989975 -0.35920322]\n",
            " [ 0.393805   -0.3723461 ]\n",
            " [ 0.34660825 -0.44333506]\n",
            " [ 0.28169107 -0.4531346 ]\n",
            " [ 0.44192973 -0.4682999 ]\n",
            " [ 0.33688003 -0.4613589 ]\n",
            " [ 0.36201897 -0.5320483 ]\n",
            " [ 0.37462917 -0.43890285]\n",
            " [ 0.3712665  -0.50813574]\n",
            " [ 0.3621321  -0.45752397]\n",
            " [ 0.40062317 -0.46243134]\n",
            " [ 0.25200713 -0.53243524]\n",
            " [ 0.18168874 -0.48388645]\n",
            " [ 0.46970376 -0.32906875]\n",
            " [ 0.31022972 -0.44119006]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1]\n",
            "Logits_each:tensor([[ 0.2591, -0.4391],\n",
            "        [ 0.3705, -0.4390],\n",
            "        [ 0.4432, -0.4723],\n",
            "        [ 0.4295, -0.4952],\n",
            "        [ 0.3946, -0.4302],\n",
            "        [ 0.3295, -0.4508],\n",
            "        [ 0.3498, -0.4991],\n",
            "        [ 0.1342, -0.4963],\n",
            "        [ 0.4238, -0.4643],\n",
            "        [ 0.3864, -0.4560],\n",
            "        [ 0.3665, -0.4727],\n",
            "        [ 0.3621, -0.4854],\n",
            "        [ 0.2321, -0.4410],\n",
            "        [ 0.4021, -0.4895],\n",
            "        [ 0.3824, -0.4993],\n",
            "        [ 0.3647, -0.4879],\n",
            "        [ 0.4257, -0.4432],\n",
            "        [ 0.2939, -0.5022],\n",
            "        [ 0.3201, -0.5087],\n",
            "        [ 0.3900, -0.4461],\n",
            "        [ 0.4065, -0.4958],\n",
            "        [ 0.3661, -0.5382],\n",
            "        [ 0.3431, -0.5368],\n",
            "        [ 0.4242, -0.5010],\n",
            "        [ 0.2302, -0.3014],\n",
            "        [ 0.3217, -0.5111],\n",
            "        [ 0.3728, -0.5242],\n",
            "        [ 0.4338, -0.4980],\n",
            "        [ 0.3563, -0.5308],\n",
            "        [ 0.4671, -0.4790],\n",
            "        [ 0.4293, -0.5745],\n",
            "        [ 0.3463, -0.5288]], device='cuda:0')\n",
            "Logits:[[ 0.2591231  -0.43909755]\n",
            " [ 0.37049317 -0.43898165]\n",
            " [ 0.4431788  -0.4722683 ]\n",
            " [ 0.42954773 -0.49516875]\n",
            " [ 0.39457995 -0.43017966]\n",
            " [ 0.32950234 -0.45083338]\n",
            " [ 0.34976116 -0.49911642]\n",
            " [ 0.13420205 -0.49626943]\n",
            " [ 0.4238228  -0.4643321 ]\n",
            " [ 0.38637283 -0.4559722 ]\n",
            " [ 0.36652347 -0.47273168]\n",
            " [ 0.3621239  -0.48538476]\n",
            " [ 0.23207723 -0.4409843 ]\n",
            " [ 0.4020909  -0.4895043 ]\n",
            " [ 0.38244    -0.4993475 ]\n",
            " [ 0.36474156 -0.4878648 ]\n",
            " [ 0.42568052 -0.4431607 ]\n",
            " [ 0.29389298 -0.5021642 ]\n",
            " [ 0.32009572 -0.5086684 ]\n",
            " [ 0.39003688 -0.44610956]\n",
            " [ 0.4065185  -0.4958496 ]\n",
            " [ 0.3660589  -0.5382338 ]\n",
            " [ 0.34307957 -0.53684664]\n",
            " [ 0.424241   -0.5010307 ]\n",
            " [ 0.23018001 -0.30140647]\n",
            " [ 0.32169583 -0.51106966]\n",
            " [ 0.37281546 -0.52419525]\n",
            " [ 0.43378443 -0.4979986 ]\n",
            " [ 0.35627985 -0.530774  ]\n",
            " [ 0.46705294 -0.47895965]\n",
            " [ 0.42932656 -0.5744798 ]\n",
            " [ 0.34627727 -0.52883345]]\n",
            "Labels:[0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3307, -0.4878],\n",
            "        [ 0.4858, -0.4708],\n",
            "        [ 0.3665, -0.4627],\n",
            "        [ 0.4012, -0.4770],\n",
            "        [ 0.4538, -0.4106],\n",
            "        [ 0.3342, -0.4782],\n",
            "        [ 0.3313, -0.4156],\n",
            "        [ 0.3986, -0.4661],\n",
            "        [ 0.4760, -0.5076],\n",
            "        [ 0.4333, -0.4810],\n",
            "        [ 0.3666, -0.4892],\n",
            "        [ 0.5014, -0.4831],\n",
            "        [ 0.3973, -0.4508],\n",
            "        [ 0.4422, -0.4861],\n",
            "        [ 0.4807, -0.5143],\n",
            "        [ 0.4061, -0.5939],\n",
            "        [ 0.4353, -0.4486],\n",
            "        [ 0.4772, -0.4439],\n",
            "        [ 0.4767, -0.4655],\n",
            "        [ 0.3928, -0.4952],\n",
            "        [ 0.3915, -0.4875],\n",
            "        [ 0.4173, -0.4475],\n",
            "        [ 0.4198, -0.4869],\n",
            "        [ 0.3780, -0.4325],\n",
            "        [ 0.3780, -0.4325],\n",
            "        [ 0.4768, -0.3861],\n",
            "        [ 0.2828, -0.5350],\n",
            "        [ 0.4053, -0.4639],\n",
            "        [ 0.4156, -0.4636],\n",
            "        [ 0.4362, -0.4464],\n",
            "        [ 0.4164, -0.5296],\n",
            "        [ 0.3135, -0.5448]], device='cuda:0')\n",
            "Logits:[[ 0.33073348 -0.48775825]\n",
            " [ 0.48583192 -0.47081146]\n",
            " [ 0.36648417 -0.46266246]\n",
            " [ 0.40117982 -0.47702953]\n",
            " [ 0.45377874 -0.41064426]\n",
            " [ 0.33421353 -0.47820103]\n",
            " [ 0.33127785 -0.41562843]\n",
            " [ 0.3985628  -0.46610662]\n",
            " [ 0.47595426 -0.50763696]\n",
            " [ 0.4332808  -0.48104107]\n",
            " [ 0.3666372  -0.48916486]\n",
            " [ 0.5013686  -0.4831273 ]\n",
            " [ 0.39728478 -0.4508358 ]\n",
            " [ 0.44220036 -0.486129  ]\n",
            " [ 0.4807128  -0.5143435 ]\n",
            " [ 0.40610167 -0.5938731 ]\n",
            " [ 0.43533838 -0.44855353]\n",
            " [ 0.4771962  -0.44385067]\n",
            " [ 0.47669187 -0.46551195]\n",
            " [ 0.39282045 -0.4951521 ]\n",
            " [ 0.39151967 -0.48746234]\n",
            " [ 0.4173203  -0.44753668]\n",
            " [ 0.41980568 -0.48687226]\n",
            " [ 0.3779839  -0.43250668]\n",
            " [ 0.3779839  -0.43250668]\n",
            " [ 0.4767646  -0.38609108]\n",
            " [ 0.28280562 -0.53500575]\n",
            " [ 0.40533608 -0.463887  ]\n",
            " [ 0.41561997 -0.46359026]\n",
            " [ 0.4361974  -0.44644374]\n",
            " [ 0.41641346 -0.52964205]\n",
            " [ 0.3134838  -0.5447631 ]]\n",
            "Labels:[0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1]\n",
            "Logits_each:tensor([[ 0.3658, -0.5424],\n",
            "        [ 0.3920, -0.5784],\n",
            "        [ 0.4310, -0.5689],\n",
            "        [ 0.3792, -0.5895],\n",
            "        [ 0.4366, -0.6113],\n",
            "        [ 0.2604, -0.5628],\n",
            "        [ 0.4628, -0.5468],\n",
            "        [ 0.4148, -0.5511],\n",
            "        [ 0.3505, -0.5318],\n",
            "        [ 0.2839, -0.5107],\n",
            "        [ 0.3527, -0.5607],\n",
            "        [ 0.2190, -0.5486],\n",
            "        [ 0.4334, -0.5876],\n",
            "        [ 0.4235, -0.5329],\n",
            "        [ 0.2790, -0.5002],\n",
            "        [ 0.3245, -0.5616],\n",
            "        [ 0.3806, -0.5329],\n",
            "        [ 0.3250, -0.6265],\n",
            "        [ 0.4605, -0.5034],\n",
            "        [ 0.3706, -0.5643],\n",
            "        [ 0.3792, -0.5497],\n",
            "        [ 0.2495, -0.5098],\n",
            "        [ 0.3850, -0.5650],\n",
            "        [ 0.3854, -0.5462],\n",
            "        [ 0.3403, -0.5442],\n",
            "        [ 0.3411, -0.5561],\n",
            "        [ 0.3756, -0.5449],\n",
            "        [ 0.2958, -0.5703],\n",
            "        [ 0.3155, -0.5386],\n",
            "        [ 0.3474, -0.5479],\n",
            "        [ 0.2130, -0.4723],\n",
            "        [ 0.3570, -0.5237]], device='cuda:0')\n",
            "Logits:[[ 0.3658265  -0.5423882 ]\n",
            " [ 0.39200222 -0.5784344 ]\n",
            " [ 0.43103975 -0.5689276 ]\n",
            " [ 0.3792191  -0.589528  ]\n",
            " [ 0.4365825  -0.61132646]\n",
            " [ 0.26038125 -0.56284636]\n",
            " [ 0.46279415 -0.5468008 ]\n",
            " [ 0.41477558 -0.55111605]\n",
            " [ 0.35054424 -0.5318315 ]\n",
            " [ 0.28392792 -0.5106584 ]\n",
            " [ 0.35267058 -0.5606552 ]\n",
            " [ 0.21897447 -0.5485976 ]\n",
            " [ 0.4334226  -0.5875795 ]\n",
            " [ 0.42352465 -0.532905  ]\n",
            " [ 0.2790437  -0.5001759 ]\n",
            " [ 0.32447398 -0.5616192 ]\n",
            " [ 0.3805902  -0.5328762 ]\n",
            " [ 0.3250022  -0.6265294 ]\n",
            " [ 0.46054313 -0.50335604]\n",
            " [ 0.37056842 -0.5642633 ]\n",
            " [ 0.3792485  -0.54969424]\n",
            " [ 0.24951541 -0.5098067 ]\n",
            " [ 0.38498256 -0.5650486 ]\n",
            " [ 0.3853628  -0.54621434]\n",
            " [ 0.34033746 -0.5441506 ]\n",
            " [ 0.34110212 -0.55605847]\n",
            " [ 0.3756269  -0.54489934]\n",
            " [ 0.2958367  -0.57030517]\n",
            " [ 0.31547204 -0.53863174]\n",
            " [ 0.3473753  -0.5478618 ]\n",
            " [ 0.21298787 -0.47232816]\n",
            " [ 0.35699657 -0.5236621 ]]\n",
            "Labels:[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4333, -0.4566],\n",
            "        [ 0.4260, -0.5147],\n",
            "        [ 0.4338, -0.5201],\n",
            "        [ 0.4338, -0.5201],\n",
            "        [ 0.4338, -0.5201],\n",
            "        [ 0.4338, -0.5201],\n",
            "        [ 0.4338, -0.5201],\n",
            "        [ 0.3194, -0.5757],\n",
            "        [ 0.3194, -0.5757],\n",
            "        [ 0.3194, -0.5757],\n",
            "        [ 0.4206, -0.4707],\n",
            "        [ 0.5322, -0.4973],\n",
            "        [ 0.5224, -0.4925],\n",
            "        [ 0.4128, -0.5660],\n",
            "        [ 0.4587, -0.5597],\n",
            "        [ 0.4329, -0.5555],\n",
            "        [ 0.0249, -0.3071],\n",
            "        [ 0.1416, -0.5788],\n",
            "        [ 0.3026, -0.6160],\n",
            "        [ 0.3496, -0.5576],\n",
            "        [ 0.2414, -0.5404],\n",
            "        [ 0.6322, -0.5201],\n",
            "        [ 0.2414, -0.5404],\n",
            "        [ 0.3344, -0.5127],\n",
            "        [ 0.3344, -0.5127],\n",
            "        [ 0.2747, -0.5799],\n",
            "        [ 0.2529, -0.5678],\n",
            "        [ 0.4645, -0.4453],\n",
            "        [ 0.3926, -0.4674],\n",
            "        [ 0.4101, -0.5569],\n",
            "        [ 0.4118, -0.5191],\n",
            "        [ 0.4401, -0.5359]], device='cuda:0')\n",
            "Logits:[[ 0.4333299  -0.45664373]\n",
            " [ 0.4259603  -0.5146625 ]\n",
            " [ 0.4337808  -0.52013373]\n",
            " [ 0.4337808  -0.52013373]\n",
            " [ 0.4337808  -0.52013373]\n",
            " [ 0.4337808  -0.52013373]\n",
            " [ 0.4337808  -0.52013373]\n",
            " [ 0.31940985 -0.57569003]\n",
            " [ 0.31940985 -0.57569003]\n",
            " [ 0.31940985 -0.57569003]\n",
            " [ 0.42058796 -0.47067   ]\n",
            " [ 0.5322124  -0.49725947]\n",
            " [ 0.52243614 -0.49246764]\n",
            " [ 0.4127838  -0.56596744]\n",
            " [ 0.45870033 -0.5597328 ]\n",
            " [ 0.43287474 -0.5554934 ]\n",
            " [ 0.02491545 -0.30714864]\n",
            " [ 0.14160143 -0.5787632 ]\n",
            " [ 0.30255437 -0.6159536 ]\n",
            " [ 0.34961358 -0.55762184]\n",
            " [ 0.24144475 -0.5404283 ]\n",
            " [ 0.63223886 -0.5200892 ]\n",
            " [ 0.24144475 -0.5404283 ]\n",
            " [ 0.3344008  -0.5126925 ]\n",
            " [ 0.3344008  -0.5126925 ]\n",
            " [ 0.27474272 -0.57985777]\n",
            " [ 0.25285769 -0.5677655 ]\n",
            " [ 0.4644569  -0.44531327]\n",
            " [ 0.39256865 -0.46741527]\n",
            " [ 0.41011703 -0.5569378 ]\n",
            " [ 0.4117813  -0.5190508 ]\n",
            " [ 0.4401247  -0.5359194 ]]\n",
            "Labels:[1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1]\n",
            "Logits_each:tensor([[ 0.4058, -0.5124],\n",
            "        [ 0.4166, -0.5388],\n",
            "        [ 0.4187, -0.4766],\n",
            "        [ 0.4581, -0.4825],\n",
            "        [ 0.4787, -0.5048],\n",
            "        [ 0.3994, -0.5424],\n",
            "        [ 0.3725, -0.5034],\n",
            "        [ 0.4932, -0.5122],\n",
            "        [ 0.5790, -0.5102],\n",
            "        [ 0.4038, -0.5272],\n",
            "        [ 0.4008, -0.5235],\n",
            "        [ 0.3920, -0.4945],\n",
            "        [ 0.4248, -0.5175],\n",
            "        [ 0.4556, -0.5150],\n",
            "        [ 0.4346, -0.5066],\n",
            "        [ 0.4687, -0.4782],\n",
            "        [ 0.5090, -0.4361],\n",
            "        [ 0.5122, -0.4931],\n",
            "        [ 0.4442, -0.4591],\n",
            "        [ 0.4579, -0.5052],\n",
            "        [ 0.4416, -0.4225],\n",
            "        [ 0.4369, -0.5111],\n",
            "        [ 0.4800, -0.4533],\n",
            "        [ 0.4500, -0.4588],\n",
            "        [ 0.4137, -0.4514],\n",
            "        [ 0.3939, -0.4984],\n",
            "        [ 0.3690, -0.5276],\n",
            "        [ 0.3843, -0.5233],\n",
            "        [ 0.3202, -0.5152],\n",
            "        [ 0.3623, -0.4832],\n",
            "        [ 0.3347, -0.5185],\n",
            "        [ 0.3867, -0.3890]], device='cuda:0')\n",
            "Logits:[[ 0.4057536  -0.51244444]\n",
            " [ 0.4166444  -0.5388068 ]\n",
            " [ 0.41869015 -0.47658047]\n",
            " [ 0.4580942  -0.48249057]\n",
            " [ 0.47869983 -0.50483066]\n",
            " [ 0.39942917 -0.54237586]\n",
            " [ 0.37249395 -0.50336325]\n",
            " [ 0.49316242 -0.51219153]\n",
            " [ 0.57904243 -0.5101851 ]\n",
            " [ 0.40377676 -0.5272282 ]\n",
            " [ 0.40082258 -0.523456  ]\n",
            " [ 0.39197153 -0.49451163]\n",
            " [ 0.42484415 -0.51754844]\n",
            " [ 0.4555963  -0.5150385 ]\n",
            " [ 0.4346212  -0.5066033 ]\n",
            " [ 0.4687162  -0.4781524 ]\n",
            " [ 0.5089961  -0.43612373]\n",
            " [ 0.51216817 -0.49307084]\n",
            " [ 0.4441837  -0.4591019 ]\n",
            " [ 0.4578807  -0.5051649 ]\n",
            " [ 0.44159576 -0.4224556 ]\n",
            " [ 0.43685555 -0.51107657]\n",
            " [ 0.48004264 -0.45329204]\n",
            " [ 0.4500491  -0.45880944]\n",
            " [ 0.4137239  -0.4513556 ]\n",
            " [ 0.39387727 -0.4984241 ]\n",
            " [ 0.36902094 -0.52755743]\n",
            " [ 0.38432014 -0.52326393]\n",
            " [ 0.32018363 -0.5152462 ]\n",
            " [ 0.36233637 -0.48321247]\n",
            " [ 0.33470523 -0.518478  ]\n",
            " [ 0.38669375 -0.38903955]]\n",
            "Labels:[1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1]\n",
            "Logits_each:tensor([[ 0.3755, -0.4992],\n",
            "        [ 0.3762, -0.4616],\n",
            "        [ 0.3533, -0.4561],\n",
            "        [ 0.4074, -0.4891],\n",
            "        [ 0.4550, -0.4612],\n",
            "        [ 0.3473, -0.4914],\n",
            "        [ 0.3494, -0.4797],\n",
            "        [ 0.3815, -0.4970],\n",
            "        [ 0.3096, -0.5261],\n",
            "        [ 0.3096, -0.4284],\n",
            "        [ 0.3203, -0.4523],\n",
            "        [ 0.4254, -0.4891],\n",
            "        [ 0.2381, -0.4848],\n",
            "        [ 0.3524, -0.4201],\n",
            "        [ 0.3030, -0.4567],\n",
            "        [ 0.3993, -0.4986],\n",
            "        [ 0.2810, -0.5494],\n",
            "        [ 0.2743, -0.5334],\n",
            "        [ 0.2774, -0.5071],\n",
            "        [ 0.4157, -0.4873],\n",
            "        [ 0.3036, -0.5019],\n",
            "        [ 0.2656, -0.4748],\n",
            "        [ 0.3089, -0.4659],\n",
            "        [ 0.3718, -0.4735],\n",
            "        [ 0.3170, -0.5031],\n",
            "        [ 0.2864, -0.5070],\n",
            "        [ 0.2793, -0.4747],\n",
            "        [ 0.2443, -0.5116],\n",
            "        [ 0.3327, -0.4339],\n",
            "        [ 0.2922, -0.5091],\n",
            "        [ 0.4760, -0.5034],\n",
            "        [ 0.3646, -0.4622]], device='cuda:0')\n",
            "Logits:[[ 0.37550583 -0.4991864 ]\n",
            " [ 0.3761668  -0.46157697]\n",
            " [ 0.35327718 -0.45613262]\n",
            " [ 0.40737805 -0.48909357]\n",
            " [ 0.45504    -0.461206  ]\n",
            " [ 0.34725899 -0.49136105]\n",
            " [ 0.34940937 -0.4797336 ]\n",
            " [ 0.38151306 -0.49701494]\n",
            " [ 0.30960366 -0.5261011 ]\n",
            " [ 0.30958992 -0.42836413]\n",
            " [ 0.3203004  -0.4523233 ]\n",
            " [ 0.42536068 -0.48914674]\n",
            " [ 0.23813511 -0.48481604]\n",
            " [ 0.35244745 -0.4201085 ]\n",
            " [ 0.3029559  -0.4566699 ]\n",
            " [ 0.39928222 -0.49864987]\n",
            " [ 0.2809975  -0.549404  ]\n",
            " [ 0.2743429  -0.533357  ]\n",
            " [ 0.27736804 -0.5071122 ]\n",
            " [ 0.41568017 -0.48732036]\n",
            " [ 0.30358618 -0.50190127]\n",
            " [ 0.265571   -0.4748184 ]\n",
            " [ 0.30885687 -0.46587497]\n",
            " [ 0.37178063 -0.47346458]\n",
            " [ 0.31703073 -0.5030709 ]\n",
            " [ 0.28636354 -0.5069653 ]\n",
            " [ 0.27932924 -0.47471723]\n",
            " [ 0.24427642 -0.51164585]\n",
            " [ 0.3326674  -0.43393606]\n",
            " [ 0.29224756 -0.5091104 ]\n",
            " [ 0.47602314 -0.50339997]\n",
            " [ 0.36461687 -0.46220484]]\n",
            "Labels:[0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3313, -0.5526],\n",
            "        [ 0.4191, -0.4994],\n",
            "        [ 0.1998, -0.5061],\n",
            "        [ 0.4598, -0.5034],\n",
            "        [ 0.4348, -0.5456],\n",
            "        [ 0.4374, -0.5394],\n",
            "        [ 0.4733, -0.5191],\n",
            "        [ 0.4537, -0.4695],\n",
            "        [ 0.4649, -0.5098],\n",
            "        [ 0.4531, -0.4869],\n",
            "        [ 0.4588, -0.4876],\n",
            "        [ 0.4475, -0.4626],\n",
            "        [ 0.4862, -0.4642],\n",
            "        [ 0.4427, -0.4631],\n",
            "        [ 0.4959, -0.5100],\n",
            "        [ 0.3986, -0.5344],\n",
            "        [ 0.4093, -0.4537],\n",
            "        [ 0.4377, -0.4962],\n",
            "        [ 0.4757, -0.4497],\n",
            "        [ 0.5395, -0.4772],\n",
            "        [ 0.4383, -0.5023],\n",
            "        [ 0.4594, -0.4843],\n",
            "        [ 0.4692, -0.4739],\n",
            "        [ 0.4696, -0.5048],\n",
            "        [ 0.4327, -0.5031],\n",
            "        [ 0.4988, -0.4612],\n",
            "        [ 0.4410, -0.5101],\n",
            "        [ 0.4612, -0.4896],\n",
            "        [ 0.4672, -0.4842],\n",
            "        [ 0.4697, -0.4788],\n",
            "        [ 0.4632, -0.4552],\n",
            "        [ 0.4147, -0.5500]], device='cuda:0')\n",
            "Logits:[[ 0.33128366 -0.55261374]\n",
            " [ 0.41911605 -0.4993608 ]\n",
            " [ 0.19976272 -0.50614756]\n",
            " [ 0.45978266 -0.5034305 ]\n",
            " [ 0.4348325  -0.54559946]\n",
            " [ 0.43744898 -0.5394402 ]\n",
            " [ 0.47328788 -0.51908624]\n",
            " [ 0.4537103  -0.46946004]\n",
            " [ 0.46494573 -0.5098155 ]\n",
            " [ 0.45306045 -0.48694536]\n",
            " [ 0.45881695 -0.48762584]\n",
            " [ 0.44750008 -0.46262765]\n",
            " [ 0.48624623 -0.46420243]\n",
            " [ 0.44270465 -0.4631301 ]\n",
            " [ 0.49590793 -0.5099807 ]\n",
            " [ 0.39859274 -0.5344492 ]\n",
            " [ 0.40929452 -0.45371833]\n",
            " [ 0.43769524 -0.49622634]\n",
            " [ 0.47568706 -0.44965458]\n",
            " [ 0.53949445 -0.4772493 ]\n",
            " [ 0.43832874 -0.5023353 ]\n",
            " [ 0.45941243 -0.48425797]\n",
            " [ 0.46920747 -0.47387826]\n",
            " [ 0.46964407 -0.5048081 ]\n",
            " [ 0.43270868 -0.503073  ]\n",
            " [ 0.4988368  -0.46115932]\n",
            " [ 0.44096056 -0.5101239 ]\n",
            " [ 0.46116078 -0.48956734]\n",
            " [ 0.46716416 -0.4842413 ]\n",
            " [ 0.46969542 -0.47882947]\n",
            " [ 0.4631506  -0.45522726]\n",
            " [ 0.41472    -0.5500073 ]]\n",
            "Labels:[1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4103, -0.4828],\n",
            "        [ 0.4666, -0.4833],\n",
            "        [ 0.4765, -0.5197],\n",
            "        [ 0.4649, -0.4976],\n",
            "        [ 0.3874, -0.5185],\n",
            "        [ 0.4520, -0.4926],\n",
            "        [ 0.4404, -0.4995],\n",
            "        [ 0.3956, -0.5195],\n",
            "        [ 0.4362, -0.3623],\n",
            "        [ 0.2154, -0.4821],\n",
            "        [ 0.3638, -0.4693],\n",
            "        [ 0.3492, -0.5019],\n",
            "        [ 0.4109, -0.4476],\n",
            "        [ 0.4109, -0.4476],\n",
            "        [ 0.3768, -0.4926],\n",
            "        [ 0.3604, -0.5117],\n",
            "        [ 0.3943, -0.4407],\n",
            "        [ 0.3442, -0.4815],\n",
            "        [ 0.4458, -0.4183],\n",
            "        [ 0.3891, -0.4143],\n",
            "        [ 0.3646, -0.5237],\n",
            "        [ 0.3646, -0.5237],\n",
            "        [ 0.4107, -0.5040],\n",
            "        [ 0.3550, -0.4575],\n",
            "        [ 0.3297, -0.4917],\n",
            "        [ 0.4555, -0.4875],\n",
            "        [ 0.4550, -0.5044],\n",
            "        [ 0.2977, -0.5507],\n",
            "        [ 0.3474, -0.5061],\n",
            "        [ 0.3105, -0.5400],\n",
            "        [ 0.3586, -0.5010],\n",
            "        [ 0.1838, -0.5304]], device='cuda:0')\n",
            "Logits:[[ 0.4102698  -0.48283517]\n",
            " [ 0.4665879  -0.4833047 ]\n",
            " [ 0.47651067 -0.5197195 ]\n",
            " [ 0.46489373 -0.49755225]\n",
            " [ 0.38744378 -0.5185091 ]\n",
            " [ 0.45201015 -0.49255535]\n",
            " [ 0.44036573 -0.49952608]\n",
            " [ 0.39561656 -0.51950055]\n",
            " [ 0.43623087 -0.36232603]\n",
            " [ 0.21537961 -0.48210683]\n",
            " [ 0.36381066 -0.46934187]\n",
            " [ 0.34921125 -0.5019492 ]\n",
            " [ 0.4108768  -0.44755757]\n",
            " [ 0.4108768  -0.44755757]\n",
            " [ 0.37677428 -0.49260917]\n",
            " [ 0.3603794  -0.5117499 ]\n",
            " [ 0.39430067 -0.44065234]\n",
            " [ 0.3442112  -0.4814574 ]\n",
            " [ 0.44577685 -0.41832817]\n",
            " [ 0.3890591  -0.41432956]\n",
            " [ 0.36461893 -0.5236929 ]\n",
            " [ 0.36461893 -0.5236929 ]\n",
            " [ 0.41073352 -0.5039963 ]\n",
            " [ 0.35502484 -0.45753127]\n",
            " [ 0.32967007 -0.49165732]\n",
            " [ 0.45545974 -0.4875239 ]\n",
            " [ 0.4550263  -0.504427  ]\n",
            " [ 0.29772055 -0.5506773 ]\n",
            " [ 0.34739473 -0.5060609 ]\n",
            " [ 0.3104596  -0.54004544]\n",
            " [ 0.35855663 -0.5010336 ]\n",
            " [ 0.18381505 -0.5303669 ]]\n",
            "Labels:[0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1]\n",
            "Logits_each:tensor([[ 0.2187, -0.5726],\n",
            "        [ 0.3853, -0.5411],\n",
            "        [ 0.3830, -0.4541],\n",
            "        [ 0.3834, -0.4762],\n",
            "        [ 0.3848, -0.4506],\n",
            "        [ 0.4190, -0.4616],\n",
            "        [ 0.3821, -0.4394],\n",
            "        [ 0.3911, -0.4631],\n",
            "        [ 0.3814, -0.5012],\n",
            "        [ 0.3922, -0.4689],\n",
            "        [ 0.3986, -0.4779],\n",
            "        [ 0.4030, -0.4781],\n",
            "        [ 0.2686, -0.3845],\n",
            "        [ 0.4484, -0.4202],\n",
            "        [ 0.3893, -0.4821],\n",
            "        [ 0.3977, -0.4826],\n",
            "        [ 0.4412, -0.4613],\n",
            "        [ 0.4380, -0.4501],\n",
            "        [ 0.3411, -0.4335],\n",
            "        [ 0.3931, -0.4679],\n",
            "        [ 0.4556, -0.4980],\n",
            "        [ 0.3539, -0.4915],\n",
            "        [ 0.3803, -0.4395],\n",
            "        [ 0.3803, -0.4395],\n",
            "        [ 0.3509, -0.4392],\n",
            "        [ 0.3967, -0.4552],\n",
            "        [ 0.2764, -0.5012],\n",
            "        [ 0.4199, -0.3893],\n",
            "        [ 0.3493, -0.4349],\n",
            "        [ 0.3272, -0.5369],\n",
            "        [ 0.4310, -0.4810],\n",
            "        [ 0.3968, -0.4222]], device='cuda:0')\n",
            "Logits:[[ 0.21873258 -0.5726311 ]\n",
            " [ 0.3852999  -0.541091  ]\n",
            " [ 0.38304353 -0.45407143]\n",
            " [ 0.3834123  -0.47620526]\n",
            " [ 0.38482162 -0.4506079 ]\n",
            " [ 0.41903794 -0.46156254]\n",
            " [ 0.38208905 -0.43943095]\n",
            " [ 0.39113727 -0.46310443]\n",
            " [ 0.38137996 -0.50119936]\n",
            " [ 0.39221478 -0.46886784]\n",
            " [ 0.39859635 -0.4778997 ]\n",
            " [ 0.40298736 -0.47808   ]\n",
            " [ 0.2686182  -0.3844924 ]\n",
            " [ 0.44842377 -0.4201514 ]\n",
            " [ 0.38929582 -0.48211035]\n",
            " [ 0.39767295 -0.48260403]\n",
            " [ 0.4411764  -0.46134   ]\n",
            " [ 0.43804395 -0.45007992]\n",
            " [ 0.3411161  -0.43348694]\n",
            " [ 0.3930868  -0.46786144]\n",
            " [ 0.4556128  -0.49795163]\n",
            " [ 0.35390097 -0.49151734]\n",
            " [ 0.38030583 -0.43953174]\n",
            " [ 0.38030583 -0.43953174]\n",
            " [ 0.3509035  -0.43919638]\n",
            " [ 0.39671326 -0.45519277]\n",
            " [ 0.27643386 -0.5011724 ]\n",
            " [ 0.4199233  -0.38925982]\n",
            " [ 0.34928006 -0.43490797]\n",
            " [ 0.32720098 -0.53686774]\n",
            " [ 0.43097273 -0.48096612]\n",
            " [ 0.39679465 -0.4222046 ]]\n",
            "Labels:[0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3969, -0.4822],\n",
            "        [ 0.4076, -0.4738],\n",
            "        [ 0.4020, -0.4648],\n",
            "        [ 0.3677, -0.4925],\n",
            "        [ 0.3827, -0.4741],\n",
            "        [ 0.3655, -0.4995],\n",
            "        [ 0.3645, -0.4904],\n",
            "        [ 0.3565, -0.4757],\n",
            "        [ 0.4120, -0.5159],\n",
            "        [ 0.3296, -0.4615],\n",
            "        [ 0.3655, -0.4945],\n",
            "        [ 0.3779, -0.4824],\n",
            "        [ 0.3861, -0.4802],\n",
            "        [ 0.4647, -0.5079],\n",
            "        [ 0.4146, -0.4409],\n",
            "        [ 0.4146, -0.4409],\n",
            "        [ 0.4166, -0.4731],\n",
            "        [ 0.3834, -0.4638],\n",
            "        [ 0.3738, -0.4360],\n",
            "        [ 0.3657, -0.5142],\n",
            "        [ 0.3947, -0.5079],\n",
            "        [ 0.4025, -0.4917],\n",
            "        [ 0.4084, -0.4776],\n",
            "        [ 0.3829, -0.4849],\n",
            "        [ 0.4622, -0.4791],\n",
            "        [ 0.3574, -0.4926],\n",
            "        [ 0.4292, -0.4632],\n",
            "        [ 0.4055, -0.4676],\n",
            "        [ 0.3651, -0.4498],\n",
            "        [ 0.4605, -0.5038],\n",
            "        [ 0.4038, -0.4863],\n",
            "        [ 0.4040, -0.4921]], device='cuda:0')\n",
            "Logits:[[ 0.39692217 -0.48221976]\n",
            " [ 0.4076364  -0.47383246]\n",
            " [ 0.40199825 -0.4647589 ]\n",
            " [ 0.36768332 -0.49252102]\n",
            " [ 0.3826595  -0.47410017]\n",
            " [ 0.3655005  -0.49949577]\n",
            " [ 0.36450467 -0.49043143]\n",
            " [ 0.35650337 -0.47569165]\n",
            " [ 0.41202042 -0.5158716 ]\n",
            " [ 0.32958993 -0.46150604]\n",
            " [ 0.36546513 -0.494506  ]\n",
            " [ 0.3778509  -0.48236284]\n",
            " [ 0.38610083 -0.48018384]\n",
            " [ 0.46471265 -0.5078551 ]\n",
            " [ 0.41464213 -0.44092163]\n",
            " [ 0.41464213 -0.44092163]\n",
            " [ 0.41663456 -0.4731293 ]\n",
            " [ 0.38336954 -0.46379873]\n",
            " [ 0.37379798 -0.4359873 ]\n",
            " [ 0.3656863  -0.51420945]\n",
            " [ 0.39473912 -0.50790346]\n",
            " [ 0.402499   -0.49171507]\n",
            " [ 0.40842298 -0.47759634]\n",
            " [ 0.38287094 -0.48489735]\n",
            " [ 0.4621502  -0.47905934]\n",
            " [ 0.35743695 -0.49256805]\n",
            " [ 0.4292372  -0.46322873]\n",
            " [ 0.40550017 -0.46755812]\n",
            " [ 0.3650784  -0.44984257]\n",
            " [ 0.4604673  -0.5037713 ]\n",
            " [ 0.4038139  -0.48630258]\n",
            " [ 0.40400773 -0.49205926]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.2577, -0.2886],\n",
            "        [ 0.1388, -0.1805],\n",
            "        [ 0.4597, -0.4668],\n",
            "        [ 0.4354, -0.5106],\n",
            "        [ 0.4059, -0.5399],\n",
            "        [ 0.4636, -0.5071],\n",
            "        [ 0.4158, -0.5279],\n",
            "        [ 0.5135, -0.5216],\n",
            "        [ 0.2356, -0.5289],\n",
            "        [ 0.2085, -0.5570],\n",
            "        [ 0.4208, -0.4538],\n",
            "        [ 0.4461, -0.4002],\n",
            "        [ 0.4596, -0.4246],\n",
            "        [ 0.4629, -0.5143],\n",
            "        [ 0.3858, -0.4692],\n",
            "        [ 0.3470, -0.5546],\n",
            "        [ 0.4237, -0.5065],\n",
            "        [ 0.2500, -0.4677],\n",
            "        [ 0.4337, -0.4992],\n",
            "        [ 0.3921, -0.4925],\n",
            "        [ 0.3676, -0.4963],\n",
            "        [ 0.4211, -0.5057],\n",
            "        [ 0.4211, -0.5057],\n",
            "        [ 0.4211, -0.5057],\n",
            "        [ 0.3296, -0.4809],\n",
            "        [ 0.5108, -0.4775],\n",
            "        [ 0.4140, -0.5264],\n",
            "        [ 0.3903, -0.5083],\n",
            "        [ 0.4628, -0.4528],\n",
            "        [ 0.4413, -0.4743],\n",
            "        [ 0.4532, -0.5351],\n",
            "        [ 0.4432, -0.4584]], device='cuda:0')\n",
            "Logits:[[ 0.25771487 -0.2886103 ]\n",
            " [ 0.13881058 -0.18054946]\n",
            " [ 0.45968804 -0.46681815]\n",
            " [ 0.43536508 -0.5106061 ]\n",
            " [ 0.40594268 -0.5398599 ]\n",
            " [ 0.46357295 -0.5071025 ]\n",
            " [ 0.4158002  -0.52791226]\n",
            " [ 0.51352787 -0.5216054 ]\n",
            " [ 0.23563693 -0.5289157 ]\n",
            " [ 0.20853274 -0.55699277]\n",
            " [ 0.42076448 -0.45384973]\n",
            " [ 0.44608268 -0.40019923]\n",
            " [ 0.45960546 -0.42461407]\n",
            " [ 0.4628647  -0.5142879 ]\n",
            " [ 0.38579446 -0.46915904]\n",
            " [ 0.34699973 -0.55459535]\n",
            " [ 0.4236583  -0.5065091 ]\n",
            " [ 0.24999784 -0.46770245]\n",
            " [ 0.43373528 -0.4992129 ]\n",
            " [ 0.3921132  -0.49251682]\n",
            " [ 0.36760643 -0.4962605 ]\n",
            " [ 0.42106417 -0.505656  ]\n",
            " [ 0.42106417 -0.505656  ]\n",
            " [ 0.42106417 -0.505656  ]\n",
            " [ 0.3296286  -0.4808756 ]\n",
            " [ 0.5107599  -0.4775387 ]\n",
            " [ 0.41403642 -0.52637756]\n",
            " [ 0.39028022 -0.5083354 ]\n",
            " [ 0.46284255 -0.45278344]\n",
            " [ 0.4413133  -0.47431502]\n",
            " [ 0.45318127 -0.53511673]\n",
            " [ 0.44316036 -0.45837742]]\n",
            "Labels:[1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1]\n",
            "Logits_each:tensor([[ 0.4637, -0.4586],\n",
            "        [ 0.4637, -0.4586],\n",
            "        [ 0.4637, -0.4586],\n",
            "        [ 0.4415, -0.4669],\n",
            "        [ 0.4637, -0.4586],\n",
            "        [ 0.4637, -0.4586],\n",
            "        [ 0.4637, -0.4586],\n",
            "        [ 0.4637, -0.4586],\n",
            "        [ 0.4637, -0.4586],\n",
            "        [ 0.4580, -0.4994],\n",
            "        [ 0.4637, -0.4586],\n",
            "        [ 0.4637, -0.4586],\n",
            "        [ 0.4637, -0.4586],\n",
            "        [ 0.4637, -0.4586],\n",
            "        [ 0.4637, -0.4586],\n",
            "        [ 0.4637, -0.4586],\n",
            "        [ 0.4637, -0.4586],\n",
            "        [ 0.4637, -0.4586],\n",
            "        [ 0.4662, -0.4501],\n",
            "        [ 0.4443, -0.4925],\n",
            "        [ 0.4079, -0.4639],\n",
            "        [ 0.4405, -0.4639],\n",
            "        [ 0.4811, -0.4930],\n",
            "        [ 0.4477, -0.4753],\n",
            "        [ 0.4056, -0.5016],\n",
            "        [ 0.2951, -0.5588],\n",
            "        [ 0.4779, -0.4461],\n",
            "        [ 0.4061, -0.4919],\n",
            "        [ 0.5235, -0.5000],\n",
            "        [ 0.5012, -0.4871],\n",
            "        [ 0.4960, -0.4879],\n",
            "        [ 0.5219, -0.4468]], device='cuda:0')\n",
            "Logits:[[ 0.4636521  -0.45857817]\n",
            " [ 0.4636521  -0.45857817]\n",
            " [ 0.4636521  -0.45857817]\n",
            " [ 0.4414896  -0.46689668]\n",
            " [ 0.4636521  -0.45857817]\n",
            " [ 0.4636521  -0.45857817]\n",
            " [ 0.4636521  -0.45857817]\n",
            " [ 0.4636521  -0.45857817]\n",
            " [ 0.4636521  -0.45857817]\n",
            " [ 0.4579625  -0.4994486 ]\n",
            " [ 0.4636521  -0.45857817]\n",
            " [ 0.4636521  -0.45857817]\n",
            " [ 0.4636521  -0.45857817]\n",
            " [ 0.4636521  -0.45857817]\n",
            " [ 0.4636521  -0.45857817]\n",
            " [ 0.4636521  -0.45857817]\n",
            " [ 0.4636521  -0.45857817]\n",
            " [ 0.4636521  -0.45857817]\n",
            " [ 0.46619806 -0.45011234]\n",
            " [ 0.44432694 -0.4925477 ]\n",
            " [ 0.4078635  -0.46394894]\n",
            " [ 0.44046506 -0.46390447]\n",
            " [ 0.48106167 -0.49303654]\n",
            " [ 0.44765404 -0.47529444]\n",
            " [ 0.40559378 -0.5016178 ]\n",
            " [ 0.2950513  -0.55880517]\n",
            " [ 0.47790462 -0.44609588]\n",
            " [ 0.40606642 -0.4919181 ]\n",
            " [ 0.52345717 -0.4999832 ]\n",
            " [ 0.5012305  -0.4871159 ]\n",
            " [ 0.49597213 -0.48788786]\n",
            " [ 0.5219156  -0.44684547]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4936, -0.4631],\n",
            "        [ 0.5671, -0.4358],\n",
            "        [ 0.4375, -0.4396],\n",
            "        [ 0.4856, -0.4483],\n",
            "        [ 0.4761, -0.4694],\n",
            "        [ 0.4857, -0.4662],\n",
            "        [ 0.4511, -0.4998],\n",
            "        [ 0.4683, -0.4497],\n",
            "        [ 0.4683, -0.4497],\n",
            "        [ 0.3343, -0.4746],\n",
            "        [ 0.5128, -0.4795],\n",
            "        [ 0.4167, -0.5021],\n",
            "        [ 0.4479, -0.4377],\n",
            "        [ 0.4486, -0.5301],\n",
            "        [ 0.4629, -0.4760],\n",
            "        [ 0.3962, -0.4516],\n",
            "        [ 0.3989, -0.5115],\n",
            "        [ 0.4374, -0.4765],\n",
            "        [ 0.3757, -0.4476],\n",
            "        [ 0.2884, -0.4902],\n",
            "        [ 0.3991, -0.5035],\n",
            "        [ 0.3903, -0.5152],\n",
            "        [ 0.4185, -0.4593],\n",
            "        [ 0.3554, -0.3978],\n",
            "        [ 0.4475, -0.4575],\n",
            "        [ 0.3573, -0.4513],\n",
            "        [ 0.4431, -0.4570],\n",
            "        [ 0.3898, -0.4754],\n",
            "        [ 0.3487, -0.4619],\n",
            "        [ 0.3977, -0.4921],\n",
            "        [ 0.3294, -0.4743],\n",
            "        [ 0.5214, -0.4952]], device='cuda:0')\n",
            "Logits:[[ 0.4936295  -0.46306023]\n",
            " [ 0.56714094 -0.43576276]\n",
            " [ 0.43748218 -0.43957818]\n",
            " [ 0.4855945  -0.44833368]\n",
            " [ 0.4760797  -0.46937722]\n",
            " [ 0.48572046 -0.46622545]\n",
            " [ 0.4510874  -0.4997706 ]\n",
            " [ 0.46833983 -0.44967723]\n",
            " [ 0.46833983 -0.44967723]\n",
            " [ 0.33434743 -0.47460693]\n",
            " [ 0.5128229  -0.47945592]\n",
            " [ 0.41670445 -0.5021325 ]\n",
            " [ 0.44792584 -0.43765226]\n",
            " [ 0.4486347  -0.5300779 ]\n",
            " [ 0.46294063 -0.4759537 ]\n",
            " [ 0.39616576 -0.45159432]\n",
            " [ 0.39891598 -0.51150036]\n",
            " [ 0.4373734  -0.47651806]\n",
            " [ 0.37568486 -0.44760165]\n",
            " [ 0.2884012  -0.4901591 ]\n",
            " [ 0.39914733 -0.5034734 ]\n",
            " [ 0.3902638  -0.5152464 ]\n",
            " [ 0.41854468 -0.45934635]\n",
            " [ 0.3553548  -0.39782676]\n",
            " [ 0.4474546  -0.45745853]\n",
            " [ 0.3572941  -0.45130113]\n",
            " [ 0.44312125 -0.4570331 ]\n",
            " [ 0.38975433 -0.4753937 ]\n",
            " [ 0.34867218 -0.46186364]\n",
            " [ 0.39774114 -0.49208865]\n",
            " [ 0.32936448 -0.4742805 ]\n",
            " [ 0.52135545 -0.4951546 ]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4316, -0.4710],\n",
            "        [ 0.4365, -0.4631],\n",
            "        [ 0.4727, -0.4927],\n",
            "        [ 0.5581, -0.3894],\n",
            "        [ 0.3897, -0.5151],\n",
            "        [ 0.3925, -0.4843],\n",
            "        [ 0.4200, -0.4831],\n",
            "        [ 0.4332, -0.4525],\n",
            "        [ 0.3351, -0.5116],\n",
            "        [ 0.3426, -0.4397],\n",
            "        [ 0.5147, -0.4602],\n",
            "        [ 0.4301, -0.4315],\n",
            "        [ 0.4087, -0.4249],\n",
            "        [ 0.5096, -0.4784],\n",
            "        [ 0.4664, -0.4969],\n",
            "        [ 0.3618, -0.4468],\n",
            "        [ 0.3725, -0.4746],\n",
            "        [ 0.1683,  0.0358],\n",
            "        [ 0.3356, -0.4667],\n",
            "        [ 0.4290, -0.4185],\n",
            "        [ 0.5231, -0.5255],\n",
            "        [ 0.3238, -0.5954],\n",
            "        [ 0.4065, -0.5896],\n",
            "        [ 0.4521, -0.5792],\n",
            "        [ 0.4546, -0.5907],\n",
            "        [ 0.4457, -0.4701],\n",
            "        [ 0.4457, -0.5757],\n",
            "        [ 0.3023, -0.6046],\n",
            "        [ 0.3561, -0.4753],\n",
            "        [ 0.1556, -0.5672],\n",
            "        [ 0.4743, -0.4599],\n",
            "        [ 0.4291, -0.5054]], device='cuda:0')\n",
            "Logits:[[ 0.4315842  -0.47095415]\n",
            " [ 0.43651435 -0.46311975]\n",
            " [ 0.47273722 -0.49273232]\n",
            " [ 0.5581491  -0.38936204]\n",
            " [ 0.38970467 -0.51510423]\n",
            " [ 0.39249393 -0.484276  ]\n",
            " [ 0.42004213 -0.48310876]\n",
            " [ 0.43320206 -0.45247042]\n",
            " [ 0.3350981  -0.5115769 ]\n",
            " [ 0.34264487 -0.43972734]\n",
            " [ 0.5146962  -0.46023566]\n",
            " [ 0.43014276 -0.4314838 ]\n",
            " [ 0.40869936 -0.42487708]\n",
            " [ 0.50956494 -0.47844648]\n",
            " [ 0.46638352 -0.49691445]\n",
            " [ 0.36180168 -0.44677868]\n",
            " [ 0.37245286 -0.474601  ]\n",
            " [ 0.16828683  0.0358064 ]\n",
            " [ 0.33563295 -0.46671045]\n",
            " [ 0.42899677 -0.41853383]\n",
            " [ 0.5231     -0.5255438 ]\n",
            " [ 0.32384112 -0.59542227]\n",
            " [ 0.4065201  -0.58959955]\n",
            " [ 0.4521037  -0.57918143]\n",
            " [ 0.45457688 -0.59066993]\n",
            " [ 0.44571528 -0.47006357]\n",
            " [ 0.4456846  -0.57565475]\n",
            " [ 0.3023315  -0.60455763]\n",
            " [ 0.35606986 -0.4752944 ]\n",
            " [ 0.15560366 -0.5672295 ]\n",
            " [ 0.47434253 -0.45989123]\n",
            " [ 0.42909503 -0.50540215]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3620, -0.4934],\n",
            "        [ 0.4511, -0.5865],\n",
            "        [ 0.4589, -0.5531],\n",
            "        [ 0.4153, -0.5104],\n",
            "        [ 0.4006, -0.4917],\n",
            "        [ 0.4427, -0.5388],\n",
            "        [ 0.3460, -0.5349],\n",
            "        [ 0.3591, -0.5341],\n",
            "        [ 0.3376, -0.5051],\n",
            "        [ 0.4497, -0.5555],\n",
            "        [ 0.4067, -0.5344],\n",
            "        [ 0.4659, -0.5712],\n",
            "        [ 0.3371, -0.5511],\n",
            "        [ 0.4420, -0.5455],\n",
            "        [ 0.4262, -0.5435],\n",
            "        [ 0.4262, -0.5435],\n",
            "        [ 0.4040, -0.4584],\n",
            "        [ 0.3805, -0.4860],\n",
            "        [ 0.3492, -0.5389],\n",
            "        [ 0.3492, -0.5389],\n",
            "        [ 0.3973, -0.4933],\n",
            "        [ 0.3571, -0.4438],\n",
            "        [ 0.3571, -0.4438],\n",
            "        [ 0.4174, -0.4643],\n",
            "        [ 0.3698, -0.4320],\n",
            "        [ 0.3381, -0.4351],\n",
            "        [ 0.4057, -0.4642],\n",
            "        [ 0.3744, -0.4362],\n",
            "        [ 0.4206, -0.4456],\n",
            "        [ 0.4002, -0.4598],\n",
            "        [ 0.4978, -0.4940],\n",
            "        [ 0.4347, -0.5297]], device='cuda:0')\n",
            "Logits:[[ 0.36200523 -0.4934353 ]\n",
            " [ 0.45108873 -0.5865207 ]\n",
            " [ 0.45889825 -0.55312335]\n",
            " [ 0.4153351  -0.51035273]\n",
            " [ 0.40060303 -0.49168646]\n",
            " [ 0.44270337 -0.53882456]\n",
            " [ 0.34601834 -0.534852  ]\n",
            " [ 0.35914364 -0.53409195]\n",
            " [ 0.33757252 -0.50514   ]\n",
            " [ 0.4496929  -0.55554014]\n",
            " [ 0.40666282 -0.5343983 ]\n",
            " [ 0.4658713  -0.5712119 ]\n",
            " [ 0.3371243  -0.5511308 ]\n",
            " [ 0.44203258 -0.54554796]\n",
            " [ 0.42616805 -0.5435069 ]\n",
            " [ 0.42616805 -0.5435069 ]\n",
            " [ 0.40401527 -0.45836446]\n",
            " [ 0.38048524 -0.4859917 ]\n",
            " [ 0.3492395  -0.53889304]\n",
            " [ 0.3492395  -0.53889304]\n",
            " [ 0.39725813 -0.4933106 ]\n",
            " [ 0.35712415 -0.443788  ]\n",
            " [ 0.35712415 -0.443788  ]\n",
            " [ 0.4173951  -0.46434343]\n",
            " [ 0.3698476  -0.43195266]\n",
            " [ 0.33814695 -0.43512455]\n",
            " [ 0.4056976  -0.46419504]\n",
            " [ 0.37442783 -0.43616992]\n",
            " [ 0.42064452 -0.44556782]\n",
            " [ 0.40015763 -0.45977774]\n",
            " [ 0.4978402  -0.49395648]\n",
            " [ 0.43467852 -0.52970636]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4193, -0.4383],\n",
            "        [ 0.4253, -0.5154],\n",
            "        [ 0.3764, -0.4885],\n",
            "        [ 0.3764, -0.4885],\n",
            "        [ 0.4882, -0.3635],\n",
            "        [ 0.3994, -0.4924],\n",
            "        [ 0.3383, -0.4711],\n",
            "        [ 0.4003, -0.4897],\n",
            "        [ 0.4413, -0.4533],\n",
            "        [ 0.3776, -0.4198],\n",
            "        [ 0.3747, -0.3784],\n",
            "        [ 0.3596, -0.4583],\n",
            "        [ 0.3354, -0.4543],\n",
            "        [ 0.4747, -0.4438],\n",
            "        [ 0.4498, -0.4647],\n",
            "        [ 0.2725, -0.5472],\n",
            "        [ 0.4850, -0.4526],\n",
            "        [ 0.4091, -0.4660],\n",
            "        [ 0.3389, -0.4944],\n",
            "        [ 0.3389, -0.4944],\n",
            "        [ 0.3389, -0.4944],\n",
            "        [ 0.1691, -0.5520],\n",
            "        [ 0.3676, -0.5974],\n",
            "        [ 0.5096, -0.5322],\n",
            "        [ 0.4590, -0.5199],\n",
            "        [ 0.4969, -0.5066],\n",
            "        [ 0.4969, -0.5066],\n",
            "        [ 0.4969, -0.5066],\n",
            "        [ 0.5054, -0.4742],\n",
            "        [ 0.4193, -0.5241],\n",
            "        [ 0.4116, -0.4815],\n",
            "        [ 0.4244, -0.4668]], device='cuda:0')\n",
            "Logits:[[ 0.4192693  -0.43827856]\n",
            " [ 0.42530733 -0.51539606]\n",
            " [ 0.37639534 -0.48852086]\n",
            " [ 0.37639534 -0.48852086]\n",
            " [ 0.4882293  -0.36349165]\n",
            " [ 0.3993764  -0.4924475 ]\n",
            " [ 0.33825296 -0.47108033]\n",
            " [ 0.40028596 -0.48970255]\n",
            " [ 0.44133702 -0.45325893]\n",
            " [ 0.37761107 -0.41976282]\n",
            " [ 0.3747014  -0.37842974]\n",
            " [ 0.3595923  -0.4582827 ]\n",
            " [ 0.33543104 -0.4542602 ]\n",
            " [ 0.47474888 -0.44381076]\n",
            " [ 0.4498226  -0.46472746]\n",
            " [ 0.27246514 -0.547201  ]\n",
            " [ 0.4850026  -0.4526028 ]\n",
            " [ 0.40905103 -0.46600768]\n",
            " [ 0.33886784 -0.49436167]\n",
            " [ 0.33886784 -0.49436167]\n",
            " [ 0.33886784 -0.49436167]\n",
            " [ 0.16914245 -0.5520004 ]\n",
            " [ 0.36758593 -0.59737986]\n",
            " [ 0.5095593  -0.5321707 ]\n",
            " [ 0.4590021  -0.5198979 ]\n",
            " [ 0.49687427 -0.5066034 ]\n",
            " [ 0.49687427 -0.5066034 ]\n",
            " [ 0.49687427 -0.5066034 ]\n",
            " [ 0.50540173 -0.47422326]\n",
            " [ 0.41925526 -0.5240843 ]\n",
            " [ 0.4116174  -0.48149896]\n",
            " [ 0.42438042 -0.46677145]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.1917, -0.5383],\n",
            "        [ 0.4905, -0.5161],\n",
            "        [ 0.4012, -0.5267],\n",
            "        [ 0.2289, -0.5524],\n",
            "        [ 0.3505, -0.4784],\n",
            "        [ 0.4368, -0.5114],\n",
            "        [ 0.1567, -0.5963],\n",
            "        [ 0.1567, -0.5963],\n",
            "        [ 0.1567, -0.5963],\n",
            "        [ 0.4083, -0.5112],\n",
            "        [ 0.3644, -0.5419],\n",
            "        [ 0.3644, -0.5419],\n",
            "        [ 0.3562, -0.3932],\n",
            "        [ 0.4488, -0.5191],\n",
            "        [ 0.4040, -0.4898],\n",
            "        [ 0.4331, -0.4689],\n",
            "        [ 0.4331, -0.4689],\n",
            "        [ 0.4331, -0.4689],\n",
            "        [ 0.4331, -0.4689],\n",
            "        [ 0.4072, -0.5098],\n",
            "        [ 0.4063, -0.5067],\n",
            "        [ 0.3017, -0.4805],\n",
            "        [ 0.3904, -0.4974],\n",
            "        [ 0.3850, -0.4728],\n",
            "        [ 0.4954, -0.5118],\n",
            "        [ 0.4954, -0.5118],\n",
            "        [ 0.4954, -0.5118],\n",
            "        [ 0.3372, -0.4940],\n",
            "        [ 0.3485, -0.4910],\n",
            "        [ 0.3701, -0.5307],\n",
            "        [ 0.3518, -0.4682],\n",
            "        [ 0.2895, -0.5416]], device='cuda:0')\n",
            "Logits:[[ 0.19167775 -0.53834933]\n",
            " [ 0.49052972 -0.5161284 ]\n",
            " [ 0.40120536 -0.5266847 ]\n",
            " [ 0.22888346 -0.55243665]\n",
            " [ 0.35047358 -0.4783997 ]\n",
            " [ 0.43684012 -0.5114034 ]\n",
            " [ 0.15665    -0.5963346 ]\n",
            " [ 0.15665    -0.5963346 ]\n",
            " [ 0.15665    -0.5963346 ]\n",
            " [ 0.40832072 -0.5112404 ]\n",
            " [ 0.3643703  -0.54194295]\n",
            " [ 0.3643703  -0.54194295]\n",
            " [ 0.3562104  -0.39324978]\n",
            " [ 0.44882283 -0.5191153 ]\n",
            " [ 0.40403405 -0.48978266]\n",
            " [ 0.43306163 -0.4689133 ]\n",
            " [ 0.43306163 -0.4689133 ]\n",
            " [ 0.43306163 -0.4689133 ]\n",
            " [ 0.43306163 -0.4689133 ]\n",
            " [ 0.4072158  -0.5097562 ]\n",
            " [ 0.40629604 -0.506724  ]\n",
            " [ 0.30168498 -0.48046538]\n",
            " [ 0.39037746 -0.49739945]\n",
            " [ 0.38504812 -0.4728411 ]\n",
            " [ 0.49536464 -0.5117647 ]\n",
            " [ 0.49536464 -0.5117647 ]\n",
            " [ 0.49536464 -0.5117647 ]\n",
            " [ 0.33724344 -0.49395832]\n",
            " [ 0.34853402 -0.49096826]\n",
            " [ 0.37011617 -0.5307401 ]\n",
            " [ 0.351798   -0.46815425]\n",
            " [ 0.28945246 -0.54158753]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3623, -0.5693],\n",
            "        [ 0.3727, -0.4682],\n",
            "        [ 0.4706, -0.4805],\n",
            "        [ 0.4048, -0.5517],\n",
            "        [ 0.4706, -0.4805],\n",
            "        [ 0.3923, -0.5367],\n",
            "        [ 0.4769, -0.5234],\n",
            "        [ 0.3923, -0.5367],\n",
            "        [ 0.4769, -0.5234],\n",
            "        [ 0.4769, -0.5234],\n",
            "        [ 0.4963, -0.5222],\n",
            "        [ 0.4103, -0.4855],\n",
            "        [ 0.3984, -0.5353],\n",
            "        [ 0.3984, -0.5353],\n",
            "        [ 0.3984, -0.5353],\n",
            "        [ 0.4301, -0.3920],\n",
            "        [ 0.4069, -0.4455],\n",
            "        [ 0.4069, -0.4455],\n",
            "        [ 0.4069, -0.4455],\n",
            "        [ 0.4069, -0.4455],\n",
            "        [ 0.4069, -0.4455],\n",
            "        [ 0.3836, -0.4650],\n",
            "        [ 0.3276, -0.4676],\n",
            "        [ 0.3276, -0.4676],\n",
            "        [ 0.3276, -0.4676],\n",
            "        [ 0.3276, -0.4676],\n",
            "        [ 0.4112, -0.4720],\n",
            "        [ 0.3679, -0.4575],\n",
            "        [ 0.3679, -0.4575],\n",
            "        [ 0.3679, -0.4575],\n",
            "        [ 0.3065, -0.5019],\n",
            "        [ 0.3442, -0.4502]], device='cuda:0')\n",
            "Logits:[[ 0.36233324 -0.5692984 ]\n",
            " [ 0.37272802 -0.46824193]\n",
            " [ 0.47064173 -0.48050776]\n",
            " [ 0.4048356  -0.5517217 ]\n",
            " [ 0.47064173 -0.48050776]\n",
            " [ 0.39225367 -0.5366933 ]\n",
            " [ 0.47686106 -0.52343744]\n",
            " [ 0.39225367 -0.5366933 ]\n",
            " [ 0.47686106 -0.52343744]\n",
            " [ 0.47686106 -0.52343744]\n",
            " [ 0.49625057 -0.5222305 ]\n",
            " [ 0.41034177 -0.48551098]\n",
            " [ 0.3983562  -0.5352842 ]\n",
            " [ 0.3983562  -0.5352842 ]\n",
            " [ 0.3983562  -0.5352842 ]\n",
            " [ 0.43009862 -0.39199665]\n",
            " [ 0.40689644 -0.44550583]\n",
            " [ 0.40689644 -0.44550583]\n",
            " [ 0.40689644 -0.44550583]\n",
            " [ 0.40689644 -0.44550583]\n",
            " [ 0.40689644 -0.44550583]\n",
            " [ 0.38363963 -0.46502343]\n",
            " [ 0.3276287  -0.46758187]\n",
            " [ 0.3276287  -0.46758187]\n",
            " [ 0.3276287  -0.46758187]\n",
            " [ 0.3276287  -0.46758187]\n",
            " [ 0.41119245 -0.472006  ]\n",
            " [ 0.36787698 -0.4574507 ]\n",
            " [ 0.36787698 -0.4574507 ]\n",
            " [ 0.36787698 -0.4574507 ]\n",
            " [ 0.30650297 -0.50191057]\n",
            " [ 0.34417439 -0.4502026 ]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3248, -0.5003],\n",
            "        [ 0.2534, -0.5627],\n",
            "        [ 0.3634, -0.5145],\n",
            "        [ 0.3386, -0.5229],\n",
            "        [ 0.2728, -0.5397],\n",
            "        [ 0.3410, -0.4945],\n",
            "        [ 0.3709, -0.5147],\n",
            "        [ 0.4193, -0.5073],\n",
            "        [ 0.1618, -0.2160],\n",
            "        [ 0.3619, -0.5509],\n",
            "        [ 0.2914, -0.5232],\n",
            "        [ 0.4238, -0.5481],\n",
            "        [ 0.3915, -0.5090],\n",
            "        [ 0.2357, -0.4575],\n",
            "        [ 0.1899, -0.5412],\n",
            "        [ 0.3980, -0.5334],\n",
            "        [ 0.0764, -0.3950],\n",
            "        [ 0.4075, -0.4918],\n",
            "        [ 0.0709, -0.5544],\n",
            "        [ 0.1861, -0.5061],\n",
            "        [ 0.2571, -0.5188],\n",
            "        [ 0.3157, -0.5265],\n",
            "        [ 0.3527, -0.5206],\n",
            "        [ 0.3837, -0.5047],\n",
            "        [ 0.3058, -0.5270],\n",
            "        [ 0.2837, -0.4871],\n",
            "        [ 0.1760, -0.5497],\n",
            "        [ 0.3576, -0.5383],\n",
            "        [ 0.4219, -0.5392],\n",
            "        [ 0.4835, -0.4988],\n",
            "        [ 0.4211, -0.5151],\n",
            "        [ 0.2969, -0.4931]], device='cuda:0')\n",
            "Logits:[[ 0.3247991  -0.50025505]\n",
            " [ 0.25344384 -0.5627032 ]\n",
            " [ 0.36343002 -0.514503  ]\n",
            " [ 0.3385736  -0.5229081 ]\n",
            " [ 0.27278107 -0.53969985]\n",
            " [ 0.34104955 -0.49452418]\n",
            " [ 0.37094352 -0.51470137]\n",
            " [ 0.41931507 -0.5072703 ]\n",
            " [ 0.16184928 -0.21596892]\n",
            " [ 0.36192    -0.5509423 ]\n",
            " [ 0.29141238 -0.52316654]\n",
            " [ 0.42379868 -0.5481302 ]\n",
            " [ 0.39145115 -0.50904554]\n",
            " [ 0.2357433  -0.45746872]\n",
            " [ 0.18991752 -0.5411904 ]\n",
            " [ 0.39797887 -0.53340906]\n",
            " [ 0.07638737 -0.39503148]\n",
            " [ 0.40747955 -0.49181157]\n",
            " [ 0.07086191 -0.55437076]\n",
            " [ 0.18610376 -0.5060665 ]\n",
            " [ 0.2571362  -0.5187863 ]\n",
            " [ 0.3157262  -0.526479  ]\n",
            " [ 0.3527061  -0.520554  ]\n",
            " [ 0.38372213 -0.5046761 ]\n",
            " [ 0.30577177 -0.5269681 ]\n",
            " [ 0.2836985  -0.48712176]\n",
            " [ 0.17602143 -0.54966795]\n",
            " [ 0.35757002 -0.5382908 ]\n",
            " [ 0.42185974 -0.5392271 ]\n",
            " [ 0.4834783  -0.4988286 ]\n",
            " [ 0.4210908  -0.51510626]\n",
            " [ 0.29690844 -0.49310762]]\n",
            "Labels:[0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3591, -0.5065],\n",
            "        [ 0.2766, -0.5371],\n",
            "        [ 0.1858, -0.5084],\n",
            "        [ 0.1343, -0.5269],\n",
            "        [ 0.2234, -0.4838],\n",
            "        [ 0.1451, -0.5079],\n",
            "        [ 0.1660, -0.5187],\n",
            "        [ 0.1675, -0.5631],\n",
            "        [ 0.1887, -0.4410],\n",
            "        [ 0.1714, -0.5555],\n",
            "        [ 0.2652, -0.5471],\n",
            "        [ 0.3577, -0.5748],\n",
            "        [ 0.4196, -0.4884],\n",
            "        [ 0.4196, -0.4884],\n",
            "        [ 0.4191, -0.4676],\n",
            "        [ 0.5020, -0.4948],\n",
            "        [ 0.5020, -0.4948],\n",
            "        [ 0.4643, -0.4738],\n",
            "        [ 0.4308, -0.4723],\n",
            "        [ 0.4837, -0.4402],\n",
            "        [ 0.4986, -0.4855],\n",
            "        [ 0.4662, -0.5078],\n",
            "        [ 0.4109, -0.4735],\n",
            "        [ 0.4571, -0.4513],\n",
            "        [ 0.4571, -0.4513],\n",
            "        [ 0.3658, -0.4971],\n",
            "        [ 0.3970, -0.5422],\n",
            "        [ 0.3169, -0.4653],\n",
            "        [ 0.2239, -0.5569],\n",
            "        [ 0.3654, -0.5128],\n",
            "        [ 0.3925, -0.4752],\n",
            "        [ 0.3921, -0.5196]], device='cuda:0')\n",
            "Logits:[[ 0.35912913 -0.50653255]\n",
            " [ 0.276624   -0.5370799 ]\n",
            " [ 0.18575242 -0.50840217]\n",
            " [ 0.13433954 -0.5268656 ]\n",
            " [ 0.2233961  -0.48383215]\n",
            " [ 0.14507204 -0.5079046 ]\n",
            " [ 0.16604221 -0.51873416]\n",
            " [ 0.16745712 -0.563103  ]\n",
            " [ 0.18872224 -0.44095382]\n",
            " [ 0.17141205 -0.5554821 ]\n",
            " [ 0.26521543 -0.5470725 ]\n",
            " [ 0.35769436 -0.57482547]\n",
            " [ 0.41961756 -0.48835358]\n",
            " [ 0.41961756 -0.48835358]\n",
            " [ 0.41910592 -0.4676041 ]\n",
            " [ 0.501983   -0.49480167]\n",
            " [ 0.501983   -0.49480167]\n",
            " [ 0.46428725 -0.47377732]\n",
            " [ 0.4307579  -0.4723426 ]\n",
            " [ 0.48366085 -0.44018996]\n",
            " [ 0.49864957 -0.4855196 ]\n",
            " [ 0.46616396 -0.50784683]\n",
            " [ 0.41088578 -0.47352138]\n",
            " [ 0.45708668 -0.4512582 ]\n",
            " [ 0.45708668 -0.4512582 ]\n",
            " [ 0.36579394 -0.49707404]\n",
            " [ 0.39702296 -0.5421503 ]\n",
            " [ 0.31688854 -0.4652824 ]\n",
            " [ 0.22387898 -0.55692846]\n",
            " [ 0.36537206 -0.5127949 ]\n",
            " [ 0.39247027 -0.47524714]\n",
            " [ 0.39207357 -0.5195563 ]]\n",
            "Labels:[0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0]\n",
            "Logits_each:tensor([[ 0.0655, -0.3767],\n",
            "        [ 0.3356, -0.5312],\n",
            "        [ 0.3950, -0.4758],\n",
            "        [ 0.3961, -0.4977],\n",
            "        [ 0.3633, -0.5234],\n",
            "        [ 0.2839, -0.5381],\n",
            "        [ 0.4481, -0.4682],\n",
            "        [ 0.3301, -0.5598],\n",
            "        [ 0.4049, -0.5272],\n",
            "        [ 0.4295, -0.5596],\n",
            "        [ 0.3349, -0.4891],\n",
            "        [ 0.4285, -0.5419],\n",
            "        [ 0.2553, -0.5296],\n",
            "        [ 0.3404, -0.5432],\n",
            "        [ 0.4111, -0.5232],\n",
            "        [ 0.3526, -0.5289],\n",
            "        [ 0.3659, -0.4459],\n",
            "        [ 0.3602, -0.5590],\n",
            "        [ 0.3371, -0.5278],\n",
            "        [ 0.4702, -0.4790],\n",
            "        [ 0.4157, -0.4652],\n",
            "        [ 0.5394, -0.4723],\n",
            "        [ 0.4748, -0.4639],\n",
            "        [ 0.4733, -0.4988],\n",
            "        [ 0.3752, -0.5051],\n",
            "        [ 0.4209, -0.5337],\n",
            "        [ 0.4209, -0.5337],\n",
            "        [ 0.4154, -0.5020],\n",
            "        [ 0.4280, -0.5286],\n",
            "        [ 0.4280, -0.5286],\n",
            "        [ 0.4280, -0.5286],\n",
            "        [ 0.4280, -0.5286]], device='cuda:0')\n",
            "Logits:[[ 0.06546327 -0.37672856]\n",
            " [ 0.33560666 -0.53122437]\n",
            " [ 0.39497036 -0.47581184]\n",
            " [ 0.39605084 -0.4976937 ]\n",
            " [ 0.36330703 -0.5234394 ]\n",
            " [ 0.28386873 -0.53806067]\n",
            " [ 0.44808686 -0.46824473]\n",
            " [ 0.3300663  -0.5597913 ]\n",
            " [ 0.4049156  -0.52719   ]\n",
            " [ 0.4295276  -0.5595545 ]\n",
            " [ 0.3348651  -0.48912466]\n",
            " [ 0.42853346 -0.5418767 ]\n",
            " [ 0.25526336 -0.5295628 ]\n",
            " [ 0.34044293 -0.5432451 ]\n",
            " [ 0.41109875 -0.52316415]\n",
            " [ 0.352582   -0.52890843]\n",
            " [ 0.36590055 -0.4459105 ]\n",
            " [ 0.36020878 -0.559039  ]\n",
            " [ 0.3371404  -0.5278186 ]\n",
            " [ 0.47023156 -0.47902018]\n",
            " [ 0.41574433 -0.46518666]\n",
            " [ 0.53935915 -0.47232696]\n",
            " [ 0.47478324 -0.46388206]\n",
            " [ 0.47331196 -0.4988236 ]\n",
            " [ 0.37518576 -0.5050598 ]\n",
            " [ 0.42088345 -0.5337181 ]\n",
            " [ 0.42088345 -0.5337181 ]\n",
            " [ 0.41537288 -0.5019963 ]\n",
            " [ 0.42802984 -0.528585  ]\n",
            " [ 0.42802984 -0.528585  ]\n",
            " [ 0.42802984 -0.528585  ]\n",
            " [ 0.42802984 -0.528585  ]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4730, -0.5168],\n",
            "        [ 0.4730, -0.5168],\n",
            "        [ 0.4392, -0.5338],\n",
            "        [ 0.3963, -0.5343],\n",
            "        [ 0.3963, -0.5343],\n",
            "        [ 0.4815, -0.4737],\n",
            "        [ 0.4477, -0.4775],\n",
            "        [ 0.4247, -0.5355],\n",
            "        [ 0.4004, -0.4768],\n",
            "        [ 0.3859, -0.5244],\n",
            "        [ 0.1066, -0.5137],\n",
            "        [ 0.0749, -0.5263],\n",
            "        [ 0.4176, -0.5192],\n",
            "        [ 0.3673, -0.5632],\n",
            "        [ 0.3910, -0.5160],\n",
            "        [ 0.4073, -0.5270],\n",
            "        [ 0.3791, -0.5298],\n",
            "        [ 0.4815, -0.4720],\n",
            "        [ 0.4260, -0.5178],\n",
            "        [ 0.4239, -0.4800],\n",
            "        [ 0.4531, -0.5228],\n",
            "        [ 0.3478, -0.5416],\n",
            "        [ 0.4163, -0.5222],\n",
            "        [ 0.3143, -0.4740],\n",
            "        [ 0.3215, -0.4618],\n",
            "        [ 0.2641, -0.4718],\n",
            "        [ 0.3454, -0.4694],\n",
            "        [ 0.3488, -0.4448],\n",
            "        [ 0.2981, -0.4959],\n",
            "        [ 0.2459, -0.5601],\n",
            "        [ 0.3058, -0.5238],\n",
            "        [ 0.3559, -0.4968]], device='cuda:0')\n",
            "Logits:[[ 0.47301224 -0.51682806]\n",
            " [ 0.47301224 -0.51682806]\n",
            " [ 0.43916595 -0.53376126]\n",
            " [ 0.39633933 -0.5342707 ]\n",
            " [ 0.39633933 -0.5342707 ]\n",
            " [ 0.4815116  -0.47369367]\n",
            " [ 0.4476996  -0.47745875]\n",
            " [ 0.4246826  -0.53546906]\n",
            " [ 0.40042272 -0.4767507 ]\n",
            " [ 0.3858962  -0.5244438 ]\n",
            " [ 0.1066197  -0.51366335]\n",
            " [ 0.0749362  -0.52626276]\n",
            " [ 0.41762027 -0.5192332 ]\n",
            " [ 0.3672882  -0.5631893 ]\n",
            " [ 0.39100066 -0.5159664 ]\n",
            " [ 0.4072996  -0.52699846]\n",
            " [ 0.37910327 -0.5297807 ]\n",
            " [ 0.4815393  -0.47197336]\n",
            " [ 0.42597866 -0.51777637]\n",
            " [ 0.42390293 -0.47998315]\n",
            " [ 0.45305574 -0.52275777]\n",
            " [ 0.34779668 -0.54160696]\n",
            " [ 0.41625684 -0.5221985 ]\n",
            " [ 0.31434608 -0.47403345]\n",
            " [ 0.32147613 -0.46181116]\n",
            " [ 0.26405233 -0.4717544 ]\n",
            " [ 0.34537557 -0.46942765]\n",
            " [ 0.34884036 -0.44483078]\n",
            " [ 0.29811004 -0.49586296]\n",
            " [ 0.24586494 -0.5601061 ]\n",
            " [ 0.30577445 -0.5238442 ]\n",
            " [ 0.35590243 -0.496794  ]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3311, -0.5223],\n",
            "        [ 0.4146, -0.5374],\n",
            "        [ 0.4076, -0.4549],\n",
            "        [ 0.4112, -0.4762],\n",
            "        [ 0.2152, -0.5152],\n",
            "        [ 0.4047, -0.4956],\n",
            "        [ 0.4415, -0.4491],\n",
            "        [ 0.4076, -0.4869],\n",
            "        [ 0.3862, -0.5197],\n",
            "        [ 0.1990, -0.5853],\n",
            "        [ 0.3681, -0.5026],\n",
            "        [ 0.2878, -0.5229],\n",
            "        [ 0.4279, -0.4522],\n",
            "        [ 0.4970, -0.3867],\n",
            "        [ 0.4970, -0.3867],\n",
            "        [ 0.4327, -0.5075],\n",
            "        [ 0.3434, -0.4997],\n",
            "        [ 0.4220, -0.4479],\n",
            "        [ 0.4431, -0.5210],\n",
            "        [ 0.4431, -0.5210],\n",
            "        [ 0.4426, -0.4604],\n",
            "        [ 0.4505, -0.4841],\n",
            "        [ 0.3556, -0.4686],\n",
            "        [ 0.4187, -0.4370],\n",
            "        [ 0.4623, -0.5273],\n",
            "        [ 0.4069, -0.4915],\n",
            "        [ 0.4102, -0.4417],\n",
            "        [ 0.3784, -0.4378],\n",
            "        [ 0.3621, -0.4603],\n",
            "        [ 0.4190, -0.4521],\n",
            "        [ 0.3850, -0.5180],\n",
            "        [ 0.4654, -0.5103]], device='cuda:0')\n",
            "Logits:[[ 0.33107194 -0.5223121 ]\n",
            " [ 0.41463816 -0.5373887 ]\n",
            " [ 0.40760556 -0.45491815]\n",
            " [ 0.411235   -0.47622836]\n",
            " [ 0.21518372 -0.5151798 ]\n",
            " [ 0.40467888 -0.4956022 ]\n",
            " [ 0.44154948 -0.44913876]\n",
            " [ 0.40760082 -0.48687157]\n",
            " [ 0.38619667 -0.5196629 ]\n",
            " [ 0.19904473 -0.5853178 ]\n",
            " [ 0.36809477 -0.5026041 ]\n",
            " [ 0.28776923 -0.52292246]\n",
            " [ 0.42793652 -0.45222673]\n",
            " [ 0.4970414  -0.38673517]\n",
            " [ 0.4970414  -0.38673517]\n",
            " [ 0.4327333  -0.5075381 ]\n",
            " [ 0.34341225 -0.49969015]\n",
            " [ 0.42204532 -0.447914  ]\n",
            " [ 0.4430749  -0.52103865]\n",
            " [ 0.4430749  -0.52103865]\n",
            " [ 0.44257858 -0.46035233]\n",
            " [ 0.45051116 -0.484127  ]\n",
            " [ 0.35557705 -0.46862543]\n",
            " [ 0.41867164 -0.4370012 ]\n",
            " [ 0.4622831  -0.5272786 ]\n",
            " [ 0.40689576 -0.491486  ]\n",
            " [ 0.4101515  -0.44167408]\n",
            " [ 0.3783522  -0.4378438 ]\n",
            " [ 0.36205834 -0.46026713]\n",
            " [ 0.4190399  -0.45214626]\n",
            " [ 0.3849959  -0.51800096]\n",
            " [ 0.46536496 -0.5103224 ]]\n",
            "Labels:[0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3806, -0.4962],\n",
            "        [ 0.4439, -0.5020],\n",
            "        [ 0.4736, -0.4836],\n",
            "        [ 0.4184, -0.5057],\n",
            "        [ 0.4184, -0.5057],\n",
            "        [ 0.4066, -0.5240],\n",
            "        [ 0.4418, -0.5177],\n",
            "        [ 0.3916, -0.4969],\n",
            "        [ 0.4049, -0.4666],\n",
            "        [ 0.4054, -0.4399],\n",
            "        [ 0.4101, -0.5085],\n",
            "        [ 0.3780, -0.4899],\n",
            "        [ 0.2622, -0.3699],\n",
            "        [ 0.3179, -0.5262],\n",
            "        [ 0.3549, -0.4976],\n",
            "        [ 0.3669, -0.5548],\n",
            "        [ 0.4102, -0.5122],\n",
            "        [ 0.4824, -0.4459],\n",
            "        [ 0.2560, -0.3344],\n",
            "        [ 0.1333, -0.2006],\n",
            "        [ 0.4274, -0.4094],\n",
            "        [ 0.4429, -0.4656],\n",
            "        [ 0.1269, -0.0642],\n",
            "        [ 0.1319, -0.1308],\n",
            "        [ 0.4221, -0.4382],\n",
            "        [ 0.5187, -0.5021],\n",
            "        [ 0.1008,  0.0179],\n",
            "        [ 0.0695,  0.0526],\n",
            "        [ 0.1008,  0.0179],\n",
            "        [ 0.1047, -0.0861],\n",
            "        [ 0.1337, -0.1075],\n",
            "        [ 0.4376, -0.4478]], device='cuda:0')\n",
            "Logits:[[ 0.38062856 -0.4961723 ]\n",
            " [ 0.44393736 -0.5019678 ]\n",
            " [ 0.47363332 -0.48364246]\n",
            " [ 0.418394   -0.5057388 ]\n",
            " [ 0.418394   -0.5057388 ]\n",
            " [ 0.40664932 -0.5240285 ]\n",
            " [ 0.44181183 -0.51770884]\n",
            " [ 0.39159778 -0.49685404]\n",
            " [ 0.40494967 -0.46662465]\n",
            " [ 0.4054207  -0.43988988]\n",
            " [ 0.4100965  -0.50852275]\n",
            " [ 0.37803984 -0.48992068]\n",
            " [ 0.26221624 -0.3698698 ]\n",
            " [ 0.31786448 -0.5261687 ]\n",
            " [ 0.35486457 -0.4975546 ]\n",
            " [ 0.36690828 -0.55480605]\n",
            " [ 0.4102022  -0.5122366 ]\n",
            " [ 0.48242912 -0.4458977 ]\n",
            " [ 0.25597656 -0.3344033 ]\n",
            " [ 0.1333224  -0.20060815]\n",
            " [ 0.42743745 -0.40943176]\n",
            " [ 0.44286716 -0.46559486]\n",
            " [ 0.12685663 -0.06424704]\n",
            " [ 0.13193092 -0.13078704]\n",
            " [ 0.4221278  -0.43815598]\n",
            " [ 0.51869255 -0.50206643]\n",
            " [ 0.10076028  0.01789362]\n",
            " [ 0.06954717  0.0525992 ]\n",
            " [ 0.10076028  0.01789362]\n",
            " [ 0.10469028 -0.08606975]\n",
            " [ 0.13372366 -0.10746189]\n",
            " [ 0.4376295  -0.44782585]]\n",
            "Labels:[0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4385, -0.3895],\n",
            "        [ 0.4003, -0.4295],\n",
            "        [ 0.2829, -0.5243],\n",
            "        [ 0.2994, -0.5396],\n",
            "        [ 0.3371, -0.5353],\n",
            "        [ 0.2332, -0.5107],\n",
            "        [ 0.2811, -0.5215],\n",
            "        [ 0.3293, -0.4933],\n",
            "        [ 0.3253, -0.4816],\n",
            "        [ 0.3475, -0.5495],\n",
            "        [ 0.4043, -0.5136],\n",
            "        [ 0.4280, -0.5636],\n",
            "        [ 0.3775, -0.5498],\n",
            "        [ 0.3991, -0.4865],\n",
            "        [ 0.3291, -0.5701],\n",
            "        [ 0.3325, -0.4065],\n",
            "        [ 0.2813, -0.4568],\n",
            "        [ 0.2360, -0.5020],\n",
            "        [ 0.3771, -0.5091],\n",
            "        [ 0.3818, -0.5118],\n",
            "        [ 0.0818, -0.3742],\n",
            "        [ 0.2128, -0.5092],\n",
            "        [ 0.3550, -0.4613],\n",
            "        [ 0.3788, -0.4454],\n",
            "        [ 0.1519, -0.4528],\n",
            "        [ 0.2686, -0.4506],\n",
            "        [ 0.2570, -0.4985],\n",
            "        [ 0.4037, -0.5103],\n",
            "        [ 0.2533, -0.4383],\n",
            "        [ 0.2306, -0.5594],\n",
            "        [ 0.3489, -0.4542],\n",
            "        [ 0.3774, -0.5170]], device='cuda:0')\n",
            "Logits:[[ 0.4385497  -0.38951784]\n",
            " [ 0.40033388 -0.42947516]\n",
            " [ 0.28294277 -0.5242857 ]\n",
            " [ 0.2993757  -0.5395872 ]\n",
            " [ 0.33706254 -0.53525066]\n",
            " [ 0.2331952  -0.51071686]\n",
            " [ 0.28108323 -0.52154213]\n",
            " [ 0.3292784  -0.49328956]\n",
            " [ 0.3252744  -0.48157853]\n",
            " [ 0.34748688 -0.54949003]\n",
            " [ 0.4043236  -0.51357776]\n",
            " [ 0.42796138 -0.56363535]\n",
            " [ 0.3775461  -0.5497564 ]\n",
            " [ 0.3990734  -0.48646253]\n",
            " [ 0.32907513 -0.5701486 ]\n",
            " [ 0.33252516 -0.406547  ]\n",
            " [ 0.2813103  -0.4568    ]\n",
            " [ 0.2360487  -0.5020189 ]\n",
            " [ 0.37709415 -0.50906754]\n",
            " [ 0.38176697 -0.5118425 ]\n",
            " [ 0.08177605 -0.3742403 ]\n",
            " [ 0.21276599 -0.509153  ]\n",
            " [ 0.3549923  -0.46133152]\n",
            " [ 0.3787852  -0.4454367 ]\n",
            " [ 0.15185165 -0.45282096]\n",
            " [ 0.26864493 -0.45058545]\n",
            " [ 0.25702846 -0.4985145 ]\n",
            " [ 0.40366477 -0.5102701 ]\n",
            " [ 0.2532703  -0.43829173]\n",
            " [ 0.23057838 -0.5593584 ]\n",
            " [ 0.348863   -0.4542194 ]\n",
            " [ 0.37744653 -0.5169927 ]]\n",
            "Labels:[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4021, -0.4425],\n",
            "        [ 0.3918, -0.4886],\n",
            "        [ 0.3892, -0.4828],\n",
            "        [ 0.1393, -0.0122],\n",
            "        [ 0.3450, -0.4678],\n",
            "        [ 0.3993, -0.5613],\n",
            "        [ 0.3929, -0.4648],\n",
            "        [ 0.3850, -0.4773],\n",
            "        [ 0.3619, -0.4514],\n",
            "        [ 0.3722, -0.4271],\n",
            "        [ 0.3513, -0.4990],\n",
            "        [ 0.2511, -0.5418],\n",
            "        [ 0.4036, -0.4028],\n",
            "        [ 0.4080, -0.4331],\n",
            "        [ 0.3757, -0.4567],\n",
            "        [ 0.3935, -0.4881],\n",
            "        [ 0.1146, -0.1830],\n",
            "        [ 0.4864, -0.4534],\n",
            "        [ 0.3519, -0.5836],\n",
            "        [ 0.3463, -0.5628],\n",
            "        [ 0.2763, -0.5178],\n",
            "        [ 0.3680, -0.5618],\n",
            "        [ 0.5309, -0.4514],\n",
            "        [ 0.5309, -0.4514],\n",
            "        [ 0.5282, -0.4620],\n",
            "        [ 0.4596, -0.4869],\n",
            "        [ 0.4595, -0.4923],\n",
            "        [ 0.4595, -0.4923],\n",
            "        [ 0.4595, -0.4923],\n",
            "        [ 0.3737, -0.5225],\n",
            "        [ 0.4236, -0.4675],\n",
            "        [ 0.4830, -0.5268]], device='cuda:0')\n",
            "Logits:[[ 0.4021159  -0.4425039 ]\n",
            " [ 0.3918134  -0.48863223]\n",
            " [ 0.38920477 -0.48277566]\n",
            " [ 0.13930316 -0.01222283]\n",
            " [ 0.3449865  -0.4677582 ]\n",
            " [ 0.39926374 -0.56127626]\n",
            " [ 0.39294785 -0.46478593]\n",
            " [ 0.38503098 -0.47730377]\n",
            " [ 0.36185932 -0.45141387]\n",
            " [ 0.37218234 -0.42705843]\n",
            " [ 0.35127768 -0.49901375]\n",
            " [ 0.25109884 -0.5417703 ]\n",
            " [ 0.40362602 -0.40284842]\n",
            " [ 0.4080186  -0.43314603]\n",
            " [ 0.37571892 -0.456736  ]\n",
            " [ 0.39351138 -0.48813096]\n",
            " [ 0.11458007 -0.18296918]\n",
            " [ 0.48644534 -0.4534312 ]\n",
            " [ 0.35190228 -0.58363837]\n",
            " [ 0.3463333  -0.5627867 ]\n",
            " [ 0.27630553 -0.5178348 ]\n",
            " [ 0.36797807 -0.5617808 ]\n",
            " [ 0.53089833 -0.4513803 ]\n",
            " [ 0.53089833 -0.4513803 ]\n",
            " [ 0.52820367 -0.4619946 ]\n",
            " [ 0.45956725 -0.486856  ]\n",
            " [ 0.45951024 -0.4923177 ]\n",
            " [ 0.45951024 -0.4923177 ]\n",
            " [ 0.45951024 -0.4923177 ]\n",
            " [ 0.37367076 -0.5224633 ]\n",
            " [ 0.4235546  -0.4674848 ]\n",
            " [ 0.4829618  -0.5268069 ]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4589, -0.4863],\n",
            "        [ 0.4361, -0.4767],\n",
            "        [ 0.4448, -0.4765],\n",
            "        [ 0.3752, -0.4701],\n",
            "        [ 0.5585, -0.4468],\n",
            "        [ 0.3861, -0.3999],\n",
            "        [ 0.4008, -0.4731],\n",
            "        [ 0.4407, -0.4825],\n",
            "        [ 0.4975, -0.4847],\n",
            "        [ 0.4017, -0.4677],\n",
            "        [ 0.4153, -0.4695],\n",
            "        [ 0.4481, -0.4791],\n",
            "        [ 0.3842, -0.4581],\n",
            "        [ 0.5123, -0.4215],\n",
            "        [ 0.4543, -0.4680],\n",
            "        [ 0.4236, -0.4294],\n",
            "        [ 0.4062, -0.4749],\n",
            "        [ 0.4108, -0.4894],\n",
            "        [ 0.4018, -0.4813],\n",
            "        [ 0.4859, -0.4344],\n",
            "        [ 0.4454, -0.4691],\n",
            "        [ 0.5168, -0.4500],\n",
            "        [ 0.4336, -0.4834],\n",
            "        [ 0.4667, -0.4016],\n",
            "        [ 0.4877, -0.4976],\n",
            "        [ 0.4882, -0.4495],\n",
            "        [ 0.4198, -0.4779],\n",
            "        [ 0.3937, -0.5392],\n",
            "        [ 0.3937, -0.5392],\n",
            "        [ 0.1554, -0.5081],\n",
            "        [ 0.3962, -0.4964],\n",
            "        [ 0.3569, -0.4949]], device='cuda:0')\n",
            "Logits:[[ 0.45888117 -0.48631495]\n",
            " [ 0.43611386 -0.4766804 ]\n",
            " [ 0.44475752 -0.47646275]\n",
            " [ 0.37515095 -0.470083  ]\n",
            " [ 0.55850405 -0.44678947]\n",
            " [ 0.38609308 -0.39987507]\n",
            " [ 0.40083843 -0.4730794 ]\n",
            " [ 0.44070724 -0.4825229 ]\n",
            " [ 0.4975484  -0.48471454]\n",
            " [ 0.401664   -0.46771926]\n",
            " [ 0.4153419  -0.469548  ]\n",
            " [ 0.4481006  -0.47908002]\n",
            " [ 0.3842223  -0.45810524]\n",
            " [ 0.5122827  -0.42150372]\n",
            " [ 0.45434737 -0.4679944 ]\n",
            " [ 0.42361766 -0.429448  ]\n",
            " [ 0.4061516  -0.47489417]\n",
            " [ 0.41083914 -0.4893951 ]\n",
            " [ 0.40184447 -0.48134822]\n",
            " [ 0.4858924  -0.43440932]\n",
            " [ 0.4454472  -0.46907687]\n",
            " [ 0.51681113 -0.4499601 ]\n",
            " [ 0.4336119  -0.48344234]\n",
            " [ 0.46667928 -0.40157858]\n",
            " [ 0.4877095  -0.4975694 ]\n",
            " [ 0.48824975 -0.4494883 ]\n",
            " [ 0.41982326 -0.47793788]\n",
            " [ 0.39370406 -0.53923744]\n",
            " [ 0.39370406 -0.53923744]\n",
            " [ 0.15542354 -0.5080763 ]\n",
            " [ 0.39623576 -0.4964415 ]\n",
            " [ 0.35693073 -0.49489683]]\n",
            "Labels:[0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0]\n",
            "Logits_each:tensor([[ 0.3896, -0.4803],\n",
            "        [ 0.3973, -0.4354],\n",
            "        [ 0.4020, -0.4727],\n",
            "        [ 0.3984, -0.4495],\n",
            "        [ 0.3038, -0.4624],\n",
            "        [ 0.2328, -0.4502],\n",
            "        [ 0.3994, -0.4086],\n",
            "        [ 0.3800, -0.5054],\n",
            "        [ 0.4015, -0.4407],\n",
            "        [ 0.3932, -0.4459],\n",
            "        [ 0.3182, -0.4699],\n",
            "        [ 0.3838, -0.4409],\n",
            "        [ 0.4112, -0.4402],\n",
            "        [ 0.1788, -0.3575],\n",
            "        [ 0.3414, -0.4251],\n",
            "        [ 0.4578, -0.5230],\n",
            "        [ 0.3433, -0.4949],\n",
            "        [ 0.3543, -0.5173],\n",
            "        [ 0.3871, -0.4301],\n",
            "        [ 0.4187, -0.4977],\n",
            "        [ 0.4334, -0.4694],\n",
            "        [ 0.3324, -0.4993],\n",
            "        [ 0.3510, -0.4910],\n",
            "        [ 0.3833, -0.5320],\n",
            "        [ 0.3178, -0.4930],\n",
            "        [ 0.3276, -0.4905],\n",
            "        [ 0.4105, -0.4467],\n",
            "        [ 0.3723, -0.4666],\n",
            "        [ 0.3853, -0.5209],\n",
            "        [ 0.3529, -0.5386],\n",
            "        [ 0.2463, -0.4921],\n",
            "        [ 0.3359, -0.5257]], device='cuda:0')\n",
            "Logits:[[ 0.38961998 -0.48028076]\n",
            " [ 0.397297   -0.4353712 ]\n",
            " [ 0.40200713 -0.47273847]\n",
            " [ 0.39842424 -0.44945008]\n",
            " [ 0.303779   -0.46243075]\n",
            " [ 0.23276088 -0.45016077]\n",
            " [ 0.39935154 -0.40862048]\n",
            " [ 0.37995258 -0.5054287 ]\n",
            " [ 0.40151325 -0.44066978]\n",
            " [ 0.39321342 -0.44588763]\n",
            " [ 0.3182387  -0.46992594]\n",
            " [ 0.3838486  -0.44085285]\n",
            " [ 0.41116434 -0.44016623]\n",
            " [ 0.17879625 -0.35745174]\n",
            " [ 0.3414418  -0.42506608]\n",
            " [ 0.45776796 -0.5229767 ]\n",
            " [ 0.34331632 -0.49485722]\n",
            " [ 0.35426205 -0.5173065 ]\n",
            " [ 0.38710916 -0.4301418 ]\n",
            " [ 0.4187488  -0.4976869 ]\n",
            " [ 0.43342194 -0.46941707]\n",
            " [ 0.33241984 -0.49932656]\n",
            " [ 0.35099918 -0.49095428]\n",
            " [ 0.3832808  -0.53198355]\n",
            " [ 0.3178489  -0.4930268 ]\n",
            " [ 0.32755974 -0.49045616]\n",
            " [ 0.41050476 -0.44674605]\n",
            " [ 0.3722979  -0.46663812]\n",
            " [ 0.38532007 -0.5209195 ]\n",
            " [ 0.35292283 -0.53862494]\n",
            " [ 0.24629074 -0.4921144 ]\n",
            " [ 0.33594912 -0.5257173 ]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3724, -0.5158],\n",
            "        [ 0.4959, -0.5271],\n",
            "        [ 0.4320, -0.5067],\n",
            "        [ 0.5634, -0.5048],\n",
            "        [ 0.5168, -0.4787],\n",
            "        [ 0.4244, -0.5657],\n",
            "        [ 0.5007, -0.5028],\n",
            "        [ 0.4574, -0.5695],\n",
            "        [ 0.4592, -0.4481],\n",
            "        [ 0.4363, -0.5078],\n",
            "        [ 0.4913, -0.4484],\n",
            "        [ 0.4480, -0.5127],\n",
            "        [ 0.4626, -0.5302],\n",
            "        [ 0.4298, -0.5304],\n",
            "        [ 0.5138, -0.4959],\n",
            "        [ 0.3941, -0.5441],\n",
            "        [ 0.4459, -0.5003],\n",
            "        [ 0.4962, -0.5111],\n",
            "        [ 0.3338, -0.5760],\n",
            "        [ 0.4199, -0.5562],\n",
            "        [ 0.4631, -0.5486],\n",
            "        [ 0.4285, -0.5128],\n",
            "        [ 0.4248, -0.4865],\n",
            "        [ 0.4271, -0.5388],\n",
            "        [ 0.3983, -0.4644],\n",
            "        [ 0.4796, -0.5443],\n",
            "        [ 0.5021, -0.5212],\n",
            "        [ 0.4286, -0.5748],\n",
            "        [ 0.4397, -0.5223],\n",
            "        [ 0.4339, -0.5307],\n",
            "        [ 0.3865, -0.4577],\n",
            "        [ 0.3761, -0.3692]], device='cuda:0')\n",
            "Logits:[[ 0.37240222 -0.5158118 ]\n",
            " [ 0.495922   -0.52706605]\n",
            " [ 0.43195412 -0.5066563 ]\n",
            " [ 0.5633692  -0.5048377 ]\n",
            " [ 0.5167974  -0.4787182 ]\n",
            " [ 0.42436984 -0.5656532 ]\n",
            " [ 0.5007165  -0.5028197 ]\n",
            " [ 0.4574405  -0.56951404]\n",
            " [ 0.4591921  -0.44806623]\n",
            " [ 0.43629643 -0.50778687]\n",
            " [ 0.49133468 -0.44842008]\n",
            " [ 0.4480145  -0.512708  ]\n",
            " [ 0.4625584  -0.5301599 ]\n",
            " [ 0.42984194 -0.5304224 ]\n",
            " [ 0.5137756  -0.4959399 ]\n",
            " [ 0.39406252 -0.5441069 ]\n",
            " [ 0.44590738 -0.50034744]\n",
            " [ 0.4961815  -0.51105237]\n",
            " [ 0.33381012 -0.5760369 ]\n",
            " [ 0.41994533 -0.5562449 ]\n",
            " [ 0.4631457  -0.5486369 ]\n",
            " [ 0.42850938 -0.51283795]\n",
            " [ 0.42475238 -0.48645458]\n",
            " [ 0.42714652 -0.5387932 ]\n",
            " [ 0.39829853 -0.4644197 ]\n",
            " [ 0.47960347 -0.5442909 ]\n",
            " [ 0.5020588  -0.5211901 ]\n",
            " [ 0.42857707 -0.5747993 ]\n",
            " [ 0.4396816  -0.5222686 ]\n",
            " [ 0.43387705 -0.5306918 ]\n",
            " [ 0.38649368 -0.45765674]\n",
            " [ 0.37605768 -0.3692225 ]]\n",
            "Labels:[0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1]\n",
            "Logits_each:tensor([[ 0.3900, -0.4543],\n",
            "        [ 0.3488, -0.4881],\n",
            "        [ 0.4105, -0.4863],\n",
            "        [ 0.4684, -0.4696],\n",
            "        [ 0.4684, -0.4696],\n",
            "        [ 0.3739, -0.4481],\n",
            "        [ 0.4613, -0.4679],\n",
            "        [ 0.3587, -0.4519],\n",
            "        [ 0.3839, -0.4826],\n",
            "        [ 0.3714, -0.4471],\n",
            "        [ 0.3847, -0.4365],\n",
            "        [ 0.4096, -0.4656],\n",
            "        [ 0.3524, -0.3992],\n",
            "        [ 0.2537, -0.4330],\n",
            "        [ 0.3495, -0.4572],\n",
            "        [ 0.4565, -0.5253],\n",
            "        [ 0.3945, -0.4674],\n",
            "        [ 0.5338, -0.4397],\n",
            "        [ 0.4580, -0.3770],\n",
            "        [ 0.4577, -0.4097],\n",
            "        [ 0.4428, -0.4123],\n",
            "        [ 0.4459, -0.4012],\n",
            "        [ 0.3941, -0.3143],\n",
            "        [ 0.4146, -0.3656],\n",
            "        [ 0.4827, -0.3735],\n",
            "        [ 0.4472, -0.3985],\n",
            "        [ 0.4470, -0.3738],\n",
            "        [ 0.5162, -0.4486],\n",
            "        [ 0.5181, -0.4268],\n",
            "        [ 0.5370, -0.4501],\n",
            "        [ 0.4968, -0.4349],\n",
            "        [ 0.3206, -0.5400]], device='cuda:0')\n",
            "Logits:[[ 0.3899644  -0.4543338 ]\n",
            " [ 0.34882092 -0.4881493 ]\n",
            " [ 0.41046813 -0.48630255]\n",
            " [ 0.4684331  -0.4696197 ]\n",
            " [ 0.4684331  -0.4696197 ]\n",
            " [ 0.37389734 -0.4480868 ]\n",
            " [ 0.46125373 -0.4679269 ]\n",
            " [ 0.35871863 -0.45192868]\n",
            " [ 0.38388434 -0.48256007]\n",
            " [ 0.37144592 -0.44708183]\n",
            " [ 0.38465244 -0.43651304]\n",
            " [ 0.40962428 -0.46558908]\n",
            " [ 0.35242948 -0.39922738]\n",
            " [ 0.2537423  -0.43301407]\n",
            " [ 0.34947345 -0.45724922]\n",
            " [ 0.45645136 -0.52525276]\n",
            " [ 0.3945075  -0.46735376]\n",
            " [ 0.5337816  -0.4396836 ]\n",
            " [ 0.45799264 -0.37696272]\n",
            " [ 0.4577452  -0.40971637]\n",
            " [ 0.4428059  -0.41227207]\n",
            " [ 0.44588456 -0.40117353]\n",
            " [ 0.39405856 -0.31433532]\n",
            " [ 0.4145555  -0.36563393]\n",
            " [ 0.48269862 -0.3734588 ]\n",
            " [ 0.44722512 -0.39854214]\n",
            " [ 0.44701752 -0.37378272]\n",
            " [ 0.51618874 -0.4485627 ]\n",
            " [ 0.51807165 -0.4268405 ]\n",
            " [ 0.53696895 -0.45011806]\n",
            " [ 0.49680722 -0.43488213]\n",
            " [ 0.32058185 -0.5400432 ]]\n",
            "Labels:[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1]\n",
            "Logits_each:tensor([[ 0.3206, -0.5400],\n",
            "        [ 0.4349, -0.5155],\n",
            "        [ 0.4349, -0.5155],\n",
            "        [ 0.3846, -0.4768],\n",
            "        [ 0.3846, -0.4768],\n",
            "        [ 0.5148, -0.4894],\n",
            "        [ 0.5270, -0.4519],\n",
            "        [ 0.4952, -0.4415],\n",
            "        [ 0.3726, -0.4705],\n",
            "        [ 0.3726, -0.4705],\n",
            "        [ 0.3184, -0.4244],\n",
            "        [ 0.4685, -0.4130],\n",
            "        [ 0.3787, -0.5063],\n",
            "        [ 0.3952, -0.5118],\n",
            "        [ 0.3952, -0.5118],\n",
            "        [ 0.4621, -0.5133],\n",
            "        [ 0.4503, -0.5025],\n",
            "        [ 0.3848, -0.5073],\n",
            "        [ 0.3971, -0.5192],\n",
            "        [ 0.4225, -0.4738],\n",
            "        [ 0.3441, -0.5039],\n",
            "        [ 0.3441, -0.5039],\n",
            "        [ 0.4081, -0.5496],\n",
            "        [ 0.4061, -0.4706],\n",
            "        [ 0.3764, -0.4737],\n",
            "        [ 0.4094, -0.5234],\n",
            "        [ 0.4094, -0.5234],\n",
            "        [ 0.4325, -0.5197],\n",
            "        [ 0.3655, -0.4939],\n",
            "        [ 0.3825, -0.5092],\n",
            "        [ 0.3825, -0.5092],\n",
            "        [ 0.4388, -0.5381]], device='cuda:0')\n",
            "Logits:[[ 0.32058185 -0.5400432 ]\n",
            " [ 0.43489182 -0.5154694 ]\n",
            " [ 0.43489182 -0.5154694 ]\n",
            " [ 0.3846246  -0.47678393]\n",
            " [ 0.3846246  -0.47678393]\n",
            " [ 0.51484954 -0.48936334]\n",
            " [ 0.52704895 -0.45189756]\n",
            " [ 0.49515492 -0.44151655]\n",
            " [ 0.37263274 -0.47050643]\n",
            " [ 0.37263274 -0.47050643]\n",
            " [ 0.3184252  -0.42438373]\n",
            " [ 0.46854895 -0.4129715 ]\n",
            " [ 0.37869662 -0.50634736]\n",
            " [ 0.39517525 -0.5117694 ]\n",
            " [ 0.39517525 -0.5117694 ]\n",
            " [ 0.46207303 -0.51332045]\n",
            " [ 0.45025232 -0.50251025]\n",
            " [ 0.38479215 -0.5072668 ]\n",
            " [ 0.39710388 -0.5192489 ]\n",
            " [ 0.42250782 -0.4738153 ]\n",
            " [ 0.34406826 -0.503936  ]\n",
            " [ 0.34406826 -0.503936  ]\n",
            " [ 0.40805712 -0.5496354 ]\n",
            " [ 0.4060536  -0.470643  ]\n",
            " [ 0.37642762 -0.4736951 ]\n",
            " [ 0.4094449  -0.5233924 ]\n",
            " [ 0.4094449  -0.5233924 ]\n",
            " [ 0.43247914 -0.5197178 ]\n",
            " [ 0.36550608 -0.49394602]\n",
            " [ 0.38247487 -0.5092148 ]\n",
            " [ 0.38247487 -0.5092148 ]\n",
            " [ 0.43879238 -0.5380713 ]]\n",
            "Labels:[1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.4417, -0.5104],\n",
            "        [ 0.4667, -0.5248],\n",
            "        [ 0.4029, -0.4596],\n",
            "        [ 0.3459, -0.4983],\n",
            "        [ 0.2831, -0.4950],\n",
            "        [ 0.4089, -0.5184],\n",
            "        [ 0.3637, -0.4963],\n",
            "        [ 0.3648, -0.5550],\n",
            "        [ 0.3627, -0.5362],\n",
            "        [ 0.4094, -0.5319],\n",
            "        [ 0.4732, -0.5543],\n",
            "        [ 0.4328, -0.5015],\n",
            "        [ 0.4219, -0.5002],\n",
            "        [ 0.4423, -0.5116],\n",
            "        [ 0.3849, -0.4818],\n",
            "        [ 0.4210, -0.4543],\n",
            "        [ 0.4903, -0.4599],\n",
            "        [ 0.4198, -0.4101],\n",
            "        [ 0.4601, -0.4687],\n",
            "        [ 0.4593, -0.5306],\n",
            "        [ 0.4410, -0.5729],\n",
            "        [ 0.4503, -0.5431],\n",
            "        [ 0.3842, -0.5430],\n",
            "        [ 0.4410, -0.4475],\n",
            "        [ 0.4064, -0.4852],\n",
            "        [ 0.3316, -0.5702],\n",
            "        [ 0.3681, -0.5694],\n",
            "        [ 0.3659, -0.5505],\n",
            "        [ 0.4055, -0.5301],\n",
            "        [ 0.2894, -0.5563],\n",
            "        [ 0.3940, -0.5390],\n",
            "        [ 0.3148, -0.5919]], device='cuda:0')\n",
            "Logits:[[ 0.44165158 -0.5103588 ]\n",
            " [ 0.46667877 -0.52481514]\n",
            " [ 0.40294313 -0.45958468]\n",
            " [ 0.3459113  -0.49832484]\n",
            " [ 0.2830705  -0.4950118 ]\n",
            " [ 0.40894255 -0.51837146]\n",
            " [ 0.3636657  -0.49630895]\n",
            " [ 0.36483184 -0.5549983 ]\n",
            " [ 0.36269766 -0.53618556]\n",
            " [ 0.40936738 -0.5318554 ]\n",
            " [ 0.47323015 -0.55428904]\n",
            " [ 0.43280306 -0.5015258 ]\n",
            " [ 0.42189047 -0.50016963]\n",
            " [ 0.44228184 -0.511625  ]\n",
            " [ 0.3849006  -0.48177657]\n",
            " [ 0.4209848  -0.45427662]\n",
            " [ 0.49030295 -0.45993534]\n",
            " [ 0.4198113  -0.4100602 ]\n",
            " [ 0.4600903  -0.4687055 ]\n",
            " [ 0.4592963  -0.5306106 ]\n",
            " [ 0.4409554  -0.57292175]\n",
            " [ 0.45027828 -0.5430792 ]\n",
            " [ 0.38424146 -0.54299617]\n",
            " [ 0.4410347  -0.44748095]\n",
            " [ 0.40635848 -0.48519558]\n",
            " [ 0.3315706  -0.5702423 ]\n",
            " [ 0.36811656 -0.56940913]\n",
            " [ 0.3659168  -0.5504566 ]\n",
            " [ 0.40550256 -0.53011626]\n",
            " [ 0.28936046 -0.5562922 ]\n",
            " [ 0.3940193  -0.53896385]\n",
            " [ 0.3148302  -0.59193325]]\n",
            "Labels:[1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.3351, -0.5968],\n",
            "        [ 0.4542, -0.5147],\n",
            "        [ 0.3617, -0.5053],\n",
            "        [ 0.4258, -0.5433],\n",
            "        [ 0.4437, -0.4355],\n",
            "        [ 0.4376, -0.4836],\n",
            "        [ 0.4029, -0.5319],\n",
            "        [ 0.4518, -0.5154],\n",
            "        [ 0.4037, -0.4903],\n",
            "        [ 0.2642, -0.5350],\n",
            "        [ 0.3862, -0.5389],\n",
            "        [ 0.4242, -0.4475],\n",
            "        [ 0.3937, -0.5481],\n",
            "        [ 0.3945, -0.5545],\n",
            "        [ 0.3980, -0.4700],\n",
            "        [ 0.4487, -0.4456],\n",
            "        [ 0.4366, -0.5175],\n",
            "        [ 0.1538, -0.4094],\n",
            "        [ 0.3349, -0.4190],\n",
            "        [ 0.3028, -0.3937],\n",
            "        [ 0.2858, -0.4153],\n",
            "        [ 0.3575, -0.4446],\n",
            "        [ 0.3095, -0.4372],\n",
            "        [ 0.3092, -0.4519],\n",
            "        [ 0.4817, -0.4828],\n",
            "        [ 0.5230, -0.4881],\n",
            "        [ 0.3751, -0.4095],\n",
            "        [ 0.2897, -0.4887],\n",
            "        [ 0.4387, -0.4441],\n",
            "        [ 0.4780, -0.4715],\n",
            "        [ 0.4083, -0.4569],\n",
            "        [ 0.4129, -0.4364]], device='cuda:0')\n",
            "Logits:[[ 0.33511606 -0.5967538 ]\n",
            " [ 0.454211   -0.5146919 ]\n",
            " [ 0.3616821  -0.50533235]\n",
            " [ 0.42584032 -0.54334944]\n",
            " [ 0.4436642  -0.43551832]\n",
            " [ 0.43755162 -0.4836074 ]\n",
            " [ 0.40286833 -0.5318916 ]\n",
            " [ 0.45178002 -0.5153678 ]\n",
            " [ 0.4036599  -0.4902902 ]\n",
            " [ 0.2641875  -0.53504115]\n",
            " [ 0.3861703  -0.5388693 ]\n",
            " [ 0.42415982 -0.44748104]\n",
            " [ 0.39371654 -0.5481061 ]\n",
            " [ 0.394463   -0.55454   ]\n",
            " [ 0.3979525  -0.4700239 ]\n",
            " [ 0.44867662 -0.4456483 ]\n",
            " [ 0.43655095 -0.51748544]\n",
            " [ 0.15378818 -0.4094247 ]\n",
            " [ 0.3348743  -0.4189742 ]\n",
            " [ 0.30282506 -0.39366013]\n",
            " [ 0.28577483 -0.41525474]\n",
            " [ 0.35746497 -0.44459745]\n",
            " [ 0.30952933 -0.4371661 ]\n",
            " [ 0.30916762 -0.451856  ]\n",
            " [ 0.48165601 -0.4827557 ]\n",
            " [ 0.5230465  -0.48805013]\n",
            " [ 0.37510136 -0.4095101 ]\n",
            " [ 0.28973937 -0.4886652 ]\n",
            " [ 0.43869522 -0.44413185]\n",
            " [ 0.47798017 -0.47150442]\n",
            " [ 0.4083342  -0.45694694]\n",
            " [ 0.41289312 -0.43640947]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
            "Logits_each:tensor([[ 0.5105, -0.4832],\n",
            "        [ 0.4013, -0.3963],\n",
            "        [ 0.3782, -0.4244],\n",
            "        [ 0.3611, -0.4702],\n",
            "        [ 0.3597, -0.4544],\n",
            "        [ 0.2526, -0.4995],\n",
            "        [ 0.3141, -0.4548],\n",
            "        [ 0.3843, -0.5184],\n",
            "        [ 0.3551, -0.4985],\n",
            "        [ 0.4278, -0.4395],\n",
            "        [ 0.4602, -0.4995],\n",
            "        [ 0.4471, -0.4780],\n",
            "        [ 0.4652, -0.4905],\n",
            "        [ 0.3619, -0.4808],\n",
            "        [ 0.4506, -0.4943],\n",
            "        [ 0.3784, -0.5470],\n",
            "        [ 0.4053, -0.5324],\n",
            "        [ 0.3782, -0.5686],\n",
            "        [ 0.3987, -0.5640],\n",
            "        [ 0.3463, -0.5182],\n",
            "        [ 0.4081, -0.5300],\n",
            "        [ 0.3784, -0.5076],\n",
            "        [ 0.4189, -0.4792],\n",
            "        [ 0.4873, -0.5300],\n",
            "        [ 0.4951, -0.5049],\n",
            "        [ 0.3199, -0.4770],\n",
            "        [ 0.4592, -0.4381],\n",
            "        [ 0.4865, -0.4545],\n",
            "        [ 0.4246, -0.4353],\n",
            "        [ 0.4494, -0.5170],\n",
            "        [ 0.4468, -0.4628],\n",
            "        [ 0.4522, -0.5519]], device='cuda:0')\n",
            "Logits:[[ 0.51049364 -0.48322138]\n",
            " [ 0.4013269  -0.39626613]\n",
            " [ 0.37816715 -0.42435095]\n",
            " [ 0.36113393 -0.4702432 ]\n",
            " [ 0.35970935 -0.45443797]\n",
            " [ 0.25261095 -0.499459  ]\n",
            " [ 0.3141417  -0.45481387]\n",
            " [ 0.38425076 -0.51838654]\n",
            " [ 0.3551004  -0.49850202]\n",
            " [ 0.42778227 -0.43945286]\n",
            " [ 0.4602023  -0.49954948]\n",
            " [ 0.44705275 -0.47800466]\n",
            " [ 0.4652356  -0.49049833]\n",
            " [ 0.36187103 -0.48081872]\n",
            " [ 0.45064837 -0.49427253]\n",
            " [ 0.37838018 -0.54696816]\n",
            " [ 0.4053101  -0.5324086 ]\n",
            " [ 0.37824336 -0.5686213 ]\n",
            " [ 0.39865977 -0.5639885 ]\n",
            " [ 0.34633544 -0.5181883 ]\n",
            " [ 0.40811098 -0.5299575 ]\n",
            " [ 0.37839267 -0.5076289 ]\n",
            " [ 0.41888916 -0.4792061 ]\n",
            " [ 0.48732266 -0.5300073 ]\n",
            " [ 0.495095   -0.5048959 ]\n",
            " [ 0.31985113 -0.47698823]\n",
            " [ 0.459188   -0.43813413]\n",
            " [ 0.48650628 -0.4545386 ]\n",
            " [ 0.42455944 -0.4353291 ]\n",
            " [ 0.44940054 -0.5170082 ]\n",
            " [ 0.4467988  -0.46282208]\n",
            " [ 0.45218882 -0.551891  ]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0]\n",
            "Logits_each:tensor([[ 0.4691, -0.4710],\n",
            "        [ 0.3244, -0.4824],\n",
            "        [ 0.3962, -0.5030],\n",
            "        [ 0.3696, -0.4386],\n",
            "        [ 0.4336, -0.4373],\n",
            "        [ 0.3145, -0.5198],\n",
            "        [ 0.4757, -0.4025],\n",
            "        [ 0.2694, -0.4744],\n",
            "        [ 0.0915, -0.3584],\n",
            "        [ 0.3600, -0.4602],\n",
            "        [ 0.4242, -0.4758],\n",
            "        [ 0.4518, -0.4451],\n",
            "        [ 0.2998, -0.5021],\n",
            "        [ 0.4403, -0.4795],\n",
            "        [ 0.3606, -0.4837],\n",
            "        [ 0.2436, -0.5819],\n",
            "        [ 0.3666, -0.4845],\n",
            "        [ 0.4139, -0.4415],\n",
            "        [ 0.2471, -0.5253],\n",
            "        [ 0.2395, -0.5271],\n",
            "        [ 0.4610, -0.5141],\n",
            "        [ 0.2426, -0.4981],\n",
            "        [ 0.4484, -0.4714],\n",
            "        [ 0.2283, -0.5221],\n",
            "        [ 0.4016, -0.4186],\n",
            "        [ 0.3719, -0.4564],\n",
            "        [ 0.4148, -0.4816],\n",
            "        [ 0.2569, -0.5258],\n",
            "        [ 0.3858, -0.4911],\n",
            "        [ 0.4360, -0.5423],\n",
            "        [ 0.4360, -0.5423],\n",
            "        [ 0.4360, -0.5423]], device='cuda:0')\n",
            "Logits:[[ 0.46907842 -0.4710217 ]\n",
            " [ 0.32436258 -0.48243323]\n",
            " [ 0.39622742 -0.5029778 ]\n",
            " [ 0.3695791  -0.43860275]\n",
            " [ 0.43364528 -0.43734905]\n",
            " [ 0.31445158 -0.51976913]\n",
            " [ 0.47571406 -0.40248126]\n",
            " [ 0.26944688 -0.47439572]\n",
            " [ 0.09149923 -0.3583559 ]\n",
            " [ 0.36003453 -0.46024877]\n",
            " [ 0.42421308 -0.4758392 ]\n",
            " [ 0.4518216  -0.44512868]\n",
            " [ 0.2998151  -0.50209635]\n",
            " [ 0.44029444 -0.47945082]\n",
            " [ 0.36059326 -0.48367104]\n",
            " [ 0.24356677 -0.5819354 ]\n",
            " [ 0.36663273 -0.48447442]\n",
            " [ 0.4138973  -0.44153   ]\n",
            " [ 0.24711773 -0.52532077]\n",
            " [ 0.23946778 -0.5270915 ]\n",
            " [ 0.46096453 -0.51407105]\n",
            " [ 0.242621   -0.4981136 ]\n",
            " [ 0.44837403 -0.4714345 ]\n",
            " [ 0.22828557 -0.5221326 ]\n",
            " [ 0.4016124  -0.41858923]\n",
            " [ 0.37194547 -0.4564085 ]\n",
            " [ 0.4147619  -0.4816458 ]\n",
            " [ 0.2569491  -0.52584213]\n",
            " [ 0.3858104  -0.4910894 ]\n",
            " [ 0.43602896 -0.54229957]\n",
            " [ 0.43602896 -0.54229957]\n",
            " [ 0.43602896 -0.54229957]]\n",
            "Labels:[0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
            "Logits_each:tensor([[ 0.3725, -0.4520],\n",
            "        [ 0.3725, -0.4520],\n",
            "        [ 0.4174, -0.3876],\n",
            "        [ 0.3499, -0.4221],\n",
            "        [ 0.3499, -0.4221],\n",
            "        [ 0.4506, -0.3291],\n",
            "        [ 0.2908, -0.4126],\n",
            "        [ 0.3311, -0.4925],\n",
            "        [ 0.2432, -0.4237],\n",
            "        [ 0.4081, -0.4823],\n",
            "        [ 0.3982, -0.4270],\n",
            "        [ 0.2719, -0.4134],\n",
            "        [ 0.3936, -0.4086],\n",
            "        [ 0.3456, -0.4361],\n",
            "        [ 0.4067, -0.4919],\n",
            "        [ 0.3990, -0.4622],\n",
            "        [ 0.4067, -0.4919],\n",
            "        [ 0.4067, -0.4919],\n",
            "        [ 0.3733, -0.4738],\n",
            "        [ 0.4074, -0.4574],\n",
            "        [ 0.3993, -0.4609],\n",
            "        [ 0.4074, -0.4574],\n",
            "        [ 0.4626, -0.5188],\n",
            "        [ 0.4375, -0.5693],\n",
            "        [ 0.3118, -0.5662],\n",
            "        [ 0.3176, -0.4957],\n",
            "        [ 0.4008, -0.4951],\n",
            "        [ 0.4641, -0.5057],\n",
            "        [ 0.3953, -0.5172],\n",
            "        [ 0.3489, -0.5250],\n",
            "        [ 0.4215, -0.5044],\n",
            "        [ 0.3412, -0.5198]], device='cuda:0')\n",
            "Logits:[[ 0.3725017  -0.4520371 ]\n",
            " [ 0.3725017  -0.4520371 ]\n",
            " [ 0.41740018 -0.387605  ]\n",
            " [ 0.349924   -0.4220609 ]\n",
            " [ 0.349924   -0.4220609 ]\n",
            " [ 0.45057064 -0.3290714 ]\n",
            " [ 0.29076698 -0.41263166]\n",
            " [ 0.3310692  -0.49245164]\n",
            " [ 0.24322322 -0.42369312]\n",
            " [ 0.40813458 -0.4822995 ]\n",
            " [ 0.39824197 -0.42704153]\n",
            " [ 0.27185452 -0.4133538 ]\n",
            " [ 0.3935888  -0.40858617]\n",
            " [ 0.34556013 -0.43608895]\n",
            " [ 0.4066589  -0.49193224]\n",
            " [ 0.39903623 -0.46218005]\n",
            " [ 0.4066589  -0.49193224]\n",
            " [ 0.4066589  -0.49193224]\n",
            " [ 0.37334767 -0.4738353 ]\n",
            " [ 0.40742078 -0.45741317]\n",
            " [ 0.39934915 -0.4608712 ]\n",
            " [ 0.40742078 -0.45741317]\n",
            " [ 0.46261418 -0.5188326 ]\n",
            " [ 0.43749028 -0.56929064]\n",
            " [ 0.311783   -0.5661712 ]\n",
            " [ 0.31762156 -0.49569267]\n",
            " [ 0.40075088 -0.49513835]\n",
            " [ 0.4641209  -0.5056932 ]\n",
            " [ 0.39533937 -0.51715714]\n",
            " [ 0.3488584  -0.5250138 ]\n",
            " [ 0.42146897 -0.50436515]\n",
            " [ 0.34123805 -0.5197809 ]]\n",
            "Labels:[1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0]\n",
            "Logits_each:tensor([[ 0.4492, -0.5103],\n",
            "        [ 0.4691, -0.4641],\n",
            "        [ 0.3720, -0.4547],\n",
            "        [ 0.3894, -0.4754],\n",
            "        [ 0.3640, -0.5199],\n",
            "        [ 0.4003, -0.4777],\n",
            "        [ 0.4663, -0.4778],\n",
            "        [ 0.4109, -0.4756],\n",
            "        [ 0.4372, -0.5039],\n",
            "        [ 0.3670, -0.5253],\n",
            "        [ 0.4550, -0.4726],\n",
            "        [ 0.4665, -0.4833],\n",
            "        [ 0.4148, -0.4632],\n",
            "        [ 0.4477, -0.4593]], device='cuda:0')\n",
            "Logits:[[ 0.44915086 -0.51032037]\n",
            " [ 0.46914852 -0.46412095]\n",
            " [ 0.37204435 -0.454679  ]\n",
            " [ 0.38940546 -0.47542435]\n",
            " [ 0.36404318 -0.5198597 ]\n",
            " [ 0.40032515 -0.47773635]\n",
            " [ 0.4663019  -0.47778678]\n",
            " [ 0.4108857  -0.47555244]\n",
            " [ 0.4371958  -0.5038687 ]\n",
            " [ 0.3669526  -0.5252967 ]\n",
            " [ 0.4549975  -0.4725848 ]\n",
            " [ 0.46654215 -0.48334968]\n",
            " [ 0.4148141  -0.46319035]\n",
            " [ 0.44766614 -0.45926994]]\n",
            "Labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Validation Accuracy: 0.6850328947368421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkSzBBkZ4CpP"
      },
      "source": [
        "# torch.save(model.state_dict(), '/content/drive/MyDrive/Thesis_B/weights_default')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JEZy0Ap6Sey"
      },
      "source": [
        "# model.load_state_dict(torch.load('/content/drive/MyDrive/Thesis_B/weights_default'))\n",
        "# model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTPRjAmeHrvm"
      },
      "source": [
        "# # load the model checkpoint\n",
        "# checkpoint = torch.load('../outputs/model.pth')\n",
        "# # load model weights state_dict\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# print('Previously trained model weights state_dict loaded...')\n",
        "# # load trained optimizer state_dict\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# print('Previously trained optimizer state_dict loaded...')\n",
        "# epochs = checkpoint['epoch']\n",
        "# # load the criterion\n",
        "# criterion = checkpoint['loss']\n",
        "# print('Trained model loss function loaded...')\n",
        "# print(f\"Previously trained for {epochs} number of epochs...\")\n",
        "# # train for more epochs\n",
        "# epochs = new_epochs\n",
        "# print(f\"Train for {epochs} more epochs...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erabHF9UHhOS"
      },
      "source": [
        "# # save model checkpoint\n",
        "# torch.save({\n",
        "#             'epoch': epochs,\n",
        "#             'model_state_dict': model.state_dict(),\n",
        "#             'optimizer_state_dict': optimizer.state_dict(),\n",
        "#             'loss': criterion,\n",
        "#             }, '/content/drive/MyDrive/Thesis_B/outputs/model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}