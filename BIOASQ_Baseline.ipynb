{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BIOASQ_Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Q4j6uSw6JhJhqaQ9LxaUrvNdMOW9g07J",
      "authorship_tag": "ABX9TyOj2wxR3tSRMECOX3xSL8KI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahithikodali1/Summarization-of-Biomedical-evidence/blob/Data_processing/BIOASQ_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmPJRc69hX1u",
        "outputId": "91f4f38d-b0ec-45a8-b11d-516c38340ad5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "print(os.listdir(\"/content/drive/MyDrive/Thesis_B\"))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rouge_8b_mod.csv', '.ipynb_checkpoints', 'test_data.csv', 'train_data.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2HrufEhQFyA"
      },
      "source": [
        "DATA_DIR = \"/content/drive/MyDrive/Thesis_B\"\n",
        "\n",
        "file = pd.read_csv(os.path.join(DATA_DIR,'rouge_8b_mod.csv'))\n",
        "f_values = file.values\n",
        "# print(f_values[:10])\n",
        "# print(col_names[:10])\n",
        "q_id_split = np.split(f_values, np.where(np.diff(f_values[:,0]))[0]+1)\n",
        "# print(q_id_split[:2])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPZjUxtKQbWn",
        "outputId": "6c894aec-30cb-413f-d062-0bb5cbbbfd0b"
      },
      "source": [
        "train_data_size = round(len(q_id_split)*0.8)\n",
        "test_data_size = round(len(q_id_split) - train_data_size)\n",
        "print(train_data_size)\n",
        "print(test_data_size)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2594\n",
            "648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPsL_08rQIkN",
        "outputId": "d410ae66-cdf9-497f-9075-233d819ef5eb"
      },
      "source": [
        "import random\n",
        "random.seed(3007)\n",
        "random.shuffle(q_id_split)\n",
        "print(type(q_id_split[:1]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54_yWb5WCCXy",
        "outputId": "ee54ac82-649d-4531-d22d-b62d547afda4"
      },
      "source": [
        "train_data_beforeval = q_id_split[:2594]\n",
        "f_values_train_beforeval = np.concatenate(train_data_beforeval, axis=0)\n",
        "# print((f_values_train_beforeval))\n",
        "\n",
        "q_id_split_train = np.split(f_values_train_beforeval, np.where(np.diff(f_values_train_beforeval[:,0]))[0]+1)\n",
        "print(len(q_id_split_train))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxLTiTwxCcFP",
        "outputId": "642c2828-3760-409f-e88c-0d6855adefc6"
      },
      "source": [
        "val_data_size = round(len(q_id_split_train)*0.2)\n",
        "train_data_size = round(len(q_id_split_train) - val_data_size)\n",
        "print(train_data_size)\n",
        "print(val_data_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2075\n",
            "519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uqmc8JyC6oW",
        "outputId": "8001efb5-7249-4329-8bec-1246ded9f5f2"
      },
      "source": [
        "train_data = q_id_split_train[:2075]\n",
        "val_data = q_id_split_train[2075:]\n",
        "test_data = q_id_split[2594:]\n",
        "f_values_train = np.concatenate(train_data, axis=0)\n",
        "f_values_val = np.concatenate(val_data, axis=0)\n",
        "f_values_test = np.concatenate(test_data, axis=0)\n",
        "col_names = file.columns\n",
        "print(col_names)\n",
        "\n",
        "train_df = pd.DataFrame(f_values_train, columns = col_names)\n",
        "val_df = pd.DataFrame(f_values_val, columns = col_names)\n",
        "test_df = pd.DataFrame(f_values_test, columns = col_names)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['qid', 'pubmedid', 'sentid', 'N1', 'N2', 'L', 'S4', 'SU4',\n",
            "       'sentence text', 'SU4_labels'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6_hHEVzRV0W",
        "outputId": "7ccbde32-4835-4928-b26e-2ef1a28e0b34"
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(val_data))\n",
        "print(len(test_data))\n",
        "\n",
        "print(len(train_df))\n",
        "print(len(val_df))\n",
        "print(len(test_df))\n",
        "print(train_df.columns.values)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2075\n",
            "519\n",
            "648\n",
            "33435\n",
            "8148\n",
            "10161\n",
            "['qid' 'pubmedid' 'sentid' 'N1' 'N2' 'L' 'S4' 'SU4' 'sentence text'\n",
            " 'SU4_labels']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bO879zfXiB3P",
        "outputId": "41df3e3f-f805-4c4d-ebd3-be31f3f9720f"
      },
      "source": [
        "# install\n",
        "!pip install pytorch-pretrained-bert pytorch-nlp\n",
        "\n",
        "# BERT imports\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification, BertForMaskedLM\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.17.62)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.8.1+cu101)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.62 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.20.62)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.4.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.62->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.62->boto3->pytorch-pretrained-bert) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZmKLBPwmzIg"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgOIOnmlm46q"
      },
      "source": [
        "def data_grouplists(data):\n",
        "  data_list = data.groupby('qid', as_index=False)['SU4','SU4_labels','sentence text'].agg(list)\n",
        "  return data_list"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQxqZJ3v1aIX",
        "outputId": "946161a1-8809-4a69-9e89-cc557abc3426"
      },
      "source": [
        "train_list = data_grouplists(train_df)\n",
        "val_list = data_grouplists(val_df)\n",
        "test_list = data_grouplists(test_df)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWQMp4ckqlP1"
      },
      "source": [
        "def add_specialtokens(data_list):\n",
        "  specialtok_sentences = []\n",
        "\n",
        "  for sentence in data_list['sentence text']:\n",
        "    each_specialtoken = []\n",
        "    for each in sentence:\n",
        "      each_specialtoken.append([\"[CLS] \" + each + \" [SEP]\" ])\n",
        "    specialtok_sentences.append(each_specialtoken)\n",
        "  return specialtok_sentences"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8DNwLWL2pNO"
      },
      "source": [
        "train_specialtok = add_specialtokens(train_list)\n",
        "val_specialtok = add_specialtokens(val_list)\n",
        "test_specialtok = add_specialtokens(test_list)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ8212nk20WG",
        "outputId": "935159b1-ef64-4bdb-ce8a-118617171d8e"
      },
      "source": [
        "print(train_specialtok[0])\n",
        "print(train_specialtok[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['[CLS] Papilin is an extracellular matrix glycoprotein [SEP]'], ['[CLS] apilins are homologous, secreted extracellular matrix proteins which share a common order of protein domains. [SEP]'], ['[CLS] Both MIG-6 isoforms have a predicted N-terminal papilin cassette [SEP]'], ['[CLS] The TSR superfamily is a diverse family of extracellular matrix and transmembrane proteins, many of which have functions related to regulating matrix organization, cell-cell interactions and cell guidance. [SEP]'], ['[CLS]  Collagen IV, laminin, glutactin, papilin, and other extracellular matrix proteins were made primarily by hemocytes and were secreted into the medium. [SEP]'], ['[CLS] A sulfated glycoprotein was isolated from the culture media of Drosophila Kc cells and named papilin. [SEP]'], ['[CLS] Using expression analysis, we identify three genes that are transcriptionally regulated by HLH-2: the protocadherin cdh-3, and two genes encoding secreted extracellular matrix proteins, mig-6/papilin and him-4/hemicentin. [SEP]'], ['[CLS] F-spondin, UNC-5, ADAMTS, papilin, and TRAP) where specific functions are assigned to the TSR domains. [SEP]'], ['[CLS] We found that mig-6 encodes long (MIG-6L) and short (MIG-6S) isoforms of the extracellular matrix protein papilin, each required for distinct aspects of DTC migration. [SEP]'], ['[CLS] Papilins are extracellular matrix proteins [SEP]'], ['[CLS] This review samples some of the contemporary literature regarding TSR superfamily members (e.g. [SEP]']]\n",
            "[['[CLS] Osteoprotegerin (OPG) and receptor activator of nuclear factor κB ligand (RANKL) are cytokines predominantly secreted by osteoblasts and play critical roles in the differentiation and function of osteoclasts. [SEP]'], ['[CLS] Receptor activator of nuclear factor κB ligand (RANKL) and osteoprotegerin (OPG) are cytokines predominantly secreted by osteoblasts and play a central role in differentiation and functional activation of osteoclasts [SEP]'], ['[CLS] It usually functions in bone remodeling, by inhibiting osteoclastogenesis through interaction with a receptor activator of the nuclear factor κB (RANKL). [SEP]'], ['[CLS] Osteoprotegerin (OPG) is a soluble secreted factor that acts as a decoy receptor for receptor activator of NF-κB ligand (RANKL) [SEP]'], ['[CLS] Osteoprotegerin (OPG) is an essential secreted protein in bone turnover due to its role as a decoy receptor for the Receptor Activator of Nuclear Factor-kB ligand (RANKL) in the osteoclasts, thus inhibiting their differentiation [SEP]'], ['[CLS] Osteoprotegerin (OPG) is a secreted glycoprotein and a member of the tumor necrosis factor receptor superfamily. [SEP]'], ['[CLS] OPG, on the other hand, is secreted by osteoblast as a decoy receptor for RANKL, prevents RANKL from binding to RANK and thus prevents bone resorption [SEP]'], ['[CLS] e RANKL/OPG ratio secreted by osteoblasts increased and RANK expression by osteoclasts increased, leading to increased osteoclastogenesis [SEP]'], ['[CLS] Activated human T cells express alternative mRNA transcripts encoding a secreted form of RANKL. [SEP]'], ['[CLS] Although B. abortus-activated T cells actively secreted the pro-osteoclastogenic cytokines RANKL and IL-17, osteoclastogenesis depended on IL-17, because osteoclast generation induced by Brucella-activated T cells was completely abrogated when these cells were cultured with BMMs from IL-17 receptor knockout mice. [SEP]'], ['[CLS] We identify a TNFSF11 transcript variant that extends the originally identified transcript encoding secreted RANKL. [SEP]'], ['[CLS] We isolated human fibroblasts from RA, pyrophosphate arthropathy (PPA) and osteoarthritis (OA) patients and analyzed their RANKL/OPG expression profile and the capacity of their secreted factors to induce osteoclastogenesis. [SEP]'], ['[CLS]  osteoclastogenesis and bone destruction in autoimmune arthritis. [SEP]']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nsQ8itK2-IW"
      },
      "source": [
        "def tokenize_sentences(specialtok_sentences):\n",
        "  tokenized_sentences = []\n",
        "\n",
        "  for sentence in specialtok_sentences:\n",
        "    eachsent_tokenized = []\n",
        "    for each in sentence:\n",
        "      eachsent_tokenized.append(tokenizer.tokenize(each[0]))\n",
        "    tokenized_sentences.append(eachsent_tokenized)\n",
        "  return tokenized_sentences"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgi8wXqU1uTg"
      },
      "source": [
        "train_tokenized = tokenize_sentences(train_specialtok)\n",
        "val_tokenized = tokenize_sentences(val_specialtok)\n",
        "test_tokenized = tokenize_sentences(test_specialtok)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW6p7qIU4Thv"
      },
      "source": [
        "def data_tokenizedsent(tokenized_sentences, data_list):\n",
        "  data_list['tokenized_sentences'] = tokenized_sentences\n",
        "  return data_list"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgJ0YFuS4kXP",
        "outputId": "1bbd2145-fc3b-4aa4-97ec-b46dfad19fba"
      },
      "source": [
        "print(train_tokenized[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['[CLS]', 'pa', '##pi', '##lin', 'is', 'an', 'extra', '##cellular', 'matrix', 'g', '##ly', '##co', '##pro', '##tein', '[SEP]'], ['[CLS]', 'api', '##lins', 'are', 'homo', '##log', '##ous', ',', 'secret', '##ed', 'extra', '##cellular', 'matrix', 'proteins', 'which', 'share', 'a', 'common', 'order', 'of', 'protein', 'domains', '.', '[SEP]'], ['[CLS]', 'both', 'mig', '-', '6', 'iso', '##forms', 'have', 'a', 'predicted', 'n', '-', 'terminal', 'pa', '##pi', '##lin', 'cassette', '[SEP]'], ['[CLS]', 'the', 'ts', '##r', 'superfamily', 'is', 'a', 'diverse', 'family', 'of', 'extra', '##cellular', 'matrix', 'and', 'trans', '##me', '##mb', '##rane', 'proteins', ',', 'many', 'of', 'which', 'have', 'functions', 'related', 'to', 'regulating', 'matrix', 'organization', ',', 'cell', '-', 'cell', 'interactions', 'and', 'cell', 'guidance', '.', '[SEP]'], ['[CLS]', 'col', '##lage', '##n', 'iv', ',', 'lam', '##ini', '##n', ',', 'g', '##lu', '##ta', '##ct', '##in', ',', 'pa', '##pi', '##lin', ',', 'and', 'other', 'extra', '##cellular', 'matrix', 'proteins', 'were', 'made', 'primarily', 'by', 'hem', '##ocytes', 'and', 'were', 'secret', '##ed', 'into', 'the', 'medium', '.', '[SEP]'], ['[CLS]', 'a', 'sulfate', '##d', 'g', '##ly', '##co', '##pro', '##tein', 'was', 'isolated', 'from', 'the', 'culture', 'media', 'of', 'dr', '##oso', '##phila', 'kc', 'cells', 'and', 'named', 'pa', '##pi', '##lin', '.', '[SEP]'], ['[CLS]', 'using', 'expression', 'analysis', ',', 'we', 'identify', 'three', 'genes', 'that', 'are', 'transcription', '##ally', 'regulated', 'by', 'h', '##l', '##h', '-', '2', ':', 'the', 'proto', '##ca', '##dh', '##erin', 'cd', '##h', '-', '3', ',', 'and', 'two', 'genes', 'encoding', 'secret', '##ed', 'extra', '##cellular', 'matrix', 'proteins', ',', 'mig', '-', '6', '/', 'pa', '##pi', '##lin', 'and', 'him', '-', '4', '/', 'hem', '##ice', '##nti', '##n', '.', '[SEP]'], ['[CLS]', 'f', '-', 'sp', '##ond', '##in', ',', 'un', '##c', '-', '5', ',', 'adam', '##ts', ',', 'pa', '##pi', '##lin', ',', 'and', 'trap', ')', 'where', 'specific', 'functions', 'are', 'assigned', 'to', 'the', 'ts', '##r', 'domains', '.', '[SEP]'], ['[CLS]', 'we', 'found', 'that', 'mig', '-', '6', 'en', '##codes', 'long', '(', 'mig', '-', '6', '##l', ')', 'and', 'short', '(', 'mig', '-', '6', '##s', ')', 'iso', '##forms', 'of', 'the', 'extra', '##cellular', 'matrix', 'protein', 'pa', '##pi', '##lin', ',', 'each', 'required', 'for', 'distinct', 'aspects', 'of', 'dt', '##c', 'migration', '.', '[SEP]'], ['[CLS]', 'pa', '##pi', '##lins', 'are', 'extra', '##cellular', 'matrix', 'proteins', '[SEP]'], ['[CLS]', 'this', 'review', 'samples', 'some', 'of', 'the', 'contemporary', 'literature', 'regarding', 'ts', '##r', 'superfamily', 'members', '(', 'e', '.', 'g', '.', '[SEP]']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZMhWwmZ4oae"
      },
      "source": [
        "data_train_tokenized = data_tokenizedsent(train_tokenized, train_list)\n",
        "data_val_tokenized = data_tokenizedsent(val_tokenized, val_list)\n",
        "data_test_tokenized = data_tokenizedsent(test_tokenized, test_list)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiHS9PKB43h4",
        "outputId": "4363c571-6da3-440d-a2cb-3345444d7376"
      },
      "source": [
        "print(data_train_tokenized.columns.values)\n",
        "print(data_train_tokenized)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['qid' 'SU4' 'SU4_labels' 'sentence text' 'tokenized_sentences']\n",
            "       qid  ...                                tokenized_sentences\n",
            "0        2  ...  [[[CLS], pa, ##pi, ##lin, is, an, extra, ##cel...\n",
            "1        4  ...  [[[CLS], os, ##te, ##op, ##rot, ##eger, ##in, ...\n",
            "2        6  ...  [[[CLS], serum, mir, -, 132, ,, mir, -, 26, ##...\n",
            "3        7  ...  [[[CLS], p, ##yr, ##ido, ##sti, ##gm, ##ine, i...\n",
            "4        9  ...  [[[CLS], w, ##nt, signaling, activate, ##s, th...\n",
            "...    ...  ...                                                ...\n",
            "2070  3235  ...  [[[CLS], the, genus, ana, ##pl, ##as, ##ma, be...\n",
            "2071  3236  ...  [[[CLS], a, number, of, bacteria, use, a, clas...\n",
            "2072  3237  ...  [[[CLS], ri, ##tu, ##xi, ##ma, ##b, in, childr...\n",
            "2073  3238  ...  [[[CLS], the, crystal, structures, of, pi, ##m...\n",
            "2074  3239  ...  [[[CLS], our, results, suggest, that, m2, -, l...\n",
            "\n",
            "[2075 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WHXKf6E5ZQ3",
        "outputId": "74a3287b-1bfa-408c-85e1-4a067f594ac5"
      },
      "source": [
        "print(len(train_tokenized[0]))\n",
        "print(len(train_tokenized[1]))\n",
        "print(len(train_tokenized[2]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11\n",
            "13\n",
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHb0_VKg53Mm"
      },
      "source": [
        "def token2ids(tokenized_sentences):\n",
        "  # Set the maximum sequence length. \n",
        "  MAX_LEN = 512\n",
        "  token_ids = []\n",
        "\n",
        "  for tokenized_sentence in tokenized_sentences:\n",
        "    tokens_to_ids = [tokenizer.convert_tokens_to_ids(each) for each in tokenized_sentence]\n",
        "    tokens_to_ids = pad_sequences(tokens_to_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    token_ids.append(tokens_to_ids)\n",
        "  return token_ids"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGZvHIjh6qHL",
        "outputId": "58222e87-4aaa-4f7c-d9f2-0019573dfcb3"
      },
      "source": [
        "train_tokens2ids = token2ids(train_tokenized)\n",
        "val_tokens2ids = token2ids(val_tokenized)\n",
        "test_tokens2ids = token2ids(test_tokenized)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (529 > 512). Running this sequence through BERT will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiArL92V7IO3",
        "outputId": "55f4f234-a684-4339-b3a8-1e500d53ecc9"
      },
      "source": [
        "print(len(train_tokens2ids))\n",
        "print(len(train_tokens2ids[0]))\n",
        "print(len(train_tokens2ids[1]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2075\n",
            "11\n",
            "13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbQNwNja5q2O"
      },
      "source": [
        "def create_masks(token_ids):\n",
        "  attention_masks = []\n",
        "\n",
        "  for tid in token_ids:\n",
        "    eachtid_mask = []\n",
        "    for each in tid:\n",
        "      mask = [float(i>0) for i in each] #for each token \n",
        "      eachtid_mask.append(mask)#for each sentence\n",
        "    attention_masks.append(np.array(eachtid_mask))\n",
        "  return attention_masks"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6-5iLDW2f3O",
        "outputId": "f78b9184-ca21-48d5-cdac-38a5acbc5c75"
      },
      "source": [
        "#define the model\n",
        "from pytorch_pretrained_bert import BertForMaskedLM\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "for param in model.bert.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "model.cuda()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): BertLayerNorm()\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez0g4unJ9j1T"
      },
      "source": [
        "train_masks = create_masks(train_tokens2ids)\n",
        "val_masks = create_masks(val_tokens2ids)\n",
        "test_masks = create_masks(test_tokens2ids)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOJdR6bt8A3z",
        "outputId": "3d81ef10-ca50-4e7b-9196-544fd516e9c4"
      },
      "source": [
        "print(len(train_masks))\n",
        "print(type(train_masks))\n",
        "print(type(train_masks[0]))\n",
        "print(len(train_masks[0]))\n",
        "print(len(train_masks[0][0]))\n",
        "print(len(train_masks[1]))\n",
        "print(len(train_masks[1][1]))\n",
        "\n",
        "print(len(val_masks))\n",
        "\n",
        "print(len(test_masks))\n",
        "\n",
        "print(len(data_train_tokenized['SU4'][0]))\n",
        "\n",
        "print(len(train_tokens2ids[0]))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2075\n",
            "<class 'list'>\n",
            "<class 'numpy.ndarray'>\n",
            "11\n",
            "512\n",
            "13\n",
            "512\n",
            "519\n",
            "648\n",
            "11\n",
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cqTfJ1c5Npev",
        "outputId": "36b4fdf9-5327-400e-bfb2-c2ed7cfe5835"
      },
      "source": [
        "# specify GPU device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tScPZU7OQN9J",
        "outputId": "539b5026-c53c-4baf-859a-f98d051759fc"
      },
      "source": [
        "train_labels = list(data_train_tokenized['SU4'])\n",
        "val_labels = list(data_val_tokenized['SU4'])\n",
        "print(len(train_labels))\n",
        "print(len(val_labels))\n",
        "\n",
        "train_tokens2ids = list(train_tokens2ids)\n",
        "val_tokens2ids= list(val_tokens2ids)\n",
        "print(len(train_tokens2ids[0]))\n",
        "print(len(val_tokens2ids))\n",
        "\n",
        "train_masks = list(train_masks)\n",
        "val_masks= list(val_masks)\n",
        "print(len(train_masks))\n",
        "print(len(val_masks))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2075\n",
            "519\n",
            "11\n",
            "519\n",
            "2075\n",
            "519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ARzDFyZT4G4",
        "outputId": "f6f6ed94-9dc9-41d3-df0a-a3d065ac2f75"
      },
      "source": [
        "print(train_labels[:3])\n",
        "print(train_tokens2ids[:3])\n",
        "print(train_masks[:3])\n",
        "\n",
        "print(type(train_labels))\n",
        "print(type(train_tokens2ids))\n",
        "print(type(train_masks))\n",
        "\n",
        "print(len(train_labels))\n",
        "print(len(train_tokens2ids))\n",
        "print(len(train_masks))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.15, 0.06383, 0.05714, 0.033710000000000004, 0.03077, 0.02, 0.0198, 0.01887, 0.01163, 0.0, 0.0], [0.39823, 0.37069, 0.28261, 0.27174, 0.21641, 0.12987, 0.09346, 0.08434, 0.07042000000000001, 0.02994, 0.02703, 0.02521, 0.0], [0.27273000000000003, 0.27273000000000003, 0.21267, 0.15859, 0.14331, 0.13618, 0.13546, 0.10593, 0.09616, 0.08867, 0.07142000000000001, 0.07142000000000001, 0.06225, 0.05759, 0.05586, 0.05154, 0.04959, 0.04946, 0.04721, 0.04396, 0.042460000000000005, 0.03846, 0.0367, 0.03665, 0.03553, 0.033839999999999995, 0.02857, 0.02747, 0.02358, 0.02, 0.01596, 0.005]]\n",
            "[array([[  101,  6643,  8197, ...,     0,     0,     0],\n",
            "       [  101, 17928, 24412, ...,     0,     0,     0],\n",
            "       [  101,  2119, 19117, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [  101,  2057,  2179, ...,     0,     0,     0],\n",
            "       [  101,  6643,  8197, ...,     0,     0,     0],\n",
            "       [  101,  2023,  3319, ...,     0,     0,     0]]), array([[  101,  9808,  2618, ...,     0,     0,     0],\n",
            "       [  101, 10769,  2552, ...,     0,     0,     0],\n",
            "       [  101,  2009,  2788, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [  101,  2057,  6709, ...,     0,     0,     0],\n",
            "       [  101,  2057,  7275, ...,     0,     0,     0],\n",
            "       [  101,  9808,  2618, ...,     0,     0,     0]]), array([[  101, 20194, 14719, ...,     0,     0,     0],\n",
            "       [  101, 20194, 14719, ...,     0,     0,     0],\n",
            "       [  101,  2633,  1010, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [  101,  1999,  2804, ...,     0,     0,     0],\n",
            "       [  101,  1996,  3463, ...,     0,     0,     0],\n",
            "       [  101,  2070,  1010, ...,     0,     0,     0]])]\n",
            "[array([[1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.]]), array([[1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.]]), array([[1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.]])]\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "2075\n",
            "2075\n",
            "2075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TE5fHRe-PeV"
      },
      "source": [
        "def convert2array(givenlist):\n",
        "  return np.array(givenlist)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRjtJPb8O6Bk",
        "outputId": "1cf75159-fe4f-40ea-ec15-3b9ef8d7798a"
      },
      "source": [
        "train_tokens2ids_nparr = convert2array(train_tokens2ids)\n",
        "val_tokens2ids_nparr = convert2array(val_tokens2ids)\n",
        "\n",
        "train_masks_nparr = convert2array(train_masks)\n",
        "val_masks_nparr = convert2array(val_masks)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMCZ9Q1NQPq4",
        "outputId": "2620b687-656b-4b47-be17-0a79c8e6f2c9"
      },
      "source": [
        "print(type(train_masks_nparr))\n",
        "print(train_masks_nparr.shape)\n",
        "print(train_masks_nparr[:3])"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(2075,)\n",
            "[array([[1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.]])\n",
            " array([[1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.]])\n",
            " array([[1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.]])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms7yMcq4E5ut"
      },
      "source": [
        "def labellist2arr(givenlist):\n",
        "  labels = []\n",
        "  for i in range(len(givenlist)):\n",
        "    label = np.array(givenlist[i])\n",
        "    labels.append(label)\n",
        "  return labels"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxbfiB_SS02H"
      },
      "source": [
        "train_labels_nparr = labellist2arr(train_labels)\n",
        "val_labels_nparr = labellist2arr(val_labels)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUNtB67HNqhb"
      },
      "source": [
        "def convert2tensor(givenarray):\n",
        "  masks_tensors = []\n",
        "  for i in range(len(givenarray)):\n",
        "    tensor_mask = torch.from_numpy(givenarray[i])\n",
        "    masks_tensors.append(tensor_mask)\n",
        "  return masks_tensors\n",
        "\n",
        "  "
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WKSK7tDONN1"
      },
      "source": [
        "train_inputs_tensors = convert2tensor(train_tokens2ids_nparr)\n",
        "val_inputs_tensors = convert2tensor(val_tokens2ids_nparr)"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czYvUqdMJ4ru",
        "outputId": "5e2aa3d1-1e68-4ebf-a3a7-8d9e22e81221"
      },
      "source": [
        "print(type(train_inputs_tensors))\n",
        "print(type(train_inputs_tensors[0][0]))\n",
        "print(train_inputs_tensors[0])"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[  101,  6643,  8197,  ...,     0,     0,     0],\n",
            "        [  101, 17928, 24412,  ...,     0,     0,     0],\n",
            "        [  101,  2119, 19117,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  2057,  2179,  ...,     0,     0,     0],\n",
            "        [  101,  6643,  8197,  ...,     0,     0,     0],\n",
            "        [  101,  2023,  3319,  ...,     0,     0,     0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn9e4quWPCOs"
      },
      "source": [
        "train_masks_tensors = convert2tensor(train_masks_nparr)\n",
        "val_masks_tensors = convert2tensor(val_masks_nparr)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHfQ99L6F29c",
        "outputId": "b92da9ad-0ba2-4559-9e7b-3978aec4b32c"
      },
      "source": [
        "print(type(train_masks_tensors))\n",
        "print(type(train_masks_tensors[0]))\n",
        "print(train_masks_tensors[0])"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ-ffp1bSkoe"
      },
      "source": [
        "train_labels_tensors = convert2tensor(train_labels_nparr)\n",
        "val_labels_tensors = convert2tensor(val_labels_nparr)"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhWbxHVCUMuB",
        "outputId": "d858fb4c-aaee-409e-b743-d84a2bdf8b11"
      },
      "source": [
        "print(type(train_labels_tensors))\n",
        "print(type(train_labels_tensors[0]))\n",
        "print(train_labels_tensors[0].shape)\n",
        "print(train_inputs_tensors[0].shape)\n",
        "print(train_masks_tensors[0].shape)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([11])\n",
            "torch.Size([11, 512])\n",
            "torch.Size([11, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-_SKMHE2kBn"
      },
      "source": [
        "#train the model\n",
        "\n",
        "# Select a batch size for training. \n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}